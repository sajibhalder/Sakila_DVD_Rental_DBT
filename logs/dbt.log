2022-01-22 17:40:28.155561 (MainThread): Running with dbt=0.21.1
2022-01-22 17:40:29.245445 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-22 17:40:29.261132 (MainThread): Tracking: tracking
2022-01-22 17:40:29.344686 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D585D9CA30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D585EACD90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D585EAC910>]}
2022-01-22 17:40:29.462689 (MainThread): Partial parsing not enabled
2022-01-22 17:40:31.926784 (MainThread): Parsing macros\adapters.sql
2022-01-22 17:40:32.092728 (MainThread): Parsing macros\catalog.sql
2022-01-22 17:40:32.111040 (MainThread): Parsing macros\relations.sql
2022-01-22 17:40:32.113001 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-22 17:40:32.115992 (MainThread): Parsing macros\core.sql
2022-01-22 17:40:32.121976 (MainThread): Parsing macros\adapters\common.sql
2022-01-22 17:40:32.207327 (MainThread): Parsing macros\etc\datetime.sql
2022-01-22 17:40:32.222949 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-22 17:40:32.222949 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-22 17:40:32.238572 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-22 17:40:32.238572 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-22 17:40:32.238572 (MainThread): Parsing macros\etc\query.sql
2022-01-22 17:40:32.238572 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-22 17:40:32.238572 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-22 17:40:32.269812 (MainThread): Parsing macros\materializations\test.sql
2022-01-22 17:40:32.285470 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-22 17:40:32.316712 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-22 17:40:32.316712 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-22 17:40:32.347921 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-22 17:40:32.384696 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-22 17:40:32.428579 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-22 17:40:32.493186 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-22 17:40:32.493186 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-22 17:40:32.524423 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-22 17:40:32.540048 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-22 17:40:32.540048 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-22 17:40:32.555632 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-22 17:40:32.555632 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-22 17:40:32.555632 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-22 17:40:32.571276 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-22 17:40:32.938860 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-22 17:40:32.970094 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:40:32.985716 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:40:33.048235 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 17:40:33.048235 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 17:40:33.063821 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 17:40:33.063821 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 17:40:33.134516 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '98a83590-3baa-421a-bbe2-3dd23f37708b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D585F33B50>]}
2022-01-22 17:40:33.223248 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-22 17:40:33.252187 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '98a83590-3baa-421a-bbe2-3dd23f37708b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D585E794F0>]}
2022-01-22 17:40:33.254173 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-01-22 17:40:33.259151 (MainThread): 
2022-01-22 17:40:33.261146 (MainThread): Acquiring new postgres connection "master".
2022-01-22 17:40:33.272117 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 17:40:33.295799 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 17:40:33.295799 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 17:40:33.295799 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-22 17:40:34.139884 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.84 seconds
2022-01-22 17:40:34.139884 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 17:40:34.155428 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_shd".
2022-01-22 17:40:34.155428 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_shd".
2022-01-22 17:40:34.155428 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."shd""
2022-01-22 17:40:34.171042 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_shd".
2022-01-22 17:40:34.171042 (ThreadPoolExecutor-0_0): On create_sakila_wh_shd: BEGIN
2022-01-22 17:40:34.171042 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 17:40:34.309450 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.14 seconds
2022-01-22 17:40:34.309450 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_shd".
2022-01-22 17:40:34.309450 (ThreadPoolExecutor-0_0): On create_sakila_wh_shd: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_shd"} */
create schema if not exists "shd"
2022-01-22 17:40:34.586058 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.28 seconds
2022-01-22 17:40:34.586058 (ThreadPoolExecutor-0_0): On create_sakila_wh_shd: COMMIT
2022-01-22 17:40:34.586058 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_shd".
2022-01-22 17:40:34.586058 (ThreadPoolExecutor-0_0): On create_sakila_wh_shd: COMMIT
2022-01-22 17:40:34.632920 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.05 seconds
2022-01-22 17:40:34.648448 (ThreadPoolExecutor-0_0): On create_sakila_wh_shd: Close
2022-01-22 17:40:34.648448 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_shd".
2022-01-22 17:40:34.679738 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_shd".
2022-01-22 17:40:34.679738 (ThreadPoolExecutor-1_0): On list_sakila_wh_shd: BEGIN
2022-01-22 17:40:34.679738 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-22 17:40:34.985757 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.31 seconds
2022-01-22 17:40:34.985757 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_shd".
2022-01-22 17:40:34.985757 (ThreadPoolExecutor-1_0): On list_sakila_wh_shd: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_shd"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'shd'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'shd'
  
2022-01-22 17:40:35.375881 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.39 seconds
2022-01-22 17:40:35.391412 (ThreadPoolExecutor-1_0): On list_sakila_wh_shd: ROLLBACK
2022-01-22 17:40:35.391412 (ThreadPoolExecutor-1_0): On list_sakila_wh_shd: Close
2022-01-22 17:40:35.407030 (MainThread): Using postgres connection "master".
2022-01-22 17:40:35.407030 (MainThread): On master: BEGIN
2022-01-22 17:40:35.407030 (MainThread): Opening a new connection, currently in state init
2022-01-22 17:40:35.503068 (MainThread): SQL status: BEGIN in 0.10 seconds
2022-01-22 17:40:35.503068 (MainThread): Using postgres connection "master".
2022-01-22 17:40:35.503068 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-22 17:40:36.464872 (MainThread): SQL status: SELECT 43 in 0.96 seconds
2022-01-22 17:40:36.464872 (MainThread): On master: ROLLBACK
2022-01-22 17:40:36.464872 (MainThread): Using postgres connection "master".
2022-01-22 17:40:36.464872 (MainThread): On master: BEGIN
2022-01-22 17:40:36.464872 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-22 17:40:36.464872 (MainThread): On master: COMMIT
2022-01-22 17:40:36.464872 (MainThread): Using postgres connection "master".
2022-01-22 17:40:36.464872 (MainThread): On master: COMMIT
2022-01-22 17:40:36.464872 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 17:40:36.464872 (MainThread): On master: Close
2022-01-22 17:40:36.464872 (MainThread): 23:10:36 | Concurrency: 1 threads (target='dev')
2022-01-22 17:40:36.464872 (MainThread): 23:10:36 | 
2022-01-22 17:40:37.188742 (Thread-1): Began running node model.sakila_dbt_project.dim_customer
2022-01-22 17:40:37.189786 (Thread-1): 23:10:37 | 1 of 3 START view model shd.dim_customer............................. [RUN]
2022-01-22 17:40:37.190840 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-22 17:40:37.191835 (Thread-1): Compiling model.sakila_dbt_project.dim_customer
2022-01-22 17:40:37.194828 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-22 17:40:37.258453 (Thread-1): finished collecting timing info
2022-01-22 17:40:37.345236 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-22 17:40:37.351271 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-22 17:40:37.352395 (Thread-1): On model.sakila_dbt_project.dim_customer: BEGIN
2022-01-22 17:40:37.352395 (Thread-1): Opening a new connection, currently in state init
2022-01-22 17:40:37.523845 (Thread-1): SQL status: BEGIN in 0.17 seconds
2022-01-22 17:40:37.523845 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-22 17:40:37.523845 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

  create view "sakila_wh"."shd"."dim_customer__dbt_tmp" as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );

2022-01-22 17:40:37.992534 (Thread-1): SQL status: CREATE VIEW in 0.47 seconds
2022-01-22 17:40:38.023746 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-22 17:40:38.023746 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */
alter table "sakila_wh"."shd"."dim_customer__dbt_tmp" rename to "dim_customer"
2022-01-22 17:40:38.164337 (Thread-1): SQL status: ALTER TABLE in 0.14 seconds
2022-01-22 17:40:38.211204 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-22 17:40:38.211204 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-22 17:40:38.211204 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-22 17:40:38.211204 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 17:40:38.211204 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-22 17:40:38.211204 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */
drop view if exists "sakila_wh"."shd"."dim_customer__dbt_backup" cascade
2022-01-22 17:40:38.242507 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2022-01-22 17:40:38.242507 (Thread-1): finished collecting timing info
2022-01-22 17:40:38.242507 (Thread-1): On model.sakila_dbt_project.dim_customer: Close
2022-01-22 17:40:38.242507 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '98a83590-3baa-421a-bbe2-3dd23f37708b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D585E7AD30>]}
2022-01-22 17:40:38.242507 (Thread-1): 23:10:38 | 1 of 3 OK created view model shd.dim_customer........................ [CREATE VIEW in 1.05s]
2022-01-22 17:40:38.242507 (Thread-1): Finished running node model.sakila_dbt_project.dim_customer
2022-01-22 17:40:38.242507 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 17:40:38.242507 (Thread-1): 23:10:38 | 2 of 3 START table model shd.my_first_dbt_model...................... [RUN]
2022-01-22 17:40:38.242507 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:40:38.242507 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-22 17:40:38.242507 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 17:40:38.258013 (Thread-1): finished collecting timing info
2022-01-22 17:40:38.289262 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 17:40:38.289262 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:40:38.289262 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-22 17:40:38.289262 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 17:40:38.423696 (Thread-1): SQL status: BEGIN in 0.13 seconds
2022-01-22 17:40:38.423696 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:40:38.423696 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."shd"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-22 17:40:38.501802 (Thread-1): SQL status: SELECT 2 in 0.08 seconds
2022-01-22 17:40:38.501802 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:40:38.501802 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."shd"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-22 17:40:38.533046 (Thread-1): SQL status: ALTER TABLE in 0.03 seconds
2022-01-22 17:40:38.548668 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 17:40:38.548668 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:40:38.548668 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 17:40:38.548668 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 17:40:38.548668 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:40:38.548668 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."shd"."my_first_dbt_model__dbt_backup" cascade
2022-01-22 17:40:38.548668 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 17:40:38.548668 (Thread-1): finished collecting timing info
2022-01-22 17:40:38.548668 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-22 17:40:38.548668 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '98a83590-3baa-421a-bbe2-3dd23f37708b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D585D6DD60>]}
2022-01-22 17:40:38.548668 (Thread-1): 23:10:38 | 2 of 3 OK created table model shd.my_first_dbt_model................. [SELECT 2 in 0.31s]
2022-01-22 17:40:38.548668 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 17:40:38.611298 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 17:40:38.611298 (Thread-1): 23:10:38 | 3 of 3 START view model shd.my_second_dbt_model...................... [RUN]
2022-01-22 17:40:38.611298 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:40:38.611298 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-22 17:40:38.611298 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 17:40:38.611298 (Thread-1): finished collecting timing info
2022-01-22 17:40:38.611298 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 17:40:38.611298 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:40:38.611298 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-22 17:40:38.611298 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 17:40:38.698856 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-22 17:40:38.698856 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:40:38.698856 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */

  create view "sakila_wh"."shd"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."shd"."my_first_dbt_model"
where id = 1
  );

2022-01-22 17:40:38.730074 (Thread-1): SQL status: CREATE VIEW in 0.03 seconds
2022-01-22 17:40:38.745696 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:40:38.745696 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."shd"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-22 17:40:38.745696 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 17:40:38.745696 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 17:40:38.745696 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:40:38.745696 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 17:40:38.745696 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 17:40:38.745696 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:40:38.761317 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop view if exists "sakila_wh"."shd"."my_second_dbt_model__dbt_backup" cascade
2022-01-22 17:40:38.761317 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2022-01-22 17:40:38.761317 (Thread-1): finished collecting timing info
2022-01-22 17:40:38.761317 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-22 17:40:38.761317 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '98a83590-3baa-421a-bbe2-3dd23f37708b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D586069790>]}
2022-01-22 17:40:38.761317 (Thread-1): 23:10:38 | 3 of 3 OK created view model shd.my_second_dbt_model................. [CREATE VIEW in 0.15s]
2022-01-22 17:40:38.761317 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 17:40:38.761317 (MainThread): Acquiring new postgres connection "master".
2022-01-22 17:40:38.761317 (MainThread): Using postgres connection "master".
2022-01-22 17:40:38.761317 (MainThread): On master: BEGIN
2022-01-22 17:40:38.761317 (MainThread): Opening a new connection, currently in state closed
2022-01-22 17:40:38.933156 (MainThread): SQL status: BEGIN in 0.17 seconds
2022-01-22 17:40:38.933156 (MainThread): On master: COMMIT
2022-01-22 17:40:38.933156 (MainThread): Using postgres connection "master".
2022-01-22 17:40:38.933156 (MainThread): On master: COMMIT
2022-01-22 17:40:38.933156 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 17:40:38.933156 (MainThread): On master: Close
2022-01-22 17:40:38.933156 (MainThread): 23:10:38 | 
2022-01-22 17:40:38.933156 (MainThread): 23:10:38 | Finished running 2 view models, 1 table model in 5.67s.
2022-01-22 17:40:38.933156 (MainThread): Connection 'master' was properly closed.
2022-01-22 17:40:38.933156 (MainThread): Connection 'create_sakila_wh_shd' was properly closed.
2022-01-22 17:40:38.933156 (MainThread): Connection 'list_sakila_wh_shd' was properly closed.
2022-01-22 17:40:38.933156 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-22 17:40:38.948773 (MainThread): 
2022-01-22 17:40:38.948773 (MainThread): Completed successfully
2022-01-22 17:40:38.948773 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-22 17:40:38.948773 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D585DAFF10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D58607C940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D585D88910>]}
2022-01-22 17:40:38.948773 (MainThread): Flushing usage events
2022-01-22 17:56:03.268903 (MainThread): Running with dbt=0.21.1
2022-01-22 17:56:03.768323 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-22 17:56:03.784064 (MainThread): Tracking: tracking
2022-01-22 17:56:03.869755 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025E7B39C850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025E7B4A5CA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025E7B4A5A90>]}
2022-01-22 17:56:03.900994 (MainThread): Partial parsing not enabled
2022-01-22 17:56:04.166607 (MainThread): Parsing macros\adapters.sql
2022-01-22 17:56:04.229036 (MainThread): Parsing macros\catalog.sql
2022-01-22 17:56:04.229036 (MainThread): Parsing macros\relations.sql
2022-01-22 17:56:04.229036 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-22 17:56:04.244656 (MainThread): Parsing macros\core.sql
2022-01-22 17:56:04.244656 (MainThread): Parsing macros\adapters\common.sql
2022-01-22 17:56:04.369628 (MainThread): Parsing macros\etc\datetime.sql
2022-01-22 17:56:04.385249 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-22 17:56:04.385249 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-22 17:56:04.385249 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-22 17:56:04.400871 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-22 17:56:04.400871 (MainThread): Parsing macros\etc\query.sql
2022-01-22 17:56:04.400871 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-22 17:56:04.400871 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-22 17:56:04.416492 (MainThread): Parsing macros\materializations\test.sql
2022-01-22 17:56:04.432114 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-22 17:56:04.447734 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-22 17:56:04.463409 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-22 17:56:04.478977 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-22 17:56:04.510219 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-22 17:56:04.557084 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-22 17:56:04.619571 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-22 17:56:04.619571 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-22 17:56:04.666433 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-22 17:56:04.682054 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-22 17:56:04.682054 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-22 17:56:04.697677 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-22 17:56:04.697677 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-22 17:56:04.697677 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-22 17:56:04.713335 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-22 17:56:05.041347 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 17:56:05.056980 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 17:56:05.072586 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:56:05.072586 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 17:56:05.072586 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:56:05.072586 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 17:56:05.119452 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 17:56:05.135112 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 17:56:05.135112 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 17:56:05.135112 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 17:56:05.150695 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.sakila_dbt_project.dimensions

2022-01-22 17:56:05.174112 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '35fe9d90-3ac5-48eb-9717-c41b242ec20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025E7B47C790>]}
2022-01-22 17:56:05.176269 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-22 17:56:05.191900 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35fe9d90-3ac5-48eb-9717-c41b242ec20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025E7B4FB790>]}
2022-01-22 17:56:05.191900 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-01-22 17:56:05.223139 (MainThread): 
2022-01-22 17:56:05.223139 (MainThread): Acquiring new postgres connection "master".
2022-01-22 17:56:05.254399 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 17:56:05.294082 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 17:56:05.294082 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 17:56:05.294082 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-22 17:56:05.731561 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.44 seconds
2022-01-22 17:56:05.731561 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 17:56:05.731561 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_shd_examples".
2022-01-22 17:56:05.731561 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_shd_examples".
2022-01-22 17:56:05.731561 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."shd_examples""
2022-01-22 17:56:05.762731 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_shd_examples".
2022-01-22 17:56:05.762731 (ThreadPoolExecutor-0_0): On create_sakila_wh_shd_examples: BEGIN
2022-01-22 17:56:05.762731 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 17:56:05.856453 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.09 seconds
2022-01-22 17:56:05.856453 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_shd_examples".
2022-01-22 17:56:05.856453 (ThreadPoolExecutor-0_0): On create_sakila_wh_shd_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_shd_examples"} */
create schema if not exists "shd_examples"
2022-01-22 17:56:05.934574 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.08 seconds
2022-01-22 17:56:05.950237 (ThreadPoolExecutor-0_0): On create_sakila_wh_shd_examples: COMMIT
2022-01-22 17:56:05.950237 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_shd_examples".
2022-01-22 17:56:05.950237 (ThreadPoolExecutor-0_0): On create_sakila_wh_shd_examples: COMMIT
2022-01-22 17:56:05.950237 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2022-01-22 17:56:05.950237 (ThreadPoolExecutor-0_0): On create_sakila_wh_shd_examples: Close
2022-01-22 17:56:05.965802 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_shd_examples".
2022-01-22 17:56:05.997085 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_shd_examples".
2022-01-22 17:56:05.997085 (ThreadPoolExecutor-1_0): On list_sakila_wh_shd_examples: BEGIN
2022-01-22 17:56:05.997085 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-22 17:56:06.090806 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.09 seconds
2022-01-22 17:56:06.090806 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_shd_examples".
2022-01-22 17:56:06.090806 (ThreadPoolExecutor-1_0): On list_sakila_wh_shd_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_shd_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'shd_examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'shd_examples'
  
2022-01-22 17:56:06.184509 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.09 seconds
2022-01-22 17:56:06.184509 (ThreadPoolExecutor-1_0): On list_sakila_wh_shd_examples: ROLLBACK
2022-01-22 17:56:06.184509 (ThreadPoolExecutor-1_0): On list_sakila_wh_shd_examples: Close
2022-01-22 17:56:06.200120 (MainThread): Using postgres connection "master".
2022-01-22 17:56:06.200120 (MainThread): On master: BEGIN
2022-01-22 17:56:06.200120 (MainThread): Opening a new connection, currently in state init
2022-01-22 17:56:06.293890 (MainThread): SQL status: BEGIN in 0.09 seconds
2022-01-22 17:56:06.293890 (MainThread): Using postgres connection "master".
2022-01-22 17:56:06.293890 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-22 17:56:06.903116 (MainThread): SQL status: SELECT 47 in 0.61 seconds
2022-01-22 17:56:06.903116 (MainThread): On master: ROLLBACK
2022-01-22 17:56:06.903116 (MainThread): Using postgres connection "master".
2022-01-22 17:56:06.903116 (MainThread): On master: BEGIN
2022-01-22 17:56:06.903116 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-22 17:56:06.903116 (MainThread): On master: COMMIT
2022-01-22 17:56:06.903116 (MainThread): Using postgres connection "master".
2022-01-22 17:56:06.903116 (MainThread): On master: COMMIT
2022-01-22 17:56:06.903116 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 17:56:06.903116 (MainThread): On master: Close
2022-01-22 17:56:06.903116 (MainThread): 23:26:06 | Concurrency: 1 threads (target='dev')
2022-01-22 17:56:06.903116 (MainThread): 23:26:06 | 
2022-01-22 17:56:06.981385 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-22 17:56:06.981385 (Thread-1): 23:26:06 | 1 of 3 START table model shd_examples.hello_world.................... [RUN]
2022-01-22 17:56:06.981385 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 17:56:06.981385 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-22 17:56:06.996814 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 17:56:06.996814 (Thread-1): finished collecting timing info
2022-01-22 17:56:07.059328 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 17:56:07.074911 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 17:56:07.074911 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-22 17:56:07.074911 (Thread-1): Opening a new connection, currently in state init
2022-01-22 17:56:07.177014 (Thread-1): SQL status: BEGIN in 0.10 seconds
2022-01-22 17:56:07.177014 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 17:56:07.177014 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."shd_examples"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-22 17:56:07.442581 (Thread-1): SQL status: SELECT 599 in 0.27 seconds
2022-01-22 17:56:07.458239 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 17:56:07.458239 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."shd_examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-22 17:56:07.505195 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-22 17:56:07.520683 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 17:56:07.520683 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 17:56:07.520683 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 17:56:07.520683 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 17:56:07.536340 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 17:56:07.536340 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."shd_examples"."hello_world__dbt_backup" cascade
2022-01-22 17:56:07.536340 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 17:56:07.536340 (Thread-1): finished collecting timing info
2022-01-22 17:56:07.536340 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-22 17:56:07.536340 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35fe9d90-3ac5-48eb-9717-c41b242ec20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025E7B5F4D60>]}
2022-01-22 17:56:07.536340 (Thread-1): 23:26:07 | 1 of 3 OK created table model shd_examples.hello_world............... [SELECT 599 in 0.55s]
2022-01-22 17:56:07.536340 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-22 17:56:07.536340 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 17:56:07.536340 (Thread-1): 23:26:07 | 2 of 3 START table model shd_examples.my_first_dbt_model............. [RUN]
2022-01-22 17:56:07.536340 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:56:07.536340 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-22 17:56:07.551930 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 17:56:07.551930 (Thread-1): finished collecting timing info
2022-01-22 17:56:07.551930 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 17:56:07.551930 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:56:07.551930 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-22 17:56:07.551930 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 17:56:07.630710 (Thread-1): SQL status: BEGIN in 0.08 seconds
2022-01-22 17:56:07.630710 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:56:07.630710 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."shd_examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-22 17:56:07.708815 (Thread-1): SQL status: SELECT 2 in 0.06 seconds
2022-01-22 17:56:07.708815 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:56:07.708815 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."shd_examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-22 17:56:07.708815 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 17:56:07.708815 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 17:56:07.708815 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:56:07.708815 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 17:56:07.724434 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-22 17:56:07.724434 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 17:56:07.724434 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."shd_examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-22 17:56:07.724434 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 17:56:07.724434 (Thread-1): finished collecting timing info
2022-01-22 17:56:07.724434 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-22 17:56:07.724434 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35fe9d90-3ac5-48eb-9717-c41b242ec20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025E79ADE820>]}
2022-01-22 17:56:07.724434 (Thread-1): 23:26:07 | 2 of 3 OK created table model shd_examples.my_first_dbt_model........ [SELECT 2 in 0.19s]
2022-01-22 17:56:07.724434 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 17:56:07.755682 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 17:56:07.755682 (Thread-1): 23:26:07 | 3 of 3 START table model shd_examples.my_second_dbt_model............ [RUN]
2022-01-22 17:56:07.755682 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:56:07.755682 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-22 17:56:07.755682 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 17:56:07.755682 (Thread-1): finished collecting timing info
2022-01-22 17:56:07.771298 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 17:56:07.771298 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:56:07.771298 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-22 17:56:07.771298 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 17:56:08.051170 (Thread-1): SQL status: BEGIN in 0.28 seconds
2022-01-22 17:56:08.051170 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:56:08.051170 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."shd_examples"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."shd_examples"."my_first_dbt_model"
where id = 1
  );
2022-01-22 17:56:08.113656 (Thread-1): SQL status: SELECT 1 in 0.05 seconds
2022-01-22 17:56:08.113656 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:56:08.113656 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."shd_examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-22 17:56:08.113656 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 17:56:08.113656 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 17:56:08.113656 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:56:08.113656 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 17:56:08.129276 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-22 17:56:08.129276 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 17:56:08.129276 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."shd_examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-22 17:56:08.129276 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 17:56:08.129276 (Thread-1): finished collecting timing info
2022-01-22 17:56:08.129276 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-22 17:56:08.129276 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35fe9d90-3ac5-48eb-9717-c41b242ec20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025E7B65D250>]}
2022-01-22 17:56:08.129276 (Thread-1): 23:26:08 | 3 of 3 OK created table model shd_examples.my_second_dbt_model....... [SELECT 1 in 0.37s]
2022-01-22 17:56:08.129276 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 17:56:08.129276 (MainThread): Acquiring new postgres connection "master".
2022-01-22 17:56:08.129276 (MainThread): Using postgres connection "master".
2022-01-22 17:56:08.129276 (MainThread): On master: BEGIN
2022-01-22 17:56:08.129276 (MainThread): Opening a new connection, currently in state closed
2022-01-22 17:56:08.238624 (MainThread): SQL status: BEGIN in 0.11 seconds
2022-01-22 17:56:08.238624 (MainThread): On master: COMMIT
2022-01-22 17:56:08.238624 (MainThread): Using postgres connection "master".
2022-01-22 17:56:08.238624 (MainThread): On master: COMMIT
2022-01-22 17:56:08.238624 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 17:56:08.238624 (MainThread): On master: Close
2022-01-22 17:56:08.238624 (MainThread): 23:26:08 | 
2022-01-22 17:56:08.238624 (MainThread): 23:26:08 | Finished running 3 table models in 3.02s.
2022-01-22 17:56:08.238624 (MainThread): Connection 'master' was properly closed.
2022-01-22 17:56:08.238624 (MainThread): Connection 'create_sakila_wh_shd_examples' was properly closed.
2022-01-22 17:56:08.238624 (MainThread): Connection 'list_sakila_wh_shd_examples' was properly closed.
2022-01-22 17:56:08.238624 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-22 17:56:08.269876 (MainThread): 
2022-01-22 17:56:08.269876 (MainThread): Completed successfully
2022-01-22 17:56:08.269876 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-22 17:56:08.269876 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025E7B60B880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025E7B669F70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025E7B643EB0>]}
2022-01-22 17:56:08.269876 (MainThread): Flushing usage events
2022-01-22 17:56:16.374178 (MainThread): The 'warn' method is deprecated, use 'warning' instead
2022-01-22 17:56:16.376172 (MainThread): Error sending message, disabling tracking
2022-01-22 18:16:40.349951 (MainThread): Running with dbt=0.21.1
2022-01-22 18:16:40.875807 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-22 18:16:40.894236 (MainThread): Tracking: tracking
2022-01-22 18:16:40.968079 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000150F434CA60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000150F4455F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000150F44555E0>]}
2022-01-22 18:16:41.008120 (MainThread): Partial parsing not enabled
2022-01-22 18:16:41.054145 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000150F447D5B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000150F443BD00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000150F443B970>]}
2022-01-22 18:16:41.055142 (MainThread): Flushing usage events
2022-01-22 18:16:46.021247 (MainThread): Encountered an error:
2022-01-22 18:16:46.021247 (MainThread): Compilation Error
  Error reading sakila_dbt_project: example\schema.yml - Runtime Error
    Syntax error near line 13
    ------------------------------
    10 |           - unique
    11 |           - not_null
    12 | 
    13 |  - name: my_second_dbt_model
    14 |     description: "A starter dbt model"
    15 |     columns:
    16 |       - name: id
    
    Raw Error:
    ------------------------------
    while parsing a block mapping
      in "<unicode string>", line 1, column 1
    did not find expected key
      in "<unicode string>", line 13, column 2
2022-01-22 18:16:48.902119 (MainThread): Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\yaml_helper.py", line 65, in load_yaml_text
    return safe_load(contents)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\yaml_helper.py", line 60, in safe_load
    return yaml.load(contents, Loader=SafeLoader)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\yaml\__init__.py", line 81, in load
    return loader.get_single_data()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\yaml\constructor.py", line 49, in get_single_data
    node = self.get_single_node()
  File "yaml\_yaml.pyx", line 673, in yaml._yaml.CParser.get_single_node
  File "yaml\_yaml.pyx", line 687, in yaml._yaml.CParser._compose_document
  File "yaml\_yaml.pyx", line 731, in yaml._yaml.CParser._compose_node
  File "yaml\_yaml.pyx", line 847, in yaml._yaml.CParser._compose_mapping_node
  File "yaml\_yaml.pyx", line 860, in yaml._yaml.CParser._parse_next_event
yaml.parser.ParserError: while parsing a block mapping
  in "<unicode string>", line 1, column 1
did not find expected key
  in "<unicode string>", line 13, column 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\schemas.py", line 108, in yaml_from_file
    return load_yaml_text(source_file.contents)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\yaml_helper.py", line 72, in load_yaml_text
    raise dbt.exceptions.ValidationException(error)
dbt.exceptions.ValidationException: Runtime Error
  Syntax error near line 13
  ------------------------------
  10 |           - unique
  11 |           - not_null
  12 | 
  13 |  - name: my_second_dbt_model
  14 |     description: "A starter dbt model"
  15 |     columns:
  16 |       - name: id
  
  Raw Error:
  ------------------------------
  while parsing a block mapping
    in "<unicode string>", line 1, column 1
  did not find expected key
    in "<unicode string>", line 13, column 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 258, in run_from_args
    results = task.run()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 438, in run
    self._runtime_initialize()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 210, in load
    read_files(project, self.manifest.files, project_parser_files, saved_files)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\read_files.py", line 151, in read_files
    project_files['SchemaParser'] = read_files_for_parser(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\read_files.py", line 106, in read_files_for_parser
    source_files = get_source_files(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\read_files.py", line 97, in get_source_files
    file = load_source_file(fp, parse_file_type, project.project_name, saved_files)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\read_files.py", line 37, in load_source_file
    dfy = yaml_from_file(source_file)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\schemas.py", line 111, in yaml_from_file
    raise CompilationException(
dbt.exceptions.CompilationException: Compilation Error
  Error reading sakila_dbt_project: example\schema.yml - Runtime Error
    Syntax error near line 13
    ------------------------------
    10 |           - unique
    11 |           - not_null
    12 | 
    13 |  - name: my_second_dbt_model
    14 |     description: "A starter dbt model"
    15 |     columns:
    16 |       - name: id
    
    Raw Error:
    ------------------------------
    while parsing a block mapping
      in "<unicode string>", line 1, column 1
    did not find expected key
      in "<unicode string>", line 13, column 2

2022-01-22 18:21:37.622396 (MainThread): Running with dbt=0.21.1
2022-01-22 18:21:37.762983 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-22 18:21:37.762983 (MainThread): Tracking: tracking
2022-01-22 18:21:37.778602 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B1D5C850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B1E65850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B1E65A90>]}
2022-01-22 18:21:37.794224 (MainThread): Partial parsing not enabled
2022-01-22 18:21:37.809845 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B1D6F2B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B1E4B370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B1E4B2B0>]}
2022-01-22 18:21:37.809845 (MainThread): Flushing usage events
2022-01-22 18:21:38.762745 (MainThread): Encountered an error:
2022-01-22 18:21:38.762745 (MainThread): Compilation Error
  Error reading sakila_dbt_project: example\schema.yml - Runtime Error
    Syntax error near line 22
    ------------------------------
    19 |           - unique
    20 |           - not_null
    21 |   - name: hello_world
    22 |    columns:
    23 |      - name: customer_id
    24 |        description: "The primary key for this table"
    25 |        tests:
    
    Raw Error:
    ------------------------------
    while parsing a block collection
      in "<unicode string>", line 4, column 3
    did not find expected '-' indicator
      in "<unicode string>", line 22, column 4
2022-01-22 18:21:38.778376 (MainThread): Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\yaml_helper.py", line 65, in load_yaml_text
    return safe_load(contents)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\yaml_helper.py", line 60, in safe_load
    return yaml.load(contents, Loader=SafeLoader)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\yaml\__init__.py", line 81, in load
    return loader.get_single_data()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\yaml\constructor.py", line 49, in get_single_data
    node = self.get_single_node()
  File "yaml\_yaml.pyx", line 673, in yaml._yaml.CParser.get_single_node
  File "yaml\_yaml.pyx", line 687, in yaml._yaml.CParser._compose_document
  File "yaml\_yaml.pyx", line 731, in yaml._yaml.CParser._compose_node
  File "yaml\_yaml.pyx", line 845, in yaml._yaml.CParser._compose_mapping_node
  File "yaml\_yaml.pyx", line 729, in yaml._yaml.CParser._compose_node
  File "yaml\_yaml.pyx", line 808, in yaml._yaml.CParser._compose_sequence_node
  File "yaml\_yaml.pyx", line 860, in yaml._yaml.CParser._parse_next_event
yaml.parser.ParserError: while parsing a block collection
  in "<unicode string>", line 4, column 3
did not find expected '-' indicator
  in "<unicode string>", line 22, column 4

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\schemas.py", line 108, in yaml_from_file
    return load_yaml_text(source_file.contents)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\yaml_helper.py", line 72, in load_yaml_text
    raise dbt.exceptions.ValidationException(error)
dbt.exceptions.ValidationException: Runtime Error
  Syntax error near line 22
  ------------------------------
  19 |           - unique
  20 |           - not_null
  21 |   - name: hello_world
  22 |    columns:
  23 |      - name: customer_id
  24 |        description: "The primary key for this table"
  25 |        tests:
  
  Raw Error:
  ------------------------------
  while parsing a block collection
    in "<unicode string>", line 4, column 3
  did not find expected '-' indicator
    in "<unicode string>", line 22, column 4

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 258, in run_from_args
    results = task.run()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 438, in run
    self._runtime_initialize()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 210, in load
    read_files(project, self.manifest.files, project_parser_files, saved_files)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\read_files.py", line 151, in read_files
    project_files['SchemaParser'] = read_files_for_parser(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\read_files.py", line 106, in read_files_for_parser
    source_files = get_source_files(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\read_files.py", line 97, in get_source_files
    file = load_source_file(fp, parse_file_type, project.project_name, saved_files)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\read_files.py", line 37, in load_source_file
    dfy = yaml_from_file(source_file)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\schemas.py", line 111, in yaml_from_file
    raise CompilationException(
dbt.exceptions.CompilationException: Compilation Error
  Error reading sakila_dbt_project: example\schema.yml - Runtime Error
    Syntax error near line 22
    ------------------------------
    19 |           - unique
    20 |           - not_null
    21 |   - name: hello_world
    22 |    columns:
    23 |      - name: customer_id
    24 |        description: "The primary key for this table"
    25 |        tests:
    
    Raw Error:
    ------------------------------
    while parsing a block collection
      in "<unicode string>", line 4, column 3
    did not find expected '-' indicator
      in "<unicode string>", line 22, column 4

2022-01-22 18:25:04.244925 (MainThread): Running with dbt=0.21.1
2022-01-22 18:25:04.369928 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-22 18:25:04.369928 (MainThread): Tracking: tracking
2022-01-22 18:25:04.448033 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4AA568610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4ACD379A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4ACD37550>]}
2022-01-22 18:25:04.463626 (MainThread): Partial parsing not enabled
2022-01-22 18:25:04.619837 (MainThread): Parsing macros\adapters.sql
2022-01-22 18:25:04.666701 (MainThread): Parsing macros\catalog.sql
2022-01-22 18:25:04.666701 (MainThread): Parsing macros\relations.sql
2022-01-22 18:25:04.666701 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-22 18:25:04.682325 (MainThread): Parsing macros\core.sql
2022-01-22 18:25:04.682325 (MainThread): Parsing macros\adapters\common.sql
2022-01-22 18:25:04.791672 (MainThread): Parsing macros\etc\datetime.sql
2022-01-22 18:25:04.807290 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-22 18:25:04.807290 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-22 18:25:04.807290 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-22 18:25:04.822911 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-22 18:25:04.822911 (MainThread): Parsing macros\etc\query.sql
2022-01-22 18:25:04.822911 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-22 18:25:04.822911 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-22 18:25:04.838571 (MainThread): Parsing macros\materializations\test.sql
2022-01-22 18:25:04.854154 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-22 18:25:04.869775 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-22 18:25:04.885396 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-22 18:25:04.901018 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-22 18:25:04.932263 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-22 18:25:04.979162 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-22 18:25:05.025991 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-22 18:25:05.041644 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-22 18:25:05.057233 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-22 18:25:05.072855 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-22 18:25:05.088476 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-22 18:25:05.104093 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-22 18:25:05.104093 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-22 18:25:05.104093 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-22 18:25:05.119715 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-22 18:25:05.525879 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:25:05.541495 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:25:05.557117 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:25:05.557117 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:25:05.557117 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:25:05.557117 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:25:05.557117 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:25:05.572734 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:25:05.619599 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:25:05.619599 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:25:05.619599 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:25:05.619599 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:25:05.635220 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:25:05.635220 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:25:05.635220 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:25:05.650844 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:25:05.682083 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.sakila_dbt_project.dimensions

2022-01-22 18:25:05.696306 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dfe7b06f-24c1-4032-b27f-6c6052cc40a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4ACE57FA0>]}
2022-01-22 18:25:05.711928 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-22 18:25:05.711928 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dfe7b06f-24c1-4032-b27f-6c6052cc40a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4AB38FA90>]}
2022-01-22 18:25:05.711928 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-01-22 18:25:05.711928 (MainThread): 
2022-01-22 18:25:05.711928 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:25:05.711928 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:25:05.743170 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:25:05.743170 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:25:05.743170 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-22 18:25:06.358705 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.62 seconds
2022-01-22 18:25:06.358705 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:25:06.358705 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:25:06.358705 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:25:06.358705 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."dwh_examples""
2022-01-22 18:25:06.374265 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:25:06.374265 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: BEGIN
2022-01-22 18:25:06.374265 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 18:25:06.468057 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:25:06.468057 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:25:06.468057 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_dwh_examples"} */
create schema if not exists "dwh_examples"
2022-01-22 18:25:06.577436 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.11 seconds
2022-01-22 18:25:06.577436 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: COMMIT
2022-01-22 18:25:06.577436 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:25:06.577436 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: COMMIT
2022-01-22 18:25:06.577436 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:25:06.593020 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: Close
2022-01-22 18:25:06.593020 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:25:06.608586 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:25:06.608586 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: BEGIN
2022-01-22 18:25:06.608586 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-22 18:25:06.686689 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.08 seconds
2022-01-22 18:25:06.686689 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:25:06.686689 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_examples'
  
2022-01-22 18:25:06.733674 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.05 seconds
2022-01-22 18:25:06.749228 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: ROLLBACK
2022-01-22 18:25:06.749228 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: Close
2022-01-22 18:25:06.764805 (MainThread): Using postgres connection "master".
2022-01-22 18:25:06.764805 (MainThread): On master: BEGIN
2022-01-22 18:25:06.764805 (MainThread): Opening a new connection, currently in state init
2022-01-22 18:25:06.858525 (MainThread): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:25:06.858525 (MainThread): Using postgres connection "master".
2022-01-22 18:25:06.858525 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-22 18:25:07.452132 (MainThread): SQL status: SELECT 43 in 0.59 seconds
2022-01-22 18:25:07.452132 (MainThread): On master: ROLLBACK
2022-01-22 18:25:07.452132 (MainThread): Using postgres connection "master".
2022-01-22 18:25:07.452132 (MainThread): On master: BEGIN
2022-01-22 18:25:07.452132 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-22 18:25:07.452132 (MainThread): On master: COMMIT
2022-01-22 18:25:07.452132 (MainThread): Using postgres connection "master".
2022-01-22 18:25:07.452132 (MainThread): On master: COMMIT
2022-01-22 18:25:07.452132 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:25:07.452132 (MainThread): On master: Close
2022-01-22 18:25:07.452132 (MainThread): 23:55:07 | Concurrency: 1 threads (target='dev')
2022-01-22 18:25:07.452132 (MainThread): 23:55:07 | 
2022-01-22 18:25:07.530249 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-22 18:25:07.545876 (Thread-1): 23:55:07 | 1 of 4 START table model dwh_examples.dim_date....................... [RUN]
2022-01-22 18:25:07.545876 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:25:07.545876 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-22 18:25:07.545876 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:25:07.545876 (Thread-1): finished collecting timing info
2022-01-22 18:25:07.618635 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:25:07.618635 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:25:07.634258 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-22 18:25:07.634258 (Thread-1): Opening a new connection, currently in state init
2022-01-22 18:25:07.719528 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:25:07.719528 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:25:07.719528 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh_examples"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-22 18:25:08.250660 (Thread-1): SQL status: SELECT 8058 in 0.53 seconds
2022-01-22 18:25:08.266278 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:25:08.266278 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_examples"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-22 18:25:08.313154 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-22 18:25:08.360003 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:25:08.360003 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:25:08.360003 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:25:08.391283 (Thread-1): SQL status: COMMIT in 0.03 seconds
2022-01-22 18:25:08.406907 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:25:08.406907 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh_examples"."dim_date__dbt_backup" cascade
2022-01-22 18:25:08.438120 (Thread-1): SQL status: DROP TABLE in 0.03 seconds
2022-01-22 18:25:08.438120 (Thread-1): finished collecting timing info
2022-01-22 18:25:08.438120 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-22 18:25:08.438120 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dfe7b06f-24c1-4032-b27f-6c6052cc40a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4ACEBE970>]}
2022-01-22 18:25:08.438120 (Thread-1): 23:55:08 | 1 of 4 OK created table model dwh_examples.dim_date.................. [SELECT 8058 in 0.89s]
2022-01-22 18:25:08.438120 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-22 18:25:08.438120 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-22 18:25:08.438120 (Thread-1): 23:55:08 | 2 of 4 START table model dwh_examples.hello_world.................... [RUN]
2022-01-22 18:25:08.438120 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:25:08.438120 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-22 18:25:08.438120 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:25:08.438120 (Thread-1): finished collecting timing info
2022-01-22 18:25:08.453733 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:25:08.453733 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:25:08.453733 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-22 18:25:08.453733 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:25:08.552092 (Thread-1): SQL status: BEGIN in 0.10 seconds
2022-01-22 18:25:08.552092 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:25:08.552092 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-22 18:25:08.770794 (Thread-1): SQL status: SELECT 599 in 0.22 seconds
2022-01-22 18:25:08.786421 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:25:08.786421 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-22 18:25:08.786421 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:25:08.802035 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:25:08.802035 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:25:08.802035 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:25:08.802035 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:25:08.802035 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:25:08.802035 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh_examples"."hello_world__dbt_backup" cascade
2022-01-22 18:25:08.802035 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:25:08.802035 (Thread-1): finished collecting timing info
2022-01-22 18:25:08.802035 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-22 18:25:08.802035 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dfe7b06f-24c1-4032-b27f-6c6052cc40a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4ACEF94F0>]}
2022-01-22 18:25:08.802035 (Thread-1): 23:55:08 | 2 of 4 OK created table model dwh_examples.hello_world............... [SELECT 599 in 0.36s]
2022-01-22 18:25:08.802035 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-22 18:25:08.802035 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:25:08.802035 (Thread-1): 23:55:08 | 3 of 4 START table model dwh_examples.my_first_dbt_model............. [RUN]
2022-01-22 18:25:08.802035 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:25:08.802035 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:25:08.817658 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:25:08.817658 (Thread-1): finished collecting timing info
2022-01-22 18:25:08.817658 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:25:08.817658 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:25:08.817658 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-22 18:25:08.817658 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:25:08.910720 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:25:08.910720 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:25:08.910720 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-22 18:25:08.941958 (Thread-1): SQL status: SELECT 2 in 0.03 seconds
2022-01-22 18:25:08.941958 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:25:08.941958 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-22 18:25:08.941958 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:25:08.941958 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:25:08.941958 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:25:08.941958 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:25:08.957580 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-22 18:25:08.957580 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:25:08.957580 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-22 18:25:08.957580 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:25:08.957580 (Thread-1): finished collecting timing info
2022-01-22 18:25:08.957580 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-22 18:25:08.957580 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dfe7b06f-24c1-4032-b27f-6c6052cc40a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4ACEE89D0>]}
2022-01-22 18:25:08.957580 (Thread-1): 23:55:08 | 3 of 4 OK created table model dwh_examples.my_first_dbt_model........ [SELECT 2 in 0.16s]
2022-01-22 18:25:08.957580 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:25:08.988823 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:25:08.988823 (Thread-1): 23:55:08 | 4 of 4 START table model dwh_examples.my_second_dbt_model............ [RUN]
2022-01-22 18:25:08.988823 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:25:08.988823 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:25:08.988823 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:25:08.988823 (Thread-1): finished collecting timing info
2022-01-22 18:25:08.988823 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:25:08.988823 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:25:08.988823 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-22 18:25:08.988823 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:25:09.081317 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:25:09.081317 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:25:09.081317 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh_examples"."my_first_dbt_model"
where id = 1
  );
2022-01-22 18:25:09.096938 (Thread-1): SQL status: SELECT 1 in 0.02 seconds
2022-01-22 18:25:09.096938 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:25:09.096938 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-22 18:25:09.096938 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:25:09.112560 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:25:09.112560 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:25:09.112560 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:25:09.112560 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:25:09.112560 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:25:09.112560 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-22 18:25:09.112560 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:25:09.112560 (Thread-1): finished collecting timing info
2022-01-22 18:25:09.112560 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-22 18:25:09.112560 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dfe7b06f-24c1-4032-b27f-6c6052cc40a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4ACEFDEB0>]}
2022-01-22 18:25:09.112560 (Thread-1): 23:55:09 | 4 of 4 OK created table model dwh_examples.my_second_dbt_model....... [SELECT 1 in 0.12s]
2022-01-22 18:25:09.112560 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:25:09.128181 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:25:09.128181 (MainThread): Using postgres connection "master".
2022-01-22 18:25:09.128181 (MainThread): On master: BEGIN
2022-01-22 18:25:09.128181 (MainThread): Opening a new connection, currently in state closed
2022-01-22 18:25:09.346881 (MainThread): SQL status: BEGIN in 0.22 seconds
2022-01-22 18:25:09.346881 (MainThread): On master: COMMIT
2022-01-22 18:25:09.346881 (MainThread): Using postgres connection "master".
2022-01-22 18:25:09.346881 (MainThread): On master: COMMIT
2022-01-22 18:25:09.346881 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:25:09.346881 (MainThread): On master: Close
2022-01-22 18:25:09.346881 (MainThread): 23:55:09 | 
2022-01-22 18:25:09.346881 (MainThread): 23:55:09 | Finished running 4 table models in 3.63s.
2022-01-22 18:25:09.346881 (MainThread): Connection 'master' was properly closed.
2022-01-22 18:25:09.346881 (MainThread): Connection 'create_sakila_wh_dwh_examples' was properly closed.
2022-01-22 18:25:09.346881 (MainThread): Connection 'list_sakila_wh_dwh_examples' was properly closed.
2022-01-22 18:25:09.346881 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-22 18:25:09.362511 (MainThread): 
2022-01-22 18:25:09.362511 (MainThread): Completed successfully
2022-01-22 18:25:09.362511 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2022-01-22 18:25:09.362511 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4ACE85F70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4ACE8A5E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4AB38F7F0>]}
2022-01-22 18:25:09.362511 (MainThread): Flushing usage events
2022-01-22 18:30:09.748910 (MainThread): Running with dbt=0.21.1
2022-01-22 18:30:09.884420 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-22 18:30:09.884420 (MainThread): Tracking: tracking
2022-01-22 18:30:09.978149 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4B4CCAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4B5D4F70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4B5D44F0>]}
2022-01-22 18:30:09.993805 (MainThread): Partial parsing not enabled
2022-01-22 18:30:10.056266 (MainThread): Parsing macros\adapters.sql
2022-01-22 18:30:10.103119 (MainThread): Parsing macros\catalog.sql
2022-01-22 18:30:10.103119 (MainThread): Parsing macros\relations.sql
2022-01-22 18:30:10.103119 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-22 18:30:10.103119 (MainThread): Parsing macros\core.sql
2022-01-22 18:30:10.118741 (MainThread): Parsing macros\adapters\common.sql
2022-01-22 18:30:10.228090 (MainThread): Parsing macros\etc\datetime.sql
2022-01-22 18:30:10.243710 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-22 18:30:10.243710 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-22 18:30:10.243710 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-22 18:30:10.259332 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-22 18:30:10.259332 (MainThread): Parsing macros\etc\query.sql
2022-01-22 18:30:10.259332 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-22 18:30:10.259332 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-22 18:30:10.274953 (MainThread): Parsing macros\materializations\test.sql
2022-01-22 18:30:10.290575 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-22 18:30:10.306197 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-22 18:30:10.321819 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-22 18:30:10.337450 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-22 18:30:10.384302 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-22 18:30:10.446788 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-22 18:30:10.524894 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-22 18:30:10.524894 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-22 18:30:10.556140 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-22 18:30:10.571759 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-22 18:30:10.587381 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-22 18:30:10.624161 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-22 18:30:10.633206 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-22 18:30:10.635303 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-22 18:30:10.638311 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-22 18:30:11.117210 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:30:11.138146 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:30:11.153154 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:30:11.164390 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:30:11.166385 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:30:11.171370 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:30:11.179349 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:30:11.184336 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:30:11.247997 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:30:11.250989 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:30:11.267634 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:30:11.271623 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:30:11.279128 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:30:11.286106 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:30:11.290144 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:30:11.300011 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:30:11.336660 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '22f02f4b-21af-43a6-97f3-c860beccbf22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4B5AE460>]}
2022-01-22 18:30:11.353070 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-22 18:30:11.353070 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '22f02f4b-21af-43a6-97f3-c860beccbf22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4B5AEA00>]}
2022-01-22 18:30:11.362727 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-01-22 18:30:11.368709 (MainThread): 
2022-01-22 18:30:11.369705 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:30:11.378683 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:30:11.403296 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:30:11.403296 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:30:11.403296 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-22 18:30:11.619459 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.22 seconds
2022-01-22 18:30:11.628157 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:30:11.630154 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:30:11.635137 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:30:11.636206 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:30:11.636206 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 18:30:11.953266 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.32 seconds
2022-01-22 18:30:11.960483 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:30:11.963459 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:30:11.965450 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:30:11.966448 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."dwh_dwh""
2022-01-22 18:30:11.987138 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:30:11.988134 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: BEGIN
2022-01-22 18:30:11.989130 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 18:30:12.168400 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.18 seconds
2022-01-22 18:30:12.168400 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:30:12.169398 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_dwh_dwh"} */
create schema if not exists "dwh_dwh"
2022-01-22 18:30:12.172387 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2022-01-22 18:30:12.176387 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: COMMIT
2022-01-22 18:30:12.177375 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:30:12.178373 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: COMMIT
2022-01-22 18:30:12.180366 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:30:12.182361 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: Close
2022-01-22 18:30:12.190340 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:30:12.215274 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:30:12.216271 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: BEGIN
2022-01-22 18:30:12.216271 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-22 18:30:12.319992 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.10 seconds
2022-01-22 18:30:12.319992 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:30:12.319992 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_examples'
  
2022-01-22 18:30:12.334953 (ThreadPoolExecutor-1_0): SQL status: SELECT 4 in 0.01 seconds
2022-01-22 18:30:12.337944 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: ROLLBACK
2022-01-22 18:30:12.338941 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: Close
2022-01-22 18:30:12.339939 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:30:12.345923 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:30:12.346920 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: BEGIN
2022-01-22 18:30:12.346920 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-22 18:30:12.433691 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:30:12.433691 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:30:12.434686 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_dwh'
  
2022-01-22 18:30:12.446653 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.01 seconds
2022-01-22 18:30:12.448649 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: ROLLBACK
2022-01-22 18:30:12.448649 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: Close
2022-01-22 18:30:12.459619 (MainThread): Using postgres connection "master".
2022-01-22 18:30:12.459619 (MainThread): On master: BEGIN
2022-01-22 18:30:12.460618 (MainThread): Opening a new connection, currently in state init
2022-01-22 18:30:12.538409 (MainThread): SQL status: BEGIN in 0.08 seconds
2022-01-22 18:30:12.539406 (MainThread): Using postgres connection "master".
2022-01-22 18:30:12.539406 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-22 18:30:13.333502 (MainThread): SQL status: SELECT 43 in 0.79 seconds
2022-01-22 18:30:13.338455 (MainThread): On master: ROLLBACK
2022-01-22 18:30:13.339453 (MainThread): Using postgres connection "master".
2022-01-22 18:30:13.339453 (MainThread): On master: BEGIN
2022-01-22 18:30:13.341445 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-22 18:30:13.342458 (MainThread): On master: COMMIT
2022-01-22 18:30:13.343445 (MainThread): Using postgres connection "master".
2022-01-22 18:30:13.344438 (MainThread): On master: COMMIT
2022-01-22 18:30:13.346432 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:30:13.346432 (MainThread): On master: Close
2022-01-22 18:30:13.347429 (MainThread): 00:00:13 | Concurrency: 1 threads (target='dev')
2022-01-22 18:30:13.348429 (MainThread): 00:00:13 | 
2022-01-22 18:30:13.353414 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-22 18:30:13.353414 (Thread-1): 00:00:13 | 1 of 4 START table model dwh_dwh.dim_date............................ [RUN]
2022-01-22 18:30:13.354414 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:30:13.355410 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-22 18:30:13.359408 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:30:13.362392 (Thread-1): finished collecting timing info
2022-01-22 18:30:13.447163 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:30:13.450154 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:30:13.451153 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-22 18:30:13.451153 (Thread-1): Opening a new connection, currently in state init
2022-01-22 18:30:13.559377 (Thread-1): SQL status: BEGIN in 0.11 seconds
2022-01-22 18:30:13.560374 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:30:13.561370 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-22 18:30:13.960343 (Thread-1): SQL status: SELECT 8059 in 0.40 seconds
2022-01-22 18:30:13.969319 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:30:13.970316 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-22 18:30:13.971317 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:30:14.002234 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:30:14.002234 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:30:14.002234 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:30:14.004012 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:30:14.014988 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:30:14.014988 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh_dwh"."dim_date__dbt_backup" cascade
2022-01-22 18:30:14.015984 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:30:14.019974 (Thread-1): finished collecting timing info
2022-01-22 18:30:14.019974 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-22 18:30:14.020971 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22f02f4b-21af-43a6-97f3-c860beccbf22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4B787A60>]}
2022-01-22 18:30:14.021969 (Thread-1): 00:00:14 | 1 of 4 OK created table model dwh_dwh.dim_date....................... [SELECT 8059 in 0.67s]
2022-01-22 18:30:14.021969 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-22 18:30:14.022966 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-22 18:30:14.022966 (Thread-1): 00:00:14 | 2 of 4 START table model dwh_examples.hello_world.................... [RUN]
2022-01-22 18:30:14.024965 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:30:14.025958 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-22 18:30:14.027955 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:30:14.029949 (Thread-1): finished collecting timing info
2022-01-22 18:30:14.032942 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:30:14.034936 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:30:14.035935 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-22 18:30:14.036929 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:30:14.263459 (Thread-1): SQL status: BEGIN in 0.23 seconds
2022-01-22 18:30:14.264460 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:30:14.265456 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-22 18:30:14.400777 (Thread-1): SQL status: SELECT 599 in 0.13 seconds
2022-01-22 18:30:14.408569 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:30:14.410579 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world" rename to "hello_world__dbt_backup"
2022-01-22 18:30:14.412557 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:30:14.419584 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:30:14.419584 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-22 18:30:14.419584 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:30:14.429174 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:30:14.430161 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:30:14.431152 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:30:14.434145 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:30:14.436192 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:30:14.436192 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh_examples"."hello_world__dbt_backup" cascade
2022-01-22 18:30:14.448093 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2022-01-22 18:30:14.451084 (Thread-1): finished collecting timing info
2022-01-22 18:30:14.452082 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-22 18:30:14.453141 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22f02f4b-21af-43a6-97f3-c860beccbf22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4B74E130>]}
2022-01-22 18:30:14.453141 (Thread-1): 00:00:14 | 2 of 4 OK created table model dwh_examples.hello_world............... [SELECT 599 in 0.43s]
2022-01-22 18:30:14.453141 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-22 18:30:14.453141 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:30:14.453141 (Thread-1): 00:00:14 | 3 of 4 START table model dwh_examples.my_first_dbt_model............. [RUN]
2022-01-22 18:30:14.460482 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:30:14.460482 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:30:14.465449 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:30:14.467444 (Thread-1): finished collecting timing info
2022-01-22 18:30:14.470435 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:30:14.472431 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:30:14.472431 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-22 18:30:14.473428 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:30:14.617968 (Thread-1): SQL status: BEGIN in 0.14 seconds
2022-01-22 18:30:14.618965 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:30:14.618965 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-22 18:30:14.632184 (Thread-1): SQL status: SELECT 2 in 0.01 seconds
2022-01-22 18:30:14.640210 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:30:14.640839 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-22 18:30:14.643831 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:30:14.651810 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:30:14.651810 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-22 18:30:14.653805 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:30:14.658488 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:30:14.660502 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:30:14.661481 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:30:14.667462 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:30:14.672449 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:30:14.673448 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-22 18:30:14.684471 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2022-01-22 18:30:14.688463 (Thread-1): finished collecting timing info
2022-01-22 18:30:14.689461 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-22 18:30:14.690519 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22f02f4b-21af-43a6-97f3-c860beccbf22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4B5B9C10>]}
2022-01-22 18:30:14.695118 (Thread-1): 00:00:14 | 3 of 4 OK created table model dwh_examples.my_first_dbt_model........ [SELECT 2 in 0.23s]
2022-01-22 18:30:14.697113 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:30:14.699105 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:30:14.700103 (Thread-1): 00:00:14 | 4 of 4 START table model dwh_examples.my_second_dbt_model............ [RUN]
2022-01-22 18:30:14.702098 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:30:14.702098 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:30:14.711992 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:30:14.713986 (Thread-1): finished collecting timing info
2022-01-22 18:30:14.718972 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:30:14.719970 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:30:14.720968 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-22 18:30:14.721965 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:30:14.898806 (Thread-1): SQL status: BEGIN in 0.18 seconds
2022-01-22 18:30:14.899805 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:30:14.899805 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh_examples"."my_first_dbt_model"
where id = 1
  );
2022-01-22 18:30:14.917578 (Thread-1): SQL status: SELECT 1 in 0.02 seconds
2022-01-22 18:30:14.929597 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:30:14.930593 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-22 18:30:14.931591 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:30:14.939611 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:30:14.939662 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-22 18:30:14.943513 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:30:14.950051 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:30:14.951051 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:30:14.951051 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:30:14.954041 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:30:14.961489 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:30:14.961489 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-22 18:30:14.970464 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:30:14.974713 (Thread-1): finished collecting timing info
2022-01-22 18:30:14.977684 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-22 18:30:14.980685 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22f02f4b-21af-43a6-97f3-c860beccbf22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4B7C6FA0>]}
2022-01-22 18:30:14.982670 (Thread-1): 00:00:14 | 4 of 4 OK created table model dwh_examples.my_second_dbt_model....... [SELECT 1 in 0.28s]
2022-01-22 18:30:14.982670 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:30:14.985662 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:30:14.986659 (MainThread): Using postgres connection "master".
2022-01-22 18:30:14.987655 (MainThread): On master: BEGIN
2022-01-22 18:30:14.987655 (MainThread): Opening a new connection, currently in state closed
2022-01-22 18:30:15.120443 (MainThread): SQL status: BEGIN in 0.13 seconds
2022-01-22 18:30:15.121443 (MainThread): On master: COMMIT
2022-01-22 18:30:15.121443 (MainThread): Using postgres connection "master".
2022-01-22 18:30:15.121443 (MainThread): On master: COMMIT
2022-01-22 18:30:15.122481 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:30:15.123002 (MainThread): On master: Close
2022-01-22 18:30:15.124180 (MainThread): 00:00:15 | 
2022-01-22 18:30:15.125178 (MainThread): 00:00:15 | Finished running 4 table models in 3.75s.
2022-01-22 18:30:15.128171 (MainThread): Connection 'master' was properly closed.
2022-01-22 18:30:15.128171 (MainThread): Connection 'create_sakila_wh_dwh_dwh' was properly closed.
2022-01-22 18:30:15.129176 (MainThread): Connection 'list_sakila_wh_dwh_dwh' was properly closed.
2022-01-22 18:30:15.131162 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-22 18:30:15.150364 (MainThread): 
2022-01-22 18:30:15.151360 (MainThread): Completed successfully
2022-01-22 18:30:15.152358 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2022-01-22 18:30:15.152358 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4B7A3EE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4B7BC4C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4B7BC4F0>]}
2022-01-22 18:30:15.153355 (MainThread): Flushing usage events
2022-01-22 18:32:29.310901 (MainThread): Running with dbt=0.21.1
2022-01-22 18:32:29.451495 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-22 18:32:29.451495 (MainThread): Tracking: tracking
2022-01-22 18:32:29.467116 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002313115C850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023131264190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023131264A90>]}
2022-01-22 18:32:29.482738 (MainThread): Partial parsing not enabled
2022-01-22 18:32:29.529600 (MainThread): Parsing macros\adapters.sql
2022-01-22 18:32:29.576463 (MainThread): Parsing macros\catalog.sql
2022-01-22 18:32:29.576463 (MainThread): Parsing macros\relations.sql
2022-01-22 18:32:29.576463 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-22 18:32:29.576463 (MainThread): Parsing macros\core.sql
2022-01-22 18:32:29.592086 (MainThread): Parsing macros\adapters\common.sql
2022-01-22 18:32:29.685816 (MainThread): Parsing macros\etc\datetime.sql
2022-01-22 18:32:29.701437 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-22 18:32:29.701437 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-22 18:32:29.701437 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-22 18:32:29.701437 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-22 18:32:29.701437 (MainThread): Parsing macros\etc\query.sql
2022-01-22 18:32:29.701437 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-22 18:32:29.717059 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-22 18:32:29.732716 (MainThread): Parsing macros\materializations\test.sql
2022-01-22 18:32:29.732716 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-22 18:32:29.763922 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-22 18:32:29.763922 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-22 18:32:29.779543 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-22 18:32:29.826406 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-22 18:32:29.857647 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-22 18:32:29.920134 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-22 18:32:29.920134 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-22 18:32:29.966997 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-22 18:32:29.966997 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-22 18:32:29.982618 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-22 18:32:29.982618 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-22 18:32:29.998241 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-22 18:32:29.998241 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-22 18:32:29.998241 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-22 18:32:30.326293 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:32:30.341914 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:32:30.341914 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:32:30.357536 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:32:30.357536 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:32:30.357536 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:32:30.357536 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:32:30.357536 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:32:30.420023 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:32:30.420023 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:32:30.420023 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:32:30.435640 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:32:30.435640 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:32:30.435640 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:32:30.451262 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:32:30.451262 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:32:30.482501 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2d16c533-e0fa-4f0f-9dfa-aa99d75718b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002312F8A3070>]}
2022-01-22 18:32:30.498123 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-22 18:32:30.498123 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2d16c533-e0fa-4f0f-9dfa-aa99d75718b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002312F8A3A90>]}
2022-01-22 18:32:30.498123 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-01-22 18:32:30.498123 (MainThread): 
2022-01-22 18:32:30.498123 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:32:30.498123 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:32:30.513742 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:32:30.513742 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:32:30.513742 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-22 18:32:30.620725 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.11 seconds
2022-01-22 18:32:30.620725 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:32:30.620725 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:32:30.620725 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:32:30.620725 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:32:30.620725 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 18:32:30.714453 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.09 seconds
2022-01-22 18:32:30.714453 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:32:30.714453 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:32:30.714453 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:32:30.714453 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."dwh_dwh""
2022-01-22 18:32:30.730071 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:32:30.730071 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: BEGIN
2022-01-22 18:32:30.730071 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 18:32:30.792558 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.06 seconds
2022-01-22 18:32:30.792558 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:32:30.792558 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_dwh_dwh"} */
create schema if not exists "dwh_dwh"
2022-01-22 18:32:30.792558 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2022-01-22 18:32:30.792558 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: COMMIT
2022-01-22 18:32:30.792558 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:32:30.792558 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: COMMIT
2022-01-22 18:32:30.792558 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:32:30.808178 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: Close
2022-01-22 18:32:30.808178 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:32:30.808178 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:32:30.808178 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."dwh_examples""
2022-01-22 18:32:30.808178 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:32:30.808178 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: BEGIN
2022-01-22 18:32:30.808178 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 18:32:30.870663 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.06 seconds
2022-01-22 18:32:30.870663 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:32:30.870663 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_dwh_examples"} */
create schema if not exists "dwh_examples"
2022-01-22 18:32:30.870663 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2022-01-22 18:32:30.886285 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: COMMIT
2022-01-22 18:32:30.886285 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:32:30.886285 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: COMMIT
2022-01-22 18:32:30.886285 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:32:30.886285 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: Close
2022-01-22 18:32:30.886285 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:32:30.901910 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:32:30.901910 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: BEGIN
2022-01-22 18:32:30.901910 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-22 18:32:30.964391 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.06 seconds
2022-01-22 18:32:30.964391 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:32:30.964391 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_dwh'
  
2022-01-22 18:32:30.964391 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.00 seconds
2022-01-22 18:32:30.964391 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: ROLLBACK
2022-01-22 18:32:30.980016 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: Close
2022-01-22 18:32:30.980016 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:32:30.980016 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:32:30.980016 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: BEGIN
2022-01-22 18:32:30.980016 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-22 18:32:31.042498 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.06 seconds
2022-01-22 18:32:31.042498 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:32:31.042498 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_examples'
  
2022-01-22 18:32:31.058119 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.02 seconds
2022-01-22 18:32:31.058119 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: ROLLBACK
2022-01-22 18:32:31.058119 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: Close
2022-01-22 18:32:31.058119 (MainThread): Using postgres connection "master".
2022-01-22 18:32:31.058119 (MainThread): On master: BEGIN
2022-01-22 18:32:31.058119 (MainThread): Opening a new connection, currently in state init
2022-01-22 18:32:31.120604 (MainThread): SQL status: BEGIN in 0.06 seconds
2022-01-22 18:32:31.120604 (MainThread): Using postgres connection "master".
2022-01-22 18:32:31.120604 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-22 18:32:31.636108 (MainThread): SQL status: SELECT 43 in 0.52 seconds
2022-01-22 18:32:31.636108 (MainThread): On master: ROLLBACK
2022-01-22 18:32:31.651733 (MainThread): Using postgres connection "master".
2022-01-22 18:32:31.651733 (MainThread): On master: BEGIN
2022-01-22 18:32:31.651733 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-22 18:32:31.651733 (MainThread): On master: COMMIT
2022-01-22 18:32:31.651733 (MainThread): Using postgres connection "master".
2022-01-22 18:32:31.651733 (MainThread): On master: COMMIT
2022-01-22 18:32:31.651733 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:32:31.651733 (MainThread): On master: Close
2022-01-22 18:32:31.651733 (MainThread): 00:02:31 | Concurrency: 1 threads (target='dev')
2022-01-22 18:32:31.651733 (MainThread): 00:02:31 | 
2022-01-22 18:32:31.651733 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-22 18:32:31.651733 (Thread-1): 00:02:31 | 1 of 4 START table model dwh_dwh.dim_date............................ [RUN]
2022-01-22 18:32:31.651733 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:32:31.651733 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-22 18:32:31.651733 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:32:31.651733 (Thread-1): finished collecting timing info
2022-01-22 18:32:31.706941 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:32:31.706941 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:32:31.706941 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-22 18:32:31.706941 (Thread-1): Opening a new connection, currently in state init
2022-01-22 18:32:31.785049 (Thread-1): SQL status: BEGIN in 0.08 seconds
2022-01-22 18:32:31.785049 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:32:31.785049 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-22 18:32:32.059457 (Thread-1): SQL status: SELECT 8059 in 0.27 seconds
2022-01-22 18:32:32.075076 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:32:32.075076 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-22 18:32:32.075076 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:32:32.090703 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:32:32.090703 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:32:32.090703 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:32:32.122073 (Thread-1): SQL status: COMMIT in 0.03 seconds
2022-01-22 18:32:32.137597 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:32:32.137597 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh_dwh"."dim_date__dbt_backup" cascade
2022-01-22 18:32:32.137597 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:32:32.137597 (Thread-1): finished collecting timing info
2022-01-22 18:32:32.137597 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-22 18:32:32.137597 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d16c533-e0fa-4f0f-9dfa-aa99d75718b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231313A1FA0>]}
2022-01-22 18:32:32.137597 (Thread-1): 00:02:32 | 1 of 4 OK created table model dwh_dwh.dim_date....................... [SELECT 8059 in 0.49s]
2022-01-22 18:32:32.137597 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-22 18:32:32.137597 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-22 18:32:32.137597 (Thread-1): 00:02:32 | 2 of 4 START table model dwh_examples.hello_world.................... [RUN]
2022-01-22 18:32:32.137597 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:32:32.137597 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-22 18:32:32.137597 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:32:32.137597 (Thread-1): finished collecting timing info
2022-01-22 18:32:32.153217 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:32:32.153217 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:32:32.153217 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-22 18:32:32.153217 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:32:32.240778 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:32:32.240778 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:32:32.240778 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-22 18:32:32.434515 (Thread-1): SQL status: SELECT 599 in 0.19 seconds
2022-01-22 18:32:32.434515 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:32:32.434515 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-22 18:32:32.450136 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:32:32.450136 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:32:32.450136 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:32:32.450136 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:32:32.543860 (Thread-1): SQL status: COMMIT in 0.09 seconds
2022-01-22 18:32:32.543860 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:32:32.543860 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh_examples"."hello_world__dbt_backup" cascade
2022-01-22 18:32:32.543860 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:32:32.559483 (Thread-1): finished collecting timing info
2022-01-22 18:32:32.559483 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-22 18:32:32.559483 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d16c533-e0fa-4f0f-9dfa-aa99d75718b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231313E5130>]}
2022-01-22 18:32:32.559483 (Thread-1): 00:02:32 | 2 of 4 OK created table model dwh_examples.hello_world............... [SELECT 599 in 0.42s]
2022-01-22 18:32:32.559483 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-22 18:32:32.559483 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:32:32.559483 (Thread-1): 00:02:32 | 3 of 4 START table model dwh_examples.my_first_dbt_model............. [RUN]
2022-01-22 18:32:32.559483 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:32:32.559483 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:32:32.559483 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:32:32.559483 (Thread-1): finished collecting timing info
2022-01-22 18:32:32.575106 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:32:32.575106 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:32:32.575106 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-22 18:32:32.575106 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:32:32.631996 (Thread-1): SQL status: BEGIN in 0.06 seconds
2022-01-22 18:32:32.647618 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:32:32.647618 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-22 18:32:32.647618 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2022-01-22 18:32:32.647618 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:32:32.647618 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-22 18:32:32.647618 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:32:32.647618 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:32:32.647618 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:32:32.647618 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:32:32.663238 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-22 18:32:32.663238 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:32:32.663238 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-22 18:32:32.663238 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:32:32.663238 (Thread-1): finished collecting timing info
2022-01-22 18:32:32.663238 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-22 18:32:32.663238 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d16c533-e0fa-4f0f-9dfa-aa99d75718b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002313123FBB0>]}
2022-01-22 18:32:32.663238 (Thread-1): 00:02:32 | 3 of 4 OK created table model dwh_examples.my_first_dbt_model........ [SELECT 2 in 0.10s]
2022-01-22 18:32:32.663238 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:32:32.663238 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:32:32.663238 (Thread-1): 00:02:32 | 4 of 4 START table model dwh_examples.my_second_dbt_model............ [RUN]
2022-01-22 18:32:32.663238 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:32:32.663238 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:32:32.663238 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:32:32.678863 (Thread-1): finished collecting timing info
2022-01-22 18:32:32.678863 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:32:32.678863 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:32:32.678863 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-22 18:32:32.678863 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:32:32.824729 (Thread-1): SQL status: BEGIN in 0.15 seconds
2022-01-22 18:32:32.824729 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:32:32.824729 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh_examples"."my_first_dbt_model"
where id = 1
  );
2022-01-22 18:32:32.840347 (Thread-1): SQL status: SELECT 1 in 0.02 seconds
2022-01-22 18:32:32.840347 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:32:32.840347 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-22 18:32:32.855968 (Thread-1): SQL status: ALTER TABLE in 0.02 seconds
2022-01-22 18:32:32.855968 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:32:32.855968 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:32:32.855968 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:32:32.855968 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:32:32.855968 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:32:32.855968 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-22 18:32:32.855968 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:32:32.871592 (Thread-1): finished collecting timing info
2022-01-22 18:32:32.871592 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-22 18:32:32.871592 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d16c533-e0fa-4f0f-9dfa-aa99d75718b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231313A1FA0>]}
2022-01-22 18:32:32.871592 (Thread-1): 00:02:32 | 4 of 4 OK created table model dwh_examples.my_second_dbt_model....... [SELECT 1 in 0.21s]
2022-01-22 18:32:32.871592 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:32:32.871592 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:32:32.871592 (MainThread): Using postgres connection "master".
2022-01-22 18:32:32.871592 (MainThread): On master: BEGIN
2022-01-22 18:32:32.871592 (MainThread): Opening a new connection, currently in state closed
2022-01-22 18:32:32.965316 (MainThread): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:32:32.980938 (MainThread): On master: COMMIT
2022-01-22 18:32:32.980938 (MainThread): Using postgres connection "master".
2022-01-22 18:32:32.980938 (MainThread): On master: COMMIT
2022-01-22 18:32:32.980938 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:32:32.980938 (MainThread): On master: Close
2022-01-22 18:32:32.980938 (MainThread): 00:02:32 | 
2022-01-22 18:32:32.980938 (MainThread): 00:02:32 | Finished running 4 table models in 2.48s.
2022-01-22 18:32:32.980938 (MainThread): Connection 'master' was properly closed.
2022-01-22 18:32:32.980938 (MainThread): Connection 'create_sakila_wh_dwh_examples' was properly closed.
2022-01-22 18:32:32.980938 (MainThread): Connection 'list_sakila_wh_dwh_examples' was properly closed.
2022-01-22 18:32:32.980938 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-22 18:32:32.996563 (MainThread): 
2022-01-22 18:32:32.996563 (MainThread): Completed successfully
2022-01-22 18:32:32.996563 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2022-01-22 18:32:32.996563 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231313E1C40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231313E1C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231313E1CD0>]}
2022-01-22 18:32:32.996563 (MainThread): Flushing usage events
2022-01-22 18:35:16.842193 (MainThread): Running with dbt=0.21.1
2022-01-22 18:35:16.980296 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-22 18:35:16.980296 (MainThread): Tracking: tracking
2022-01-22 18:35:17.058402 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAA600CA60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAA6114F70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAA61145E0>]}
2022-01-22 18:35:17.064909 (MainThread): Partial parsing not enabled
2022-01-22 18:35:17.127404 (MainThread): Parsing macros\adapters.sql
2022-01-22 18:35:17.165151 (MainThread): Parsing macros\catalog.sql
2022-01-22 18:35:17.165151 (MainThread): Parsing macros\relations.sql
2022-01-22 18:35:17.165151 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-22 18:35:17.180780 (MainThread): Parsing macros\core.sql
2022-01-22 18:35:17.180780 (MainThread): Parsing macros\adapters\common.sql
2022-01-22 18:35:17.312273 (MainThread): Parsing macros\etc\datetime.sql
2022-01-22 18:35:17.327896 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-22 18:35:17.327896 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-22 18:35:17.327896 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-22 18:35:17.343562 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-22 18:35:17.343562 (MainThread): Parsing macros\etc\query.sql
2022-01-22 18:35:17.343562 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-22 18:35:17.343562 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-22 18:35:17.365717 (MainThread): Parsing macros\materializations\test.sql
2022-01-22 18:35:17.381382 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-22 18:35:17.397004 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-22 18:35:17.397004 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-22 18:35:17.428247 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-22 18:35:17.466000 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-22 18:35:17.512907 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-22 18:35:17.559774 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-22 18:35:17.566285 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-22 18:35:17.597574 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-22 18:35:17.597574 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-22 18:35:17.613194 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-22 18:35:17.613194 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-22 18:35:17.628817 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-22 18:35:17.628817 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-22 18:35:17.628817 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-22 18:35:17.960943 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:35:17.967456 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:35:17.983088 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:35:17.983088 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:35:17.983088 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:35:17.983088 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:35:17.998707 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:35:17.998707 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:35:18.045612 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:35:18.045612 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:35:18.061224 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:35:18.061224 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:35:18.067737 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:35:18.067737 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:35:18.067737 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:35:18.067737 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:35:18.098990 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '29849e61-1865-4c36-9222-c443181df902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAA60F30A0>]}
2022-01-22 18:35:18.114609 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-22 18:35:18.114609 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '29849e61-1865-4c36-9222-c443181df902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAA60F3B80>]}
2022-01-22 18:35:18.114609 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-01-22 18:35:18.114609 (MainThread): 
2022-01-22 18:35:18.114609 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:35:18.130234 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:35:18.145853 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:35:18.145853 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:35:18.145853 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-22 18:35:18.368191 (ThreadPoolExecutor-0_0): SQL status: SELECT 7 in 0.22 seconds
2022-01-22 18:35:18.368191 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:35:18.368191 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:35:18.368191 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:35:18.368191 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:35:18.368191 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 18:35:18.499685 (ThreadPoolExecutor-0_0): SQL status: SELECT 7 in 0.13 seconds
2022-01-22 18:35:18.499685 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:35:18.515306 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:35:18.515306 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:35:18.515306 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: BEGIN
2022-01-22 18:35:18.515306 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-22 18:35:18.749626 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.23 seconds
2022-01-22 18:35:18.749626 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:35:18.749626 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_dwh'
  
2022-01-22 18:35:18.749626 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2022-01-22 18:35:18.765246 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: ROLLBACK
2022-01-22 18:35:18.765246 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: Close
2022-01-22 18:35:18.765246 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:35:18.765246 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:35:18.765246 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: BEGIN
2022-01-22 18:35:18.765246 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-22 18:35:18.827733 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.06 seconds
2022-01-22 18:35:18.827733 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:35:18.827733 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_examples'
  
2022-01-22 18:35:18.843356 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.02 seconds
2022-01-22 18:35:18.843356 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: ROLLBACK
2022-01-22 18:35:18.843356 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: Close
2022-01-22 18:35:18.843356 (MainThread): Using postgres connection "master".
2022-01-22 18:35:18.843356 (MainThread): On master: BEGIN
2022-01-22 18:35:18.843356 (MainThread): Opening a new connection, currently in state init
2022-01-22 18:35:18.921461 (MainThread): SQL status: BEGIN in 0.08 seconds
2022-01-22 18:35:18.921461 (MainThread): Using postgres connection "master".
2022-01-22 18:35:18.921461 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-22 18:35:19.530690 (MainThread): SQL status: SELECT 43 in 0.61 seconds
2022-01-22 18:35:19.530690 (MainThread): On master: ROLLBACK
2022-01-22 18:35:19.530690 (MainThread): Using postgres connection "master".
2022-01-22 18:35:19.530690 (MainThread): On master: BEGIN
2022-01-22 18:35:19.530690 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-22 18:35:19.530690 (MainThread): On master: COMMIT
2022-01-22 18:35:19.530690 (MainThread): Using postgres connection "master".
2022-01-22 18:35:19.530690 (MainThread): On master: COMMIT
2022-01-22 18:35:19.530690 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:35:19.530690 (MainThread): On master: Close
2022-01-22 18:35:19.530690 (MainThread): 00:05:19 | Concurrency: 1 threads (target='dev')
2022-01-22 18:35:19.530690 (MainThread): 00:05:19 | 
2022-01-22 18:35:19.546315 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-22 18:35:19.546315 (Thread-1): 00:05:19 | 1 of 4 START table model dwh_dwh.dim_date............................ [RUN]
2022-01-22 18:35:19.546315 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:35:19.546315 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-22 18:35:19.546315 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:35:19.546315 (Thread-1): finished collecting timing info
2022-01-22 18:35:19.619043 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:35:19.634664 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:35:19.634664 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-22 18:35:19.634664 (Thread-1): Opening a new connection, currently in state init
2022-01-22 18:35:19.721677 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:35:19.721677 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:35:19.721677 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-22 18:35:20.002926 (Thread-1): SQL status: SELECT 8059 in 0.28 seconds
2022-01-22 18:35:20.018482 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:35:20.018482 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-22 18:35:20.018482 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:35:20.018482 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:35:20.018482 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-22 18:35:20.018482 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:35:20.049725 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:35:20.049725 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:35:20.049725 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:35:20.049725 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:35:20.065346 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:35:20.065346 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh_dwh"."dim_date__dbt_backup" cascade
2022-01-22 18:35:20.096707 (Thread-1): SQL status: DROP TABLE in 0.03 seconds
2022-01-22 18:35:20.096707 (Thread-1): finished collecting timing info
2022-01-22 18:35:20.096707 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-22 18:35:20.096707 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29849e61-1865-4c36-9222-c443181df902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAA6288AC0>]}
2022-01-22 18:35:20.096707 (Thread-1): 00:05:20 | 1 of 4 OK created table model dwh_dwh.dim_date....................... [SELECT 8059 in 0.55s]
2022-01-22 18:35:20.096707 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-22 18:35:20.096707 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-22 18:35:20.096707 (Thread-1): 00:05:20 | 2 of 4 START view model dwh_examples.hello_world..................... [RUN]
2022-01-22 18:35:20.096707 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:35:20.112211 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-22 18:35:20.112211 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:35:20.112211 (Thread-1): finished collecting timing info
2022-01-22 18:35:20.159075 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:35:20.159075 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:35:20.159075 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-22 18:35:20.159075 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:35:20.252803 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:35:20.252803 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:35:20.252803 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */

  create view "sakila_wh"."dwh_examples"."hello_world__dbt_tmp" as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );

2022-01-22 18:35:20.361474 (Thread-1): SQL status: CREATE VIEW in 0.11 seconds
2022-01-22 18:35:20.361474 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:35:20.361474 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world" rename to "hello_world__dbt_backup"
2022-01-22 18:35:20.361474 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:35:20.361474 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:35:20.361474 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-22 18:35:20.361474 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:35:20.377088 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:35:20.377088 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:35:20.377088 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:35:20.377088 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:35:20.377088 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:35:20.377088 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh_examples"."hello_world__dbt_backup" cascade
2022-01-22 18:35:20.392709 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-01-22 18:35:20.392709 (Thread-1): finished collecting timing info
2022-01-22 18:35:20.392709 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-22 18:35:20.392709 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29849e61-1865-4c36-9222-c443181df902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAA474E940>]}
2022-01-22 18:35:20.392709 (Thread-1): 00:05:20 | 2 of 4 OK created view model dwh_examples.hello_world................ [CREATE VIEW in 0.30s]
2022-01-22 18:35:20.392709 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-22 18:35:20.392709 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:35:20.408332 (Thread-1): 00:05:20 | 3 of 4 START table model dwh_examples.my_first_dbt_model............. [RUN]
2022-01-22 18:35:20.408332 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:35:20.408332 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:35:20.408332 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:35:20.408332 (Thread-1): finished collecting timing info
2022-01-22 18:35:20.423954 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:35:20.423954 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:35:20.423954 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-22 18:35:20.423954 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:35:20.539833 (Thread-1): SQL status: BEGIN in 0.12 seconds
2022-01-22 18:35:20.540830 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:35:20.541826 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-22 18:35:20.542985 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2022-01-22 18:35:20.542985 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:35:20.542985 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-22 18:35:20.542985 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:35:20.558609 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:35:20.558609 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-22 18:35:20.558609 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:35:20.558609 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:35:20.558609 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:35:20.558609 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:35:20.558609 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:35:20.574229 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:35:20.574229 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-22 18:35:20.574229 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:35:20.574229 (Thread-1): finished collecting timing info
2022-01-22 18:35:20.574229 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-22 18:35:20.574229 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29849e61-1865-4c36-9222-c443181df902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAA62475B0>]}
2022-01-22 18:35:20.589850 (Thread-1): 00:05:20 | 3 of 4 OK created table model dwh_examples.my_first_dbt_model........ [SELECT 2 in 0.17s]
2022-01-22 18:35:20.589850 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:35:20.589850 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:35:20.589850 (Thread-1): 00:05:20 | 4 of 4 START view model dwh_examples.my_second_dbt_model............. [RUN]
2022-01-22 18:35:20.589850 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:35:20.589850 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:35:20.589850 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:35:20.589850 (Thread-1): finished collecting timing info
2022-01-22 18:35:20.605502 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:35:20.605502 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:35:20.605502 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-22 18:35:20.605502 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:35:20.694906 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:35:20.694906 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:35:20.694906 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */

  create view "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh_examples"."my_first_dbt_model"
where id = 1
  );

2022-01-22 18:35:20.710526 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2022-01-22 18:35:20.710526 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:35:20.710526 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-22 18:35:20.726150 (Thread-1): SQL status: ALTER TABLE in 0.02 seconds
2022-01-22 18:35:20.726150 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:35:20.726150 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-22 18:35:20.726150 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:35:20.726150 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:35:20.726150 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:35:20.726150 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:35:20.726150 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:35:20.741770 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:35:20.741770 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-22 18:35:20.741770 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:35:20.741770 (Thread-1): finished collecting timing info
2022-01-22 18:35:20.757391 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-22 18:35:20.757391 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29849e61-1865-4c36-9222-c443181df902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAA62475B0>]}
2022-01-22 18:35:20.757391 (Thread-1): 00:05:20 | 4 of 4 OK created view model dwh_examples.my_second_dbt_model........ [CREATE VIEW in 0.17s]
2022-01-22 18:35:20.757391 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:35:20.757391 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:35:20.757391 (MainThread): Using postgres connection "master".
2022-01-22 18:35:20.757391 (MainThread): On master: BEGIN
2022-01-22 18:35:20.757391 (MainThread): Opening a new connection, currently in state closed
2022-01-22 18:35:20.835496 (MainThread): SQL status: BEGIN in 0.08 seconds
2022-01-22 18:35:20.835496 (MainThread): On master: COMMIT
2022-01-22 18:35:20.851118 (MainThread): Using postgres connection "master".
2022-01-22 18:35:20.851118 (MainThread): On master: COMMIT
2022-01-22 18:35:20.851118 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:35:20.851118 (MainThread): On master: Close
2022-01-22 18:35:20.851118 (MainThread): 00:05:20 | 
2022-01-22 18:35:20.851118 (MainThread): 00:05:20 | Finished running 2 table models, 2 view models in 2.74s.
2022-01-22 18:35:20.851118 (MainThread): Connection 'master' was properly closed.
2022-01-22 18:35:20.851118 (MainThread): Connection 'list_sakila_wh' was properly closed.
2022-01-22 18:35:20.851118 (MainThread): Connection 'list_sakila_wh_dwh_examples' was properly closed.
2022-01-22 18:35:20.851118 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-22 18:35:20.866741 (MainThread): 
2022-01-22 18:35:20.866741 (MainThread): Completed successfully
2022-01-22 18:35:20.866741 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2022-01-22 18:35:20.866741 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAA62E71C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAA62E7130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAA62E79A0>]}
2022-01-22 18:35:20.866741 (MainThread): Flushing usage events
2022-01-22 18:38:38.256475 (MainThread): Running with dbt=0.21.1
2022-01-22 18:38:38.397103 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-22 18:38:38.397103 (MainThread): Tracking: tracking
2022-01-22 18:38:38.412689 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021733FACAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000217340B5AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000217340B54F0>]}
2022-01-22 18:38:38.428306 (MainThread): Partial parsing not enabled
2022-01-22 18:38:38.499267 (MainThread): Parsing macros\adapters.sql
2022-01-22 18:38:38.577374 (MainThread): Parsing macros\catalog.sql
2022-01-22 18:38:38.577374 (MainThread): Parsing macros\relations.sql
2022-01-22 18:38:38.577374 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-22 18:38:38.593033 (MainThread): Parsing macros\core.sql
2022-01-22 18:38:38.593033 (MainThread): Parsing macros\adapters\common.sql
2022-01-22 18:38:38.717973 (MainThread): Parsing macros\etc\datetime.sql
2022-01-22 18:38:38.717973 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-22 18:38:38.733592 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-22 18:38:38.733592 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-22 18:38:38.733592 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-22 18:38:38.733592 (MainThread): Parsing macros\etc\query.sql
2022-01-22 18:38:38.733592 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-22 18:38:38.749248 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-22 18:38:38.764868 (MainThread): Parsing macros\materializations\test.sql
2022-01-22 18:38:38.764868 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-22 18:38:38.796073 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-22 18:38:38.796073 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-22 18:38:38.811697 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-22 18:38:38.842977 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-22 18:38:38.905423 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-22 18:38:38.983566 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-22 18:38:38.983566 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-22 18:38:39.014772 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-22 18:38:39.030393 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-22 18:38:39.030393 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-22 18:38:39.046016 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-22 18:38:39.046016 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-22 18:38:39.061638 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-22 18:38:39.061638 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-22 18:38:39.389718 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:38:39.405346 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:38:39.405346 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:38:39.420964 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:38:39.420964 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:38:39.420964 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:38:39.420964 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:38:39.436588 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:38:39.467833 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:38:39.467833 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:38:39.483452 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:38:39.483452 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:38:39.483452 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:38:39.483452 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:38:39.499033 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:38:39.499033 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:38:39.530277 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4659cee9-afe2-49de-976e-00e1caed01be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002173408DEE0>]}
2022-01-22 18:38:39.539329 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-22 18:38:39.539329 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4659cee9-afe2-49de-976e-00e1caed01be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002173408D7C0>]}
2022-01-22 18:38:39.554949 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-01-22 18:38:39.554949 (MainThread): 
2022-01-22 18:38:39.554949 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:38:39.554949 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:38:39.570584 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:38:39.570584 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:38:39.570584 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-22 18:38:39.686401 (ThreadPoolExecutor-0_0): SQL status: SELECT 7 in 0.12 seconds
2022-01-22 18:38:39.686401 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:38:39.686401 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:38:39.686401 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:38:39.686401 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:38:39.686401 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 18:38:39.811372 (ThreadPoolExecutor-0_0): SQL status: SELECT 7 in 0.12 seconds
2022-01-22 18:38:39.811372 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:38:39.811372 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:38:39.826994 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:38:39.826994 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: BEGIN
2022-01-22 18:38:39.826994 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-22 18:38:39.905100 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.08 seconds
2022-01-22 18:38:39.905100 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:38:39.905100 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_dwh'
  
2022-01-22 18:38:39.920722 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.02 seconds
2022-01-22 18:38:39.920722 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: ROLLBACK
2022-01-22 18:38:39.920722 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: Close
2022-01-22 18:38:39.920722 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:38:39.920722 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:38:39.920722 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: BEGIN
2022-01-22 18:38:39.920722 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-22 18:38:39.983209 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.06 seconds
2022-01-22 18:38:39.983209 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:38:39.983209 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_examples'
  
2022-01-22 18:38:39.998829 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.02 seconds
2022-01-22 18:38:39.998829 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: ROLLBACK
2022-01-22 18:38:39.998829 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: Close
2022-01-22 18:38:39.998829 (MainThread): Using postgres connection "master".
2022-01-22 18:38:39.998829 (MainThread): On master: BEGIN
2022-01-22 18:38:40.014451 (MainThread): Opening a new connection, currently in state init
2022-01-22 18:38:40.076935 (MainThread): SQL status: BEGIN in 0.06 seconds
2022-01-22 18:38:40.076935 (MainThread): Using postgres connection "master".
2022-01-22 18:38:40.076935 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-22 18:38:40.670581 (MainThread): SQL status: SELECT 47 in 0.59 seconds
2022-01-22 18:38:40.670581 (MainThread): On master: ROLLBACK
2022-01-22 18:38:40.670581 (MainThread): Using postgres connection "master".
2022-01-22 18:38:40.670581 (MainThread): On master: BEGIN
2022-01-22 18:38:40.670581 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-22 18:38:40.670581 (MainThread): On master: COMMIT
2022-01-22 18:38:40.670581 (MainThread): Using postgres connection "master".
2022-01-22 18:38:40.670581 (MainThread): On master: COMMIT
2022-01-22 18:38:40.670581 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:38:40.686168 (MainThread): On master: Close
2022-01-22 18:38:40.686168 (MainThread): 00:08:40 | Concurrency: 1 threads (target='dev')
2022-01-22 18:38:40.686168 (MainThread): 00:08:40 | 
2022-01-22 18:38:40.686168 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-22 18:38:40.686168 (Thread-1): 00:08:40 | 1 of 4 START view model dwh_dwh.dim_date............................. [RUN]
2022-01-22 18:38:40.686168 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:38:40.686168 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-22 18:38:40.686168 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:38:40.686168 (Thread-1): finished collecting timing info
2022-01-22 18:38:40.733031 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:38:40.733031 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:38:40.733031 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-22 18:38:40.733031 (Thread-1): Opening a new connection, currently in state init
2022-01-22 18:38:40.823495 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:38:40.823495 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:38:40.823495 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */

  create view "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp" as (
    
with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );

2022-01-22 18:38:40.870358 (Thread-1): SQL status: CREATE VIEW in 0.05 seconds
2022-01-22 18:38:40.870358 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:38:40.870358 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-22 18:38:40.885983 (Thread-1): SQL status: ALTER TABLE in 0.02 seconds
2022-01-22 18:38:40.885983 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:38:40.885983 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-22 18:38:40.885983 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:38:40.885983 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:38:40.901607 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:38:40.901607 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:38:40.917262 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-22 18:38:40.917262 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:38:40.917262 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh_dwh"."dim_date__dbt_backup" cascade
2022-01-22 18:38:40.979718 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-22 18:38:40.979718 (Thread-1): finished collecting timing info
2022-01-22 18:38:40.979718 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-22 18:38:40.979718 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4659cee9-afe2-49de-976e-00e1caed01be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002173422CAF0>]}
2022-01-22 18:38:40.979718 (Thread-1): 00:08:40 | 1 of 4 OK created view model dwh_dwh.dim_date........................ [CREATE VIEW in 0.29s]
2022-01-22 18:38:40.995334 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-22 18:38:40.995334 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-22 18:38:40.995334 (Thread-1): 00:08:40 | 2 of 4 START table model dwh_examples.hello_world.................... [RUN]
2022-01-22 18:38:40.995334 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:38:40.995334 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-22 18:38:40.995334 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:38:40.995334 (Thread-1): finished collecting timing info
2022-01-22 18:38:41.054426 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:38:41.054426 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:38:41.054426 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-22 18:38:41.054426 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:38:41.170597 (Thread-1): SQL status: BEGIN in 0.12 seconds
2022-01-22 18:38:41.170597 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:38:41.170597 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-22 18:38:41.279939 (Thread-1): SQL status: SELECT 599 in 0.11 seconds
2022-01-22 18:38:41.295561 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:38:41.295561 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world" rename to "hello_world__dbt_backup"
2022-01-22 18:38:41.295561 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:38:41.295561 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:38:41.295561 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-22 18:38:41.295561 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:38:41.311184 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:38:41.311184 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:38:41.311184 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:38:41.342431 (Thread-1): SQL status: COMMIT in 0.03 seconds
2022-01-22 18:38:41.358047 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:38:41.358047 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop view if exists "sakila_wh"."dwh_examples"."hello_world__dbt_backup" cascade
2022-01-22 18:38:41.358047 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2022-01-22 18:38:41.358047 (Thread-1): finished collecting timing info
2022-01-22 18:38:41.358047 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-22 18:38:41.373674 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4659cee9-afe2-49de-976e-00e1caed01be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002173422C040>]}
2022-01-22 18:38:41.373674 (Thread-1): 00:08:41 | 2 of 4 OK created table model dwh_examples.hello_world............... [SELECT 599 in 0.36s]
2022-01-22 18:38:41.373674 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-22 18:38:41.373674 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:38:41.373674 (Thread-1): 00:08:41 | 3 of 4 START table model dwh_examples.my_first_dbt_model............. [RUN]
2022-01-22 18:38:41.373674 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:38:41.373674 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:38:41.389295 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:38:41.389295 (Thread-1): finished collecting timing info
2022-01-22 18:38:41.389295 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:38:41.404914 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:38:41.404914 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-22 18:38:41.404914 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:38:41.493764 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:38:41.493764 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:38:41.493764 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-22 18:38:41.525006 (Thread-1): SQL status: SELECT 2 in 0.02 seconds
2022-01-22 18:38:41.525006 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:38:41.525006 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-22 18:38:41.525006 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:38:41.525006 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:38:41.525006 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-22 18:38:41.525006 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:38:41.540629 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:38:41.540629 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:38:41.540629 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:38:41.540629 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:38:41.540629 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:38:41.540629 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-22 18:38:41.556249 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-01-22 18:38:41.556249 (Thread-1): finished collecting timing info
2022-01-22 18:38:41.556249 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-22 18:38:41.556249 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4659cee9-afe2-49de-976e-00e1caed01be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021733FA6640>]}
2022-01-22 18:38:41.556249 (Thread-1): 00:08:41 | 3 of 4 OK created table model dwh_examples.my_first_dbt_model........ [SELECT 2 in 0.18s]
2022-01-22 18:38:41.556249 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:38:41.556249 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:38:41.556249 (Thread-1): 00:08:41 | 4 of 4 START table model dwh_examples.my_second_dbt_model............ [RUN]
2022-01-22 18:38:41.556249 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:38:41.556249 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:38:41.571870 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:38:41.571870 (Thread-1): finished collecting timing info
2022-01-22 18:38:41.571870 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:38:41.571870 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:38:41.571870 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-22 18:38:41.571870 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:38:41.665604 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:38:41.665604 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:38:41.665604 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh_examples"."my_first_dbt_model"
where id = 1
  );
2022-01-22 18:38:41.681221 (Thread-1): SQL status: SELECT 1 in 0.02 seconds
2022-01-22 18:38:41.681221 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:38:41.681221 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-22 18:38:41.681221 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:38:41.681221 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:38:41.681221 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:38:41.681221 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:38:41.696840 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-22 18:38:41.712460 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:38:41.712460 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-22 18:38:41.712460 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:38:41.712460 (Thread-1): finished collecting timing info
2022-01-22 18:38:41.712460 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-22 18:38:41.712460 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4659cee9-afe2-49de-976e-00e1caed01be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021733FA6640>]}
2022-01-22 18:38:41.712460 (Thread-1): 00:08:41 | 4 of 4 OK created table model dwh_examples.my_second_dbt_model....... [SELECT 1 in 0.16s]
2022-01-22 18:38:41.712460 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:38:41.728083 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:38:41.728083 (MainThread): Using postgres connection "master".
2022-01-22 18:38:41.728083 (MainThread): On master: BEGIN
2022-01-22 18:38:41.728083 (MainThread): Opening a new connection, currently in state closed
2022-01-22 18:38:41.790568 (MainThread): SQL status: BEGIN in 0.06 seconds
2022-01-22 18:38:41.790568 (MainThread): On master: COMMIT
2022-01-22 18:38:41.790568 (MainThread): Using postgres connection "master".
2022-01-22 18:38:41.790568 (MainThread): On master: COMMIT
2022-01-22 18:38:41.790568 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:38:41.790568 (MainThread): On master: Close
2022-01-22 18:38:41.790568 (MainThread): 00:08:41 | 
2022-01-22 18:38:41.790568 (MainThread): 00:08:41 | Finished running 1 view model, 3 table models in 2.24s.
2022-01-22 18:38:41.790568 (MainThread): Connection 'master' was properly closed.
2022-01-22 18:38:41.790568 (MainThread): Connection 'list_sakila_wh' was properly closed.
2022-01-22 18:38:41.790568 (MainThread): Connection 'list_sakila_wh_dwh_examples' was properly closed.
2022-01-22 18:38:41.790568 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-22 18:38:41.806190 (MainThread): 
2022-01-22 18:38:41.806190 (MainThread): Completed successfully
2022-01-22 18:38:41.806190 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2022-01-22 18:38:41.806190 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002173417A400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002172E59FB20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021734272760>]}
2022-01-22 18:38:41.806190 (MainThread): Flushing usage events
2022-01-22 18:39:40.773869 (MainThread): Running with dbt=0.21.1
2022-01-22 18:39:40.898849 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-22 18:39:40.914469 (MainThread): Tracking: tracking
2022-01-22 18:39:40.930047 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1BD2CAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1BE35C70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1BE35AF0>]}
2022-01-22 18:39:40.945711 (MainThread): Partial parsing not enabled
2022-01-22 18:39:41.008155 (MainThread): Parsing macros\adapters.sql
2022-01-22 18:39:41.070641 (MainThread): Parsing macros\catalog.sql
2022-01-22 18:39:41.070641 (MainThread): Parsing macros\relations.sql
2022-01-22 18:39:41.070641 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-22 18:39:41.070641 (MainThread): Parsing macros\core.sql
2022-01-22 18:39:41.086262 (MainThread): Parsing macros\adapters\common.sql
2022-01-22 18:39:41.226855 (MainThread): Parsing macros\etc\datetime.sql
2022-01-22 18:39:41.258099 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-22 18:39:41.258099 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-22 18:39:41.258099 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-22 18:39:41.258099 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-22 18:39:41.273719 (MainThread): Parsing macros\etc\query.sql
2022-01-22 18:39:41.273719 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-22 18:39:41.273719 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-22 18:39:41.289342 (MainThread): Parsing macros\materializations\test.sql
2022-01-22 18:39:41.304967 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-22 18:39:41.336210 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-22 18:39:41.351867 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-22 18:39:41.367485 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-22 18:39:41.429967 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-22 18:39:41.492422 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-22 18:39:41.554905 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-22 18:39:41.554905 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-22 18:39:41.601771 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-22 18:39:41.633050 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-22 18:39:41.633050 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-22 18:39:41.648636 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-22 18:39:41.664254 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-22 18:39:41.664254 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-22 18:39:41.664254 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-22 18:39:42.070416 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:39:42.086030 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:39:42.086030 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:39:42.101647 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:39:42.101647 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:39:42.101647 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:39:42.117274 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:39:42.117274 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:39:42.179753 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:39:42.195376 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:39:42.195376 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:39:42.210996 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:39:42.210996 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:39:42.210996 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:39:42.210996 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:39:42.226617 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:39:42.242237 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '13364969-5189-4fd2-aff5-935289206cf8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1BE251C0>]}
2022-01-22 18:39:42.257860 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-22 18:39:42.257860 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '13364969-5189-4fd2-aff5-935289206cf8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1BE257F0>]}
2022-01-22 18:39:42.257860 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-01-22 18:39:42.273480 (MainThread): 
2022-01-22 18:39:42.273480 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:39:42.283707 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:39:42.316114 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:39:42.316114 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:39:42.316114 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-22 18:39:42.456707 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.14 seconds
2022-01-22 18:39:42.456707 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:39:42.456707 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:39:42.472327 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:39:42.472327 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:39:42.472327 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 18:39:42.566054 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.09 seconds
2022-01-22 18:39:42.566054 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:39:42.566054 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:39:42.566054 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:39:42.566054 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."dwh_dwh""
2022-01-22 18:39:42.581676 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:39:42.597316 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: BEGIN
2022-01-22 18:39:42.597316 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.06 seconds
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_dwh_dwh"} */
create schema if not exists "dwh_dwh"
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: COMMIT
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_dwh".
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: COMMIT
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: Close
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."dwh_examples""
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: BEGIN
2022-01-22 18:39:42.675404 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 18:39:42.769133 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:39:42.769133 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:39:42.769133 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_dwh_examples"} */
create schema if not exists "dwh_examples"
2022-01-22 18:39:42.769133 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2022-01-22 18:39:42.769133 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: COMMIT
2022-01-22 18:39:42.769133 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_examples".
2022-01-22 18:39:42.769133 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: COMMIT
2022-01-22 18:39:42.769133 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:39:42.769133 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_examples: Close
2022-01-22 18:39:42.784754 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:39:42.784754 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:39:42.784754 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: BEGIN
2022-01-22 18:39:42.784754 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-22 18:39:42.862861 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.08 seconds
2022-01-22 18:39:42.862861 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:39:42.862861 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_dwh'
  
2022-01-22 18:39:42.878480 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.02 seconds
2022-01-22 18:39:42.878480 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: ROLLBACK
2022-01-22 18:39:42.878480 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: Close
2022-01-22 18:39:42.878480 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:39:42.894116 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:39:42.894116 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: BEGIN
2022-01-22 18:39:42.894116 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-22 18:39:42.972214 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.08 seconds
2022-01-22 18:39:42.972214 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:39:42.972214 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_examples'
  
2022-01-22 18:39:42.972214 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.00 seconds
2022-01-22 18:39:42.972214 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: ROLLBACK
2022-01-22 18:39:42.972214 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: Close
2022-01-22 18:39:42.987831 (MainThread): Using postgres connection "master".
2022-01-22 18:39:42.987831 (MainThread): On master: BEGIN
2022-01-22 18:39:42.987831 (MainThread): Opening a new connection, currently in state init
2022-01-22 18:39:43.175286 (MainThread): SQL status: BEGIN in 0.19 seconds
2022-01-22 18:39:43.175286 (MainThread): Using postgres connection "master".
2022-01-22 18:39:43.175286 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-22 18:39:43.800142 (MainThread): SQL status: SELECT 43 in 0.62 seconds
2022-01-22 18:39:43.800142 (MainThread): On master: ROLLBACK
2022-01-22 18:39:43.800142 (MainThread): Using postgres connection "master".
2022-01-22 18:39:43.800142 (MainThread): On master: BEGIN
2022-01-22 18:39:43.800142 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-22 18:39:43.800142 (MainThread): On master: COMMIT
2022-01-22 18:39:43.800142 (MainThread): Using postgres connection "master".
2022-01-22 18:39:43.800142 (MainThread): On master: COMMIT
2022-01-22 18:39:43.800142 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:39:43.800142 (MainThread): On master: Close
2022-01-22 18:39:43.800142 (MainThread): 00:09:43 | Concurrency: 1 threads (target='dev')
2022-01-22 18:39:43.800142 (MainThread): 00:09:43 | 
2022-01-22 18:39:43.815761 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-22 18:39:43.815761 (Thread-1): 00:09:43 | 1 of 4 START view model dwh_dwh.dim_date............................. [RUN]
2022-01-22 18:39:43.815761 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:39:43.815761 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-22 18:39:43.815761 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:39:43.815761 (Thread-1): finished collecting timing info
2022-01-22 18:39:43.862627 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:39:43.862627 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:39:43.862627 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-22 18:39:43.862627 (Thread-1): Opening a new connection, currently in state init
2022-01-22 18:39:43.970748 (Thread-1): SQL status: BEGIN in 0.11 seconds
2022-01-22 18:39:43.970748 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:39:43.970748 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */

  create view "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp" as (
    
with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );

2022-01-22 18:39:43.986370 (Thread-1): SQL status: CREATE VIEW in 0.02 seconds
2022-01-22 18:39:44.001997 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:39:44.001997 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-22 18:39:44.001997 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:39:44.017613 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:39:44.017613 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:39:44.017613 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:39:44.017613 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:39:44.033234 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:39:44.033234 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop view if exists "sakila_wh"."dwh_dwh"."dim_date__dbt_backup" cascade
2022-01-22 18:39:44.033234 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2022-01-22 18:39:44.033234 (Thread-1): finished collecting timing info
2022-01-22 18:39:44.033234 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-22 18:39:44.048857 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13364969-5189-4fd2-aff5-935289206cf8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1BFFCFD0>]}
2022-01-22 18:39:44.048857 (Thread-1): 00:09:44 | 1 of 4 OK created view model dwh_dwh.dim_date........................ [CREATE VIEW in 0.23s]
2022-01-22 18:39:44.048857 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-22 18:39:44.048857 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-22 18:39:44.048857 (Thread-1): 00:09:44 | 2 of 4 START table model dwh_examples.hello_world.................... [RUN]
2022-01-22 18:39:44.048857 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:39:44.048857 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-22 18:39:44.048857 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:39:44.048857 (Thread-1): finished collecting timing info
2022-01-22 18:39:44.123552 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:39:44.123552 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:39:44.123552 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-22 18:39:44.123552 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:39:44.226523 (Thread-1): SQL status: BEGIN in 0.10 seconds
2022-01-22 18:39:44.226523 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:39:44.273388 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-22 18:39:44.460856 (Thread-1): SQL status: SELECT 599 in 0.19 seconds
2022-01-22 18:39:44.460856 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:39:44.460856 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-22 18:39:44.460856 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:39:44.492088 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:39:44.492088 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:39:44.492088 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:39:44.492088 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:39:44.507714 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:39:44.507714 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh_examples"."hello_world__dbt_backup" cascade
2022-01-22 18:39:44.507714 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:39:44.507714 (Thread-1): finished collecting timing info
2022-01-22 18:39:44.507714 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-22 18:39:44.507714 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13364969-5189-4fd2-aff5-935289206cf8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1BED4FA0>]}
2022-01-22 18:39:44.507714 (Thread-1): 00:09:44 | 2 of 4 OK created table model dwh_examples.hello_world............... [SELECT 599 in 0.46s]
2022-01-22 18:39:44.507714 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-22 18:39:44.507714 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:39:44.507714 (Thread-1): 00:09:44 | 3 of 4 START table model dwh_examples.my_first_dbt_model............. [RUN]
2022-01-22 18:39:44.523332 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:39:44.523332 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:39:44.523332 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:39:44.523332 (Thread-1): finished collecting timing info
2022-01-22 18:39:44.538961 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:39:44.538961 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:39:44.538961 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-22 18:39:44.538961 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:39:44.742028 (Thread-1): SQL status: BEGIN in 0.20 seconds
2022-01-22 18:39:44.742028 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:39:44.742028 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-22 18:39:44.757649 (Thread-1): SQL status: SELECT 2 in 0.02 seconds
2022-01-22 18:39:44.757649 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:39:44.757649 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-22 18:39:44.757649 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:39:44.773272 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:39:44.773272 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:39:44.773272 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:39:44.773272 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:39:44.773272 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:39:44.773272 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-22 18:39:44.773272 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:39:44.773272 (Thread-1): finished collecting timing info
2022-01-22 18:39:44.788892 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-22 18:39:44.788892 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13364969-5189-4fd2-aff5-935289206cf8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1BE18E80>]}
2022-01-22 18:39:44.788892 (Thread-1): 00:09:44 | 3 of 4 OK created table model dwh_examples.my_first_dbt_model........ [SELECT 2 in 0.27s]
2022-01-22 18:39:44.788892 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:39:44.788892 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:39:44.788892 (Thread-1): 00:09:44 | 4 of 4 START table model dwh_examples.my_second_dbt_model............ [RUN]
2022-01-22 18:39:44.788892 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:39:44.788892 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:39:44.804512 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:39:44.804512 (Thread-1): finished collecting timing info
2022-01-22 18:39:44.804512 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:39:44.804512 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:39:44.804512 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-22 18:39:44.804512 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:39:44.924525 (Thread-1): SQL status: BEGIN in 0.12 seconds
2022-01-22 18:39:44.924525 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:39:44.924525 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh_examples"."my_first_dbt_model"
where id = 1
  );
2022-01-22 18:39:44.940147 (Thread-1): SQL status: SELECT 1 in 0.02 seconds
2022-01-22 18:39:44.940147 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:39:44.940147 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-22 18:39:44.940147 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:39:44.940147 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:39:44.955767 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:39:44.955767 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:39:44.955767 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:39:44.955767 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:39:44.955767 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-22 18:39:44.955767 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:39:44.955767 (Thread-1): finished collecting timing info
2022-01-22 18:39:44.955767 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-22 18:39:44.971388 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13364969-5189-4fd2-aff5-935289206cf8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1BE10A00>]}
2022-01-22 18:39:44.971388 (Thread-1): 00:09:44 | 4 of 4 OK created table model dwh_examples.my_second_dbt_model....... [SELECT 1 in 0.18s]
2022-01-22 18:39:44.971388 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:39:44.971388 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:39:44.971388 (MainThread): Using postgres connection "master".
2022-01-22 18:39:44.971388 (MainThread): On master: BEGIN
2022-01-22 18:39:44.971388 (MainThread): Opening a new connection, currently in state closed
2022-01-22 18:39:45.080740 (MainThread): SQL status: BEGIN in 0.11 seconds
2022-01-22 18:39:45.080740 (MainThread): On master: COMMIT
2022-01-22 18:39:45.080740 (MainThread): Using postgres connection "master".
2022-01-22 18:39:45.080740 (MainThread): On master: COMMIT
2022-01-22 18:39:45.080740 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:39:45.080740 (MainThread): On master: Close
2022-01-22 18:39:45.080740 (MainThread): 00:09:45 | 
2022-01-22 18:39:45.080740 (MainThread): 00:09:45 | Finished running 1 view model, 3 table models in 2.81s.
2022-01-22 18:39:45.080740 (MainThread): Connection 'master' was properly closed.
2022-01-22 18:39:45.080740 (MainThread): Connection 'create_sakila_wh_dwh_examples' was properly closed.
2022-01-22 18:39:45.096359 (MainThread): Connection 'list_sakila_wh_dwh_examples' was properly closed.
2022-01-22 18:39:45.096359 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-22 18:39:45.096359 (MainThread): 
2022-01-22 18:39:45.096359 (MainThread): Completed successfully
2022-01-22 18:39:45.096359 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2022-01-22 18:39:45.096359 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1BCFDF40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1BCFDEE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1BCFDC10>]}
2022-01-22 18:39:45.111980 (MainThread): Flushing usage events
2022-01-22 18:45:35.636490 (MainThread): Running with dbt=0.21.1
2022-01-22 18:45:35.792708 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-22 18:45:35.824010 (MainThread): Tracking: tracking
2022-01-22 18:45:35.855191 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66A62CAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66A7346D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66A734AF0>]}
2022-01-22 18:45:35.886885 (MainThread): Partial parsing not enabled
2022-01-22 18:45:35.964992 (MainThread): Parsing macros\adapters.sql
2022-01-22 18:45:36.028189 (MainThread): Parsing macros\catalog.sql
2022-01-22 18:45:36.028189 (MainThread): Parsing macros\relations.sql
2022-01-22 18:45:36.043810 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-22 18:45:36.043810 (MainThread): Parsing macros\core.sql
2022-01-22 18:45:36.059433 (MainThread): Parsing macros\adapters\common.sql
2022-01-22 18:45:36.153194 (MainThread): Parsing macros\etc\datetime.sql
2022-01-22 18:45:36.168821 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-22 18:45:36.168821 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-22 18:45:36.184440 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-22 18:45:36.184440 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-22 18:45:36.184440 (MainThread): Parsing macros\etc\query.sql
2022-01-22 18:45:36.184440 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-22 18:45:36.184440 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-22 18:45:36.215645 (MainThread): Parsing macros\materializations\test.sql
2022-01-22 18:45:36.215645 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-22 18:45:36.246889 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-22 18:45:36.246889 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-22 18:45:36.278133 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-22 18:45:36.309374 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-22 18:45:36.340653 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-22 18:45:36.403141 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-22 18:45:36.403141 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-22 18:45:36.434380 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-22 18:45:36.450001 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-22 18:45:36.450001 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-22 18:45:36.465622 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-22 18:45:36.465622 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-22 18:45:36.465622 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-22 18:45:36.481245 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-22 18:45:36.824879 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:45:36.824879 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:36.840503 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:45:36.840503 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:36.840503 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:45:36.856124 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:36.856124 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:45:36.856124 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:36.856124 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-22 18:45:36.918734 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:36.996749 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:36.996749 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:37.012379 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:37.012379 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:37.012379 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:37.012379 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:37.027992 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:37.027992 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-22 18:45:37.043616 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a12ac6bd-d14c-4ab8-8633-ea37d34cd96e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66A618E50>]}
2022-01-22 18:45:37.074822 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-22 18:45:37.074822 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a12ac6bd-d14c-4ab8-8633-ea37d34cd96e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66A7A2AF0>]}
2022-01-22 18:45:37.074822 (MainThread): Found 5 models, 8 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-01-22 18:45:37.084233 (MainThread): 
2022-01-22 18:45:37.084233 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:45:37.084233 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:45:37.099855 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:45:37.099855 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:45:37.099855 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-22 18:45:37.372121 (ThreadPoolExecutor-0_0): SQL status: SELECT 7 in 0.27 seconds
2022-01-22 18:45:37.372121 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:45:37.372121 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-22 18:45:37.372121 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-22 18:45:37.372121 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-22 18:45:37.372121 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-22 18:45:37.465835 (ThreadPoolExecutor-0_0): SQL status: SELECT 7 in 0.09 seconds
2022-01-22 18:45:37.465835 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-22 18:45:37.465835 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:45:37.481457 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:45:37.481457 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: BEGIN
2022-01-22 18:45:37.481457 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-22 18:45:37.575250 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.09 seconds
2022-01-22 18:45:37.575250 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-22 18:45:37.575250 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_dwh'
  
2022-01-22 18:45:37.653341 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.08 seconds
2022-01-22 18:45:37.653341 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: ROLLBACK
2022-01-22 18:45:37.668916 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: Close
2022-01-22 18:45:37.668916 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:45:37.668916 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:45:37.668916 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: BEGIN
2022-01-22 18:45:37.668916 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-22 18:45:37.747054 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.08 seconds
2022-01-22 18:45:37.747054 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-22 18:45:37.747054 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_examples'
  
2022-01-22 18:45:37.747054 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2022-01-22 18:45:37.747054 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: ROLLBACK
2022-01-22 18:45:37.762649 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: Close
2022-01-22 18:45:37.762649 (MainThread): Using postgres connection "master".
2022-01-22 18:45:37.762649 (MainThread): On master: BEGIN
2022-01-22 18:45:37.762649 (MainThread): Opening a new connection, currently in state init
2022-01-22 18:45:37.840748 (MainThread): SQL status: BEGIN in 0.08 seconds
2022-01-22 18:45:37.840748 (MainThread): Using postgres connection "master".
2022-01-22 18:45:37.840748 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-22 18:45:38.465598 (MainThread): SQL status: SELECT 43 in 0.62 seconds
2022-01-22 18:45:38.465598 (MainThread): On master: ROLLBACK
2022-01-22 18:45:38.465598 (MainThread): Using postgres connection "master".
2022-01-22 18:45:38.465598 (MainThread): On master: BEGIN
2022-01-22 18:45:38.465598 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-22 18:45:38.465598 (MainThread): On master: COMMIT
2022-01-22 18:45:38.465598 (MainThread): Using postgres connection "master".
2022-01-22 18:45:38.465598 (MainThread): On master: COMMIT
2022-01-22 18:45:38.465598 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:45:38.465598 (MainThread): On master: Close
2022-01-22 18:45:38.465598 (MainThread): 00:15:38 | Concurrency: 1 threads (target='dev')
2022-01-22 18:45:38.465598 (MainThread): 00:15:38 | 
2022-01-22 18:45:38.481257 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-22 18:45:38.481257 (Thread-1): 00:15:38 | 1 of 5 START view model dwh_dwh.dim_date............................. [RUN]
2022-01-22 18:45:38.481257 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:45:38.481257 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-22 18:45:38.481257 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:45:38.481257 (Thread-1): finished collecting timing info
2022-01-22 18:45:38.528089 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-22 18:45:38.543707 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:45:38.543707 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-22 18:45:38.543707 (Thread-1): Opening a new connection, currently in state init
2022-01-22 18:45:38.617634 (Thread-1): SQL status: BEGIN in 0.07 seconds
2022-01-22 18:45:38.618632 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:45:38.618998 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */

  create view "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp" as (
    
with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );

2022-01-22 18:45:39.114232 (Thread-1): SQL status: CREATE VIEW in 0.49 seconds
2022-01-22 18:45:39.129823 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:45:39.129823 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-22 18:45:39.192390 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-22 18:45:39.207923 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:45:39.207923 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-22 18:45:39.207923 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:45:39.223541 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:45:39.223541 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:45:39.239162 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-22 18:45:39.239162 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:45:39.239162 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-22 18:45:39.239162 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop view if exists "sakila_wh"."dwh_dwh"."dim_date__dbt_backup" cascade
2022-01-22 18:45:39.254868 (Thread-1): SQL status: DROP VIEW in 0.02 seconds
2022-01-22 18:45:39.270403 (Thread-1): finished collecting timing info
2022-01-22 18:45:39.270403 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-22 18:45:39.270403 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a12ac6bd-d14c-4ab8-8633-ea37d34cd96e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66A8C7E50>]}
2022-01-22 18:45:39.270403 (Thread-1): 00:15:39 | 1 of 5 OK created view model dwh_dwh.dim_date........................ [CREATE VIEW in 0.79s]
2022-01-22 18:45:39.270403 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-22 18:45:39.270403 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-22 18:45:39.270403 (Thread-1): 00:15:39 | 2 of 5 START table model dwh_examples.hello_world.................... [RUN]
2022-01-22 18:45:39.270403 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:45:39.270403 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-22 18:45:39.270403 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:45:39.270403 (Thread-1): finished collecting timing info
2022-01-22 18:45:39.310318 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-22 18:45:39.310318 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:45:39.310318 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-22 18:45:39.310318 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:45:39.456957 (Thread-1): SQL status: BEGIN in 0.15 seconds
2022-01-22 18:45:39.456957 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:45:39.456957 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-22 18:45:39.597546 (Thread-1): SQL status: SELECT 599 in 0.14 seconds
2022-01-22 18:45:39.597546 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:45:39.597546 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world" rename to "hello_world__dbt_backup"
2022-01-22 18:45:39.597546 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:45:39.597546 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:45:39.597546 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-22 18:45:39.597546 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:45:39.613170 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:45:39.613170 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:45:39.613170 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-22 18:45:39.613170 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:45:39.613170 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-22 18:45:39.613170 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh_examples"."hello_world__dbt_backup" cascade
2022-01-22 18:45:39.691277 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-22 18:45:39.706903 (Thread-1): finished collecting timing info
2022-01-22 18:45:39.706903 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-22 18:45:39.706903 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a12ac6bd-d14c-4ab8-8633-ea37d34cd96e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E668D4FA30>]}
2022-01-22 18:45:39.706903 (Thread-1): 00:15:39 | 2 of 5 OK created table model dwh_examples.hello_world............... [SELECT 599 in 0.44s]
2022-01-22 18:45:39.706903 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-22 18:45:39.706903 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:45:39.706903 (Thread-1): 00:15:39 | 3 of 5 START table model dwh_examples.my_first_dbt_model............. [RUN]
2022-01-22 18:45:39.722524 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:45:39.722524 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:45:39.722524 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:45:39.738143 (Thread-1): finished collecting timing info
2022-01-22 18:45:39.738143 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-22 18:45:39.738143 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:45:39.738143 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-22 18:45:39.738143 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:45:39.983638 (Thread-1): SQL status: BEGIN in 0.25 seconds
2022-01-22 18:45:39.983638 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:45:39.983638 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-22 18:45:39.999261 (Thread-1): SQL status: SELECT 2 in 0.02 seconds
2022-01-22 18:45:40.014881 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:45:40.014881 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-22 18:45:40.014881 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:45:40.014881 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:45:40.014881 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-22 18:45:40.014881 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:45:40.030504 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:45:40.030504 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:45:40.030504 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-22 18:45:40.030504 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:45:40.030504 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-22 18:45:40.030504 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-22 18:45:40.046123 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-01-22 18:45:40.046123 (Thread-1): finished collecting timing info
2022-01-22 18:45:40.046123 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-22 18:45:40.046123 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a12ac6bd-d14c-4ab8-8633-ea37d34cd96e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66A7CC7C0>]}
2022-01-22 18:45:40.046123 (Thread-1): 00:15:40 | 3 of 5 OK created table model dwh_examples.my_first_dbt_model........ [SELECT 2 in 0.32s]
2022-01-22 18:45:40.046123 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-22 18:45:40.046123 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-22 18:45:40.046123 (Thread-1): 00:15:40 | 4 of 5 START incremental model dwh_examples.payment_inc.............. [RUN]
2022-01-22 18:45:40.046123 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-22 18:45:40.046123 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-22 18:45:40.046123 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-22 18:45:40.061744 (Thread-1): finished collecting timing info
2022-01-22 18:45:40.167157 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-22 18:45:40.182777 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-22 18:45:40.182777 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-22 18:45:40.182777 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:45:40.424913 (Thread-1): SQL status: BEGIN in 0.24 seconds
2022-01-22 18:45:40.424913 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-22 18:45:40.424913 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      

  create  table "sakila_wh"."dwh_examples"."payment_inc"
  as (
    

select
*,
'2022-01-22 18:45:35' as dbt_time
from
stg.payment
where 1=1




-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-22 18:45:40.893672 (Thread-1): SQL status: SELECT 16049 in 0.47 seconds
2022-01-22 18:45:40.909173 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-22 18:45:40.909173 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-22 18:45:40.909173 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-22 18:45:40.924794 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-22 18:45:40.924794 (Thread-1): finished collecting timing info
2022-01-22 18:45:40.924794 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-22 18:45:40.924794 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a12ac6bd-d14c-4ab8-8633-ea37d34cd96e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66A8C5280>]}
2022-01-22 18:45:40.924794 (Thread-1): 00:15:40 | 4 of 5 OK created incremental model dwh_examples.payment_inc......... [SELECT 16049 in 0.88s]
2022-01-22 18:45:40.924794 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-22 18:45:40.924794 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:45:40.924794 (Thread-1): 00:15:40 | 5 of 5 START table model dwh_examples.my_second_dbt_model............ [RUN]
2022-01-22 18:45:40.924794 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:45:40.924794 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:45:40.924794 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:45:40.924794 (Thread-1): finished collecting timing info
2022-01-22 18:45:40.940417 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-22 18:45:40.940417 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:45:40.940417 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-22 18:45:40.940417 (Thread-1): Opening a new connection, currently in state closed
2022-01-22 18:45:41.051419 (Thread-1): SQL status: BEGIN in 0.11 seconds
2022-01-22 18:45:41.051419 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:45:41.051419 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh_examples"."my_first_dbt_model"
where id = 1
  );
2022-01-22 18:45:41.067040 (Thread-1): SQL status: SELECT 1 in 0.02 seconds
2022-01-22 18:45:41.067040 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:45:41.067040 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-22 18:45:41.067040 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:45:41.067040 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:45:41.067040 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-22 18:45:41.067040 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-22 18:45:41.082664 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:45:41.082664 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:45:41.082664 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-22 18:45:41.082664 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:45:41.082664 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-22 18:45:41.082664 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-22 18:45:41.082664 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-22 18:45:41.098283 (Thread-1): finished collecting timing info
2022-01-22 18:45:41.098283 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-22 18:45:41.098283 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a12ac6bd-d14c-4ab8-8633-ea37d34cd96e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66A7F7A90>]}
2022-01-22 18:45:41.098283 (Thread-1): 00:15:41 | 5 of 5 OK created table model dwh_examples.my_second_dbt_model....... [SELECT 1 in 0.17s]
2022-01-22 18:45:41.098283 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-22 18:45:41.160776 (MainThread): Acquiring new postgres connection "master".
2022-01-22 18:45:41.160776 (MainThread): Using postgres connection "master".
2022-01-22 18:45:41.160776 (MainThread): On master: BEGIN
2022-01-22 18:45:41.160776 (MainThread): Opening a new connection, currently in state closed
2022-01-22 18:45:41.332602 (MainThread): SQL status: BEGIN in 0.17 seconds
2022-01-22 18:45:41.332602 (MainThread): On master: COMMIT
2022-01-22 18:45:41.332602 (MainThread): Using postgres connection "master".
2022-01-22 18:45:41.332602 (MainThread): On master: COMMIT
2022-01-22 18:45:41.332602 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-22 18:45:41.332602 (MainThread): On master: Close
2022-01-22 18:45:41.332602 (MainThread): 00:15:41 | 
2022-01-22 18:45:41.348224 (MainThread): 00:15:41 | Finished running 1 view model, 3 table models, 1 incremental model in 4.25s.
2022-01-22 18:45:41.348224 (MainThread): Connection 'master' was properly closed.
2022-01-22 18:45:41.348224 (MainThread): Connection 'list_sakila_wh' was properly closed.
2022-01-22 18:45:41.348224 (MainThread): Connection 'list_sakila_wh_dwh_examples' was properly closed.
2022-01-22 18:45:41.348224 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-22 18:45:41.363847 (MainThread): 
2022-01-22 18:45:41.363847 (MainThread): Completed successfully
2022-01-22 18:45:41.363847 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-22 18:45:41.363847 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66A859D60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6690A2250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66A70FF40>]}
2022-01-22 18:45:41.363847 (MainThread): Flushing usage events
2022-01-23 07:33:57.542150 (MainThread): Running with dbt=0.21.1
2022-01-23 07:33:58.545385 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-23 07:33:58.561042 (MainThread): Tracking: tracking
2022-01-23 07:33:58.741038 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA8175CAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA81864A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA818644F0>]}
2022-01-23 07:33:58.803560 (MainThread): Partial parsing not enabled
2022-01-23 07:34:00.511613 (MainThread): Parsing macros\adapters.sql
2022-01-23 07:34:00.628923 (MainThread): Parsing macros\catalog.sql
2022-01-23 07:34:00.628923 (MainThread): Parsing macros\relations.sql
2022-01-23 07:34:00.628923 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-23 07:34:00.644552 (MainThread): Parsing macros\core.sql
2022-01-23 07:34:00.644552 (MainThread): Parsing macros\adapters\common.sql
2022-01-23 07:34:00.753902 (MainThread): Parsing macros\etc\datetime.sql
2022-01-23 07:34:00.769524 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-23 07:34:00.769524 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-23 07:34:00.769524 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-23 07:34:00.769524 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-23 07:34:00.769524 (MainThread): Parsing macros\etc\query.sql
2022-01-23 07:34:00.769524 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-23 07:34:00.785180 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-23 07:34:00.800766 (MainThread): Parsing macros\materializations\test.sql
2022-01-23 07:34:00.808777 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-23 07:34:00.840030 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-23 07:34:00.840030 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-23 07:34:00.871273 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-23 07:34:00.918136 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-23 07:34:00.965000 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-23 07:34:01.019948 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-23 07:34:01.035569 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-23 07:34:01.066852 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-23 07:34:01.066852 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-23 07:34:01.082469 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-23 07:34:01.098055 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-23 07:34:01.098055 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-23 07:34:01.098055 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-23 07:34:01.098055 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-23 07:34:01.489135 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 07:34:01.544037 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.559674 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 07:34:01.559674 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.622176 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 07:34:01.653393 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.653393 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 07:34:01.653393 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.669006 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 07:34:01.669006 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.669006 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 07:34:01.684625 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.684625 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 07:34:01.684625 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.684625 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 07:34:01.700246 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.700246 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 07:34:01.708262 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.739516 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.739516 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.755136 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.755136 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.755136 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.770760 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.770760 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.770760 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:34:01.770760 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA81936EB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA819304C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA8197D490>]}
2022-01-23 07:34:01.770760 (MainThread): Flushing usage events
2022-01-23 07:34:05.109915 (MainThread): Connection 'model.sakila_dbt_project.payment_inc' was properly closed.
2022-01-23 07:34:05.109915 (MainThread): Encountered an error:
2022-01-23 07:34:05.125493 (MainThread): Compilation Error in model dim_customer (models\dimensions\dim_customer.sql)
  Model 'model.sakila_dbt_project.dim_customer' (models\dimensions\dim_customer.sql) depends on a source named 'stg.customer' which was not found
2022-01-23 07:34:05.650213 (MainThread): Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 258, in run_from_args
    results = task.run()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 438, in run
    self._runtime_initialize()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 360, in load
    self.process_sources(self.root_project.project_name)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 783, in process_sources
    _process_sources_for_node(self.manifest, current_project, node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 1088, in _process_sources_for_node
    invalid_source_fail_unless_test(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 828, in invalid_source_fail_unless_test
    source_target_not_found(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\exceptions.py", line 618, in source_target_not_found
    raise_compiler_error(msg, model)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\exceptions.py", line 447, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model dim_customer (models\dimensions\dim_customer.sql)
  Model 'model.sakila_dbt_project.dim_customer' (models\dimensions\dim_customer.sql) depends on a source named 'stg.customer' which was not found

2022-01-23 07:35:51.094645 (MainThread): Running with dbt=0.21.1
2022-01-23 07:35:51.243295 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-23 07:35:51.243295 (MainThread): Tracking: tracking
2022-01-23 07:35:51.258876 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000233D19EBA60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000233D1AF5AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000233D1AF5580>]}
2022-01-23 07:35:51.274499 (MainThread): Partial parsing not enabled
2022-01-23 07:35:51.321390 (MainThread): Parsing macros\adapters.sql
2022-01-23 07:35:51.368264 (MainThread): Parsing macros\catalog.sql
2022-01-23 07:35:51.368264 (MainThread): Parsing macros\relations.sql
2022-01-23 07:35:51.368264 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-23 07:35:51.368264 (MainThread): Parsing macros\core.sql
2022-01-23 07:35:51.383847 (MainThread): Parsing macros\adapters\common.sql
2022-01-23 07:35:51.470076 (MainThread): Parsing macros\etc\datetime.sql
2022-01-23 07:35:51.485702 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-23 07:35:51.485702 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-23 07:35:51.501285 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-23 07:35:51.501285 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-23 07:35:51.501285 (MainThread): Parsing macros\etc\query.sql
2022-01-23 07:35:51.501285 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-23 07:35:51.501285 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-23 07:35:51.516905 (MainThread): Parsing macros\materializations\test.sql
2022-01-23 07:35:51.532531 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-23 07:35:51.563806 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-23 07:35:51.563806 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-23 07:35:51.579431 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-23 07:35:51.618760 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-23 07:35:51.649966 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-23 07:35:51.712454 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-23 07:35:51.712454 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-23 07:35:51.743698 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-23 07:35:51.767362 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-23 07:35:51.767362 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-23 07:35:51.782998 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-23 07:35:51.782998 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-23 07:35:51.782998 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-23 07:35:51.782998 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-23 07:35:52.127111 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 07:35:52.158362 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.158362 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 07:35:52.174017 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.174017 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 07:35:52.174017 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.189605 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 07:35:52.189605 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.189605 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 07:35:52.205227 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.205227 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 07:35:52.205227 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.205227 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 07:35:52.220882 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.220882 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 07:35:52.220882 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.220882 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 07:35:52.236470 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.267715 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.283331 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.283331 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.283331 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.298955 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.298955 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.306998 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.306998 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:35:52.306998 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000233D1C05EE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000233D1BBBF40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000233D1C02550>]}
2022-01-23 07:35:52.306998 (MainThread): Flushing usage events
2022-01-23 07:35:55.283052 (MainThread): Connection 'model.sakila_dbt_project.payment_inc' was properly closed.
2022-01-23 07:35:55.284045 (MainThread): Encountered an error:
2022-01-23 07:35:55.285075 (MainThread): Compilation Error in model dim_customer (models\dimensions\dim_customer.sql)
  Model 'model.sakila_dbt_project.dim_customer' (models\dimensions\dim_customer.sql) depends on a source named 'stg.customer' which was not found
2022-01-23 07:35:55.296010 (MainThread): Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 258, in run_from_args
    results = task.run()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 438, in run
    self._runtime_initialize()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 360, in load
    self.process_sources(self.root_project.project_name)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 783, in process_sources
    _process_sources_for_node(self.manifest, current_project, node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 1088, in _process_sources_for_node
    invalid_source_fail_unless_test(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 828, in invalid_source_fail_unless_test
    source_target_not_found(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\exceptions.py", line 618, in source_target_not_found
    raise_compiler_error(msg, model)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\exceptions.py", line 447, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model dim_customer (models\dimensions\dim_customer.sql)
  Model 'model.sakila_dbt_project.dim_customer' (models\dimensions\dim_customer.sql) depends on a source named 'stg.customer' which was not found

2022-01-23 07:45:11.535694 (MainThread): Running with dbt=0.21.1
2022-01-23 07:45:11.684306 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-23 07:45:11.684306 (MainThread): Tracking: tracking
2022-01-23 07:45:11.699928 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A31CAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A424F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A4242E0>]}
2022-01-23 07:45:11.715548 (MainThread): Partial parsing not enabled
2022-01-23 07:45:11.770475 (MainThread): Parsing macros\adapters.sql
2022-01-23 07:45:11.801672 (MainThread): Parsing macros\catalog.sql
2022-01-23 07:45:11.817293 (MainThread): Parsing macros\relations.sql
2022-01-23 07:45:11.817293 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-23 07:45:11.817293 (MainThread): Parsing macros\core.sql
2022-01-23 07:45:11.817293 (MainThread): Parsing macros\adapters\common.sql
2022-01-23 07:45:11.919070 (MainThread): Parsing macros\etc\datetime.sql
2022-01-23 07:45:11.934729 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-23 07:45:11.934729 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-23 07:45:11.934729 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-23 07:45:11.934729 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-23 07:45:11.934729 (MainThread): Parsing macros\etc\query.sql
2022-01-23 07:45:11.934729 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-23 07:45:11.950351 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-23 07:45:11.965935 (MainThread): Parsing macros\materializations\test.sql
2022-01-23 07:45:11.965935 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-23 07:45:11.997217 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-23 07:45:12.012834 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-23 07:45:12.028462 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-23 07:45:12.059703 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-23 07:45:12.099031 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-23 07:45:12.161483 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-23 07:45:12.177105 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-23 07:45:12.208346 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-23 07:45:12.208346 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-23 07:45:12.224002 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-23 07:45:12.224002 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-23 07:45:12.239623 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-23 07:45:12.239623 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-23 07:45:12.239623 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-23 07:45:12.568187 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 07:45:12.615049 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.623061 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 07:45:12.623061 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.623061 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 07:45:12.638697 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.638697 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 07:45:12.638697 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.638697 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 07:45:12.654348 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.654348 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 07:45:12.654348 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.669968 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 07:45:12.669968 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.669968 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 07:45:12.669968 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.669968 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 07:45:12.685555 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.748043 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.748043 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.748043 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.748043 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.763668 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.763668 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.763668 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.763668 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.763668 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.779290 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.802922 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.802922 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.802922 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.802922 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.802922 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.818555 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:12.834174 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a576685b-6647-45a1-bb5c-587773ffa4ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A5012E0>]}
2022-01-23 07:45:12.906090 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-23 07:45:12.906090 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a576685b-6647-45a1-bb5c-587773ffa4ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A316040>]}
2022-01-23 07:45:12.921635 (MainThread): Found 9 models, 16 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 10 sources, 0 exposures
2022-01-23 07:45:12.921635 (MainThread): 
2022-01-23 07:45:12.921635 (MainThread): Acquiring new postgres connection "master".
2022-01-23 07:45:12.921635 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-23 07:45:12.952837 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-23 07:45:12.952837 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-23 07:45:12.952837 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-23 07:45:13.092320 (ThreadPoolExecutor-0_0): SQL status: SELECT 7 in 0.14 seconds
2022-01-23 07:45:13.107943 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-23 07:45:13.107943 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-23 07:45:13.107943 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-23 07:45:13.107943 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-23 07:45:13.107943 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-23 07:45:13.256562 (ThreadPoolExecutor-0_0): SQL status: SELECT 7 in 0.15 seconds
2022-01-23 07:45:13.256562 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-23 07:45:13.256562 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_examples".
2022-01-23 07:45:13.272183 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-23 07:45:13.272183 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: BEGIN
2022-01-23 07:45:13.272183 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-23 07:45:13.405241 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.13 seconds
2022-01-23 07:45:13.405241 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_examples".
2022-01-23 07:45:13.405241 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_examples'
  
2022-01-23 07:45:13.585201 (ThreadPoolExecutor-1_0): SQL status: SELECT 4 in 0.18 seconds
2022-01-23 07:45:13.585201 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: ROLLBACK
2022-01-23 07:45:13.585201 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_examples: Close
2022-01-23 07:45:13.585201 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_dwh".
2022-01-23 07:45:13.600826 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-23 07:45:13.600826 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: BEGIN
2022-01-23 07:45:13.600826 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-23 07:45:13.702561 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.10 seconds
2022-01-23 07:45:13.702561 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-23 07:45:13.702561 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_dwh'
  
2022-01-23 07:45:13.718190 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.02 seconds
2022-01-23 07:45:13.718190 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: ROLLBACK
2022-01-23 07:45:13.718190 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: Close
2022-01-23 07:45:13.718190 (MainThread): Using postgres connection "master".
2022-01-23 07:45:13.718190 (MainThread): On master: BEGIN
2022-01-23 07:45:13.718190 (MainThread): Opening a new connection, currently in state init
2022-01-23 07:45:13.796297 (MainThread): SQL status: BEGIN in 0.08 seconds
2022-01-23 07:45:13.796297 (MainThread): Using postgres connection "master".
2022-01-23 07:45:13.796297 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-23 07:45:14.633526 (MainThread): SQL status: SELECT 43 in 0.84 seconds
2022-01-23 07:45:14.633526 (MainThread): On master: ROLLBACK
2022-01-23 07:45:14.649147 (MainThread): Using postgres connection "master".
2022-01-23 07:45:14.649147 (MainThread): On master: BEGIN
2022-01-23 07:45:14.649147 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-23 07:45:14.649147 (MainThread): On master: COMMIT
2022-01-23 07:45:14.649147 (MainThread): Using postgres connection "master".
2022-01-23 07:45:14.649147 (MainThread): On master: COMMIT
2022-01-23 07:45:14.649147 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-23 07:45:14.649147 (MainThread): On master: Close
2022-01-23 07:45:14.649147 (MainThread): 13:15:14 | Concurrency: 1 threads (target='dev')
2022-01-23 07:45:14.649147 (MainThread): 13:15:14 | 
2022-01-23 07:45:14.696078 (Thread-1): Began running node model.sakila_dbt_project.dim_customer
2022-01-23 07:45:14.696078 (Thread-1): 13:15:14 | 1 of 9 START incremental model dwh_dwh.dim_customer.................. [RUN]
2022-01-23 07:45:14.696078 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 07:45:14.711601 (Thread-1): Compiling model.sakila_dbt_project.dim_customer
2022-01-23 07:45:14.727220 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-23 07:45:14.727220 (Thread-1): finished collecting timing info
2022-01-23 07:45:14.844727 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-23 07:45:14.844727 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 07:45:14.844727 (Thread-1): On model.sakila_dbt_project.dim_customer: BEGIN
2022-01-23 07:45:14.844727 (Thread-1): Opening a new connection, currently in state init
2022-01-23 07:45:14.938430 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-23 07:45:14.938430 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 07:45:14.938430 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      

  create  table "sakila_wh"."dwh_dwh"."dim_customer"
  as (
    

with customer_base as (

select
 *,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.active::int as active_int,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
  '2022-01-23 07:45:11'::timestamp as dbt_time
from
	"sakila_wh"."stg"."customer" as customer),

  address as (
    select * from "sakila_wh"."stg"."address"
  ),

  city as (
    select * from "sakila_wh"."stg"."city"
  ),

  country as (
    select * from "sakila_wh"."stg"."country"
  )

  select
  customer_base.customer_id,
  customer_base.store_id,
  customer_base.first_name,
  customer_base.last_name,
  customer_base.full_name,
  customer_base.domain,
  customer_base.email,
  customer_base.active_int as active,
  customer_base.active_desc,

  address.address_id,
  address.address,
  city.city_id,
  city.city,
  country.country_id,
  country.country,

  customer_base.create_date,
  customer_base.last_update,
  customer_base.dbt_time

  from
  customer_base

	left join address on 1=1
	and customer_base.address_id =address.address_id

	left join city on 1=1
	and address.city_id = city.city_id

  left join country on 1=1
  and country.country_id = city.country_id

  where 1=1

  
  );
  
2022-01-23 07:45:15.337968 (Thread-1): SQL status: SELECT 599 in 0.40 seconds
2022-01-23 07:45:15.384806 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:15.384806 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 07:45:15.384806 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

        insert into "sakila_wh"."dwh_dwh"."dim_customer"(customer_id) VALUES (-1)
      
2022-01-23 07:45:15.462857 (Thread-1): SQL status: INSERT 0 1 in 0.08 seconds
2022-01-23 07:45:15.462857 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-23 07:45:15.462857 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 07:45:15.462857 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-23 07:45:15.462857 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 07:45:15.478480 (Thread-1): finished collecting timing info
2022-01-23 07:45:15.478480 (Thread-1): On model.sakila_dbt_project.dim_customer: Close
2022-01-23 07:45:15.478480 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a576685b-6647-45a1-bb5c-587773ffa4ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A6167C0>]}
2022-01-23 07:45:15.478480 (Thread-1): 13:15:15 | 1 of 9 OK created incremental model dwh_dwh.dim_customer............. [SELECT 599 in 0.78s]
2022-01-23 07:45:15.478480 (Thread-1): Finished running node model.sakila_dbt_project.dim_customer
2022-01-23 07:45:15.478480 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-23 07:45:15.478480 (Thread-1): 13:15:15 | 2 of 9 START table model dwh_dwh.dim_date............................ [RUN]
2022-01-23 07:45:15.478480 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 07:45:15.478480 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-23 07:45:15.478480 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-23 07:45:15.478480 (Thread-1): finished collecting timing info
2022-01-23 07:45:15.522023 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-23 07:45:15.553263 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 07:45:15.553263 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-23 07:45:15.553263 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 07:45:15.656743 (Thread-1): SQL status: BEGIN in 0.10 seconds
2022-01-23 07:45:15.656743 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 07:45:15.656743 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-23 07:45:16.119774 (Thread-1): SQL status: SELECT 8059 in 0.46 seconds
2022-01-23 07:45:16.119774 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 07:45:16.119774 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-23 07:45:16.182278 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-23 07:45:16.197850 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 07:45:16.197850 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-23 07:45:16.197850 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 07:45:16.197850 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-23 07:45:16.197850 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 07:45:16.197850 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-23 07:45:16.221521 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-23 07:45:16.237162 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 07:45:16.237162 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop view if exists "sakila_wh"."dwh_dwh"."dim_date__dbt_backup" cascade
2022-01-23 07:45:16.330976 (Thread-1): SQL status: DROP VIEW in 0.09 seconds
2022-01-23 07:45:16.346507 (Thread-1): finished collecting timing info
2022-01-23 07:45:16.346507 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-23 07:45:16.346507 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a576685b-6647-45a1-bb5c-587773ffa4ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A402730>]}
2022-01-23 07:45:16.346507 (Thread-1): 13:15:16 | 2 of 9 OK created table model dwh_dwh.dim_date....................... [SELECT 8059 in 0.87s]
2022-01-23 07:45:16.346507 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-23 07:45:16.346507 (Thread-1): Began running node model.sakila_dbt_project.dim_film
2022-01-23 07:45:16.346507 (Thread-1): 13:15:16 | 3 of 9 START incremental model dwh_dwh.dim_film...................... [RUN]
2022-01-23 07:45:16.362133 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 07:45:16.362133 (Thread-1): Compiling model.sakila_dbt_project.dim_film
2022-01-23 07:45:16.377746 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_film"
2022-01-23 07:45:16.377746 (Thread-1): finished collecting timing info
2022-01-23 07:45:16.393366 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_film"
2022-01-23 07:45:16.393366 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 07:45:16.401377 (Thread-1): On model.sakila_dbt_project.dim_film: BEGIN
2022-01-23 07:45:16.401377 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 07:45:16.505138 (Thread-1): SQL status: BEGIN in 0.10 seconds
2022-01-23 07:45:16.505138 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 07:45:16.520759 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      

  create  table "sakila_wh"."dwh_dwh"."dim_film"
  as (
    

with stg_film as (
	select
	*,
	(case
	when length<=75 then 'short'
	when (length>75 and length<=120) then 'medium'
	when length>120 then 'long'
	else 'na' end) as length_desc,
	COALESCE(original_language_id,0) as original_language_id_zero,
	case when POSITION('Trailers' in special_features::varchar)>0 then 1 else 0 end  as has_trailers,
	case when POSITION('Commentaries' in special_features::varchar)>0 then 1 else 0 end  as has_commentaries,
	case when POSITION('Deleted Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_deleted_scenes,
	case when POSITION('Behind the Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_behind_the_scenes,
	'2022-01-23 07:45:11'::timestamp as dbt_time
	from
	"sakila_wh"."stg"."film"
),

language as (
	select * from "sakila_wh"."stg"."language"
),

category as (
	select * from "sakila_wh"."stg"."category"
),

film_category as (
	select * from "sakila_wh"."stg"."film_category"
),

stg_film_1 as (
	select
	stg_film.*,
	language.name as lang_name
	from
	stg_film
	left join language on 1=1
	and stg_film.language_id = language.language_id
),

stg_film_2 as (
	select
		stg_film_1.*,
		category.category_id,
		category.name as category_desc
	from
	stg_film_1

	left join film_category on 1=1
	and stg_film_1.film_id = film_category.film_id

	left join category on 1=1
	and film_category.category_id  = category.category_id
)


select
  film_id,
  title,
  description,
  release_year,
  language_id,
  lang_name,
  original_language_id_zero as original_language_id,
  rental_duration,
  rental_rate,
  length,
  length_desc,
  replacement_cost,
  rating,
  category_id,
  category_desc,
  special_features,
  has_trailers,
  has_commentaries,
  has_behind_the_scenes,
  has_deleted_scenes,
  last_update,
	dbt_time
from
stg_film_2

where 1=1


  );
  
2022-01-23 07:45:16.721751 (Thread-1): SQL status: SELECT 1000 in 0.20 seconds
2022-01-23 07:45:16.721751 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:16.721751 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 07:45:16.721751 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

        insert into "sakila_wh"."dwh_dwh"."dim_film"(film_id) VALUES (-1)
      
2022-01-23 07:45:16.721751 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 07:45:16.721751 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-23 07:45:16.721751 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 07:45:16.721751 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-23 07:45:16.721751 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 07:45:16.721751 (Thread-1): finished collecting timing info
2022-01-23 07:45:16.721751 (Thread-1): On model.sakila_dbt_project.dim_film: Close
2022-01-23 07:45:16.737371 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a576685b-6647-45a1-bb5c-587773ffa4ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A533EB0>]}
2022-01-23 07:45:16.737371 (Thread-1): 13:15:16 | 3 of 9 OK created incremental model dwh_dwh.dim_film................. [SELECT 1000 in 0.39s]
2022-01-23 07:45:16.737371 (Thread-1): Finished running node model.sakila_dbt_project.dim_film
2022-01-23 07:45:16.737371 (Thread-1): Began running node model.sakila_dbt_project.dim_staff
2022-01-23 07:45:16.737371 (Thread-1): 13:15:16 | 4 of 9 START table model dwh_dwh.dim_staff........................... [RUN]
2022-01-23 07:45:16.737371 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 07:45:16.737371 (Thread-1): Compiling model.sakila_dbt_project.dim_staff
2022-01-23 07:45:16.737371 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-23 07:45:16.737371 (Thread-1): finished collecting timing info
2022-01-23 07:45:16.737371 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-23 07:45:16.737371 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 07:45:16.752992 (Thread-1): On model.sakila_dbt_project.dim_staff: BEGIN
2022-01-23 07:45:16.752992 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 07:45:16.855237 (Thread-1): SQL status: BEGIN in 0.10 seconds
2022-01-23 07:45:16.855237 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 07:45:16.855237 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */


  create  table "sakila_wh"."dwh_dwh"."dim_staff__dbt_tmp"
  as (
    

with staff_base as (
select
*,
(case when active::int = 1 then 1 else 0 end) as "active_int",
(case when active::int = 1 then 'yes' else 'no' end) as "active_desc",
'2022-01-23 07:45:11'::timestamp as dbt_time
from
"sakila_wh"."stg"."staff"
)

select
	staff_id,
	first_name,
	last_name,
	email,
  active_int as active,
  active_desc,
	last_update,
  dbt_time
from
	staff_base
  );
2022-01-23 07:45:16.917721 (Thread-1): SQL status: SELECT 2 in 0.06 seconds
2022-01-23 07:45:16.917721 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 07:45:16.917721 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
alter table "sakila_wh"."dwh_dwh"."dim_staff__dbt_tmp" rename to "dim_staff"
2022-01-23 07:45:16.917721 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 07:45:16.933343 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:16.933343 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 07:45:16.933343 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */

        insert into "sakila_wh"."dwh_dwh"."dim_staff"(staff_id) VALUES (-1)
      
2022-01-23 07:45:16.933343 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 07:45:16.933343 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-23 07:45:16.933343 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 07:45:16.933343 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-23 07:45:16.941351 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 07:45:16.941351 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 07:45:16.941351 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
drop table if exists "sakila_wh"."dwh_dwh"."dim_staff__dbt_backup" cascade
2022-01-23 07:45:16.941351 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 07:45:16.941351 (Thread-1): finished collecting timing info
2022-01-23 07:45:16.941351 (Thread-1): On model.sakila_dbt_project.dim_staff: Close
2022-01-23 07:45:16.941351 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a576685b-6647-45a1-bb5c-587773ffa4ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A6358E0>]}
2022-01-23 07:45:16.941351 (Thread-1): 13:15:16 | 4 of 9 OK created table model dwh_dwh.dim_staff...................... [SELECT 2 in 0.20s]
2022-01-23 07:45:16.941351 (Thread-1): Finished running node model.sakila_dbt_project.dim_staff
2022-01-23 07:45:16.941351 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-23 07:45:16.941351 (Thread-1): 13:15:16 | 5 of 9 START table model dwh_examples.hello_world.................... [RUN]
2022-01-23 07:45:16.941351 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 07:45:16.941351 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-23 07:45:16.941351 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-23 07:45:16.941351 (Thread-1): finished collecting timing info
2022-01-23 07:45:16.956979 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-23 07:45:16.956979 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 07:45:16.956979 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-23 07:45:16.956979 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 07:45:17.246158 (Thread-1): SQL status: BEGIN in 0.29 seconds
2022-01-23 07:45:17.246158 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 07:45:17.246158 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-23 07:45:17.332277 (Thread-1): SQL status: SELECT 599 in 0.09 seconds
2022-01-23 07:45:17.332277 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 07:45:17.332277 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world" rename to "hello_world__dbt_backup"
2022-01-23 07:45:17.347900 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 07:45:17.347900 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 07:45:17.347900 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-23 07:45:17.347900 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 07:45:17.347900 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-23 07:45:17.347900 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 07:45:17.347900 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-23 07:45:17.363521 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-23 07:45:17.363521 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 07:45:17.363521 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh_examples"."hello_world__dbt_backup" cascade
2022-01-23 07:45:17.441628 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-23 07:45:17.441628 (Thread-1): finished collecting timing info
2022-01-23 07:45:17.441628 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-23 07:45:17.441628 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a576685b-6647-45a1-bb5c-587773ffa4ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A533F10>]}
2022-01-23 07:45:17.441628 (Thread-1): 13:15:17 | 5 of 9 OK created table model dwh_examples.hello_world............... [SELECT 599 in 0.50s]
2022-01-23 07:45:17.441628 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-23 07:45:17.441628 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-23 07:45:17.441628 (Thread-1): 13:15:17 | 6 of 9 START table model dwh_examples.my_first_dbt_model............. [RUN]
2022-01-23 07:45:17.441628 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 07:45:17.441628 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-23 07:45:17.457249 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-23 07:45:17.457249 (Thread-1): finished collecting timing info
2022-01-23 07:45:17.457249 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-23 07:45:17.457249 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 07:45:17.457249 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-23 07:45:17.457249 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 07:45:17.562878 (Thread-1): SQL status: BEGIN in 0.11 seconds
2022-01-23 07:45:17.562878 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 07:45:17.562878 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-23 07:45:17.594123 (Thread-1): SQL status: SELECT 2 in 0.03 seconds
2022-01-23 07:45:17.594123 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 07:45:17.594123 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-23 07:45:17.609744 (Thread-1): SQL status: ALTER TABLE in 0.02 seconds
2022-01-23 07:45:17.609744 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 07:45:17.609744 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-23 07:45:17.609744 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 07:45:17.609744 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-23 07:45:17.609744 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 07:45:17.609744 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-23 07:45:17.609744 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 07:45:17.625364 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 07:45:17.625364 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-23 07:45:17.640985 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-01-23 07:45:17.640985 (Thread-1): finished collecting timing info
2022-01-23 07:45:17.640985 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-23 07:45:17.640985 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a576685b-6647-45a1-bb5c-587773ffa4ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A533820>]}
2022-01-23 07:45:17.640985 (Thread-1): 13:15:17 | 6 of 9 OK created table model dwh_examples.my_first_dbt_model........ [SELECT 2 in 0.20s]
2022-01-23 07:45:17.640985 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-23 07:45:17.640985 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-23 07:45:17.656608 (Thread-1): 13:15:17 | 7 of 9 START incremental model dwh_examples.payment_inc.............. [RUN]
2022-01-23 07:45:17.656608 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 07:45:17.656608 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-23 07:45:17.660620 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-23 07:45:17.660620 (Thread-1): finished collecting timing info
2022-01-23 07:45:17.660620 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 07:45:17.660620 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

    

  create temporary table "payment_inc__dbt_tmp131517660620"
  as (
    

select
*,
'2022-01-23 07:45:11' as dbt_time
from
stg.payment
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."dwh_examples"."payment_inc")



-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-23 07:45:17.660620 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 07:45:18.012641 (Thread-1): SQL status: SELECT 0 in 0.35 seconds
2022-01-23 07:45:18.020651 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 07:45:18.020651 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-23 07:45:18.020651 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-23 07:45:18.020651 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 07:45:18.020651 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc__dbt_tmp131517660620'
        
      order by ordinal_position

  
2022-01-23 07:45:18.216370 (Thread-1): SQL status: SELECT 7 in 0.20 seconds
2022-01-23 07:45:18.247520 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 07:45:18.247520 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh_examples'
        
      order by ordinal_position

  
2022-01-23 07:45:18.263140 (Thread-1): SQL status: SELECT 7 in 0.02 seconds
2022-01-23 07:45:18.294433 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 07:45:18.294433 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh_examples'
        
      order by ordinal_position

  
2022-01-23 07:45:18.294433 (Thread-1): SQL status: SELECT 7 in 0.00 seconds
2022-01-23 07:45:18.310056 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-23 07:45:18.310056 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 07:45:18.310056 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      delete
    from "sakila_wh"."dwh_examples"."payment_inc"
    where (payment_id) in (
        select (payment_id)
        from "payment_inc__dbt_tmp131517660620"
    );

    insert into "sakila_wh"."dwh_examples"."payment_inc" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time"
       from "payment_inc__dbt_tmp131517660620"
    );
  
2022-01-23 07:45:18.368595 (Thread-1): SQL status: INSERT 0 0 in 0.06 seconds
2022-01-23 07:45:18.368595 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-23 07:45:18.368595 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 07:45:18.368595 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-23 07:45:18.380605 (Thread-1): SQL status: COMMIT in 0.01 seconds
2022-01-23 07:45:18.380605 (Thread-1): finished collecting timing info
2022-01-23 07:45:18.380605 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-23 07:45:18.380605 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a576685b-6647-45a1-bb5c-587773ffa4ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A653D60>]}
2022-01-23 07:45:18.380605 (Thread-1): 13:15:18 | 7 of 9 OK created incremental model dwh_examples.payment_inc......... [INSERT 0 0 in 0.72s]
2022-01-23 07:45:18.380605 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-23 07:45:18.380605 (Thread-1): Began running node model.sakila_dbt_project.dim_store
2022-01-23 07:45:18.380605 (Thread-1): 13:15:18 | 8 of 9 START table model dwh_dwh.dim_store........................... [RUN]
2022-01-23 07:45:18.380605 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 07:45:18.380605 (Thread-1): Compiling model.sakila_dbt_project.dim_store
2022-01-23 07:45:18.396238 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_store"
2022-01-23 07:45:18.396238 (Thread-1): finished collecting timing info
2022-01-23 07:45:18.396238 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_store"
2022-01-23 07:45:18.396238 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 07:45:18.396238 (Thread-1): On model.sakila_dbt_project.dim_store: BEGIN
2022-01-23 07:45:18.396238 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 07:45:18.495859 (Thread-1): SQL status: BEGIN in 0.10 seconds
2022-01-23 07:45:18.495859 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 07:45:18.495859 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */


  create  table "sakila_wh"."dwh_dwh"."dim_store__dbt_tmp"
  as (
    

with stg_store as (
		select
    *,
    '2022-01-23 07:45:11'::timestamp as dbt_time
     from "sakila_wh"."stg"."store"
),

staff as (
 select * from "sakila_wh"."dwh_dwh"."dim_staff"
),

address as (
  select * from "sakila_wh"."stg"."address"
),

city as (
  select * from "sakila_wh"."stg"."city"
),

country as (
  select * from "sakila_wh"."stg"."country"
),
stg_store_1 as (-- add staff
		select
		stg_store.*,
		staff.first_name as staff_first_name,
		staff.last_name as staff_last_name
		from
		stg_store
		left join staff  on 1=1
		and stg_store.manager_staff_id = staff.staff_id
),
stg_store_2 as (-- add adress
		select
		stg_store_1.*,
		address.address,
		city.city_id,
		city.city,
		country.country_id,
		country.country
		from
		stg_store_1

		left join address on 1=1
		and stg_store_1.address_id =address.address_id

		left join city on 1=1
		and address.city_id = city.city_id

		left join country on  1=1
		and city.country_id = country.country_id
)

select
  store_id,
  manager_staff_id,
  staff_first_name,
  staff_last_name,
  address_id,
  address,
  city_id,
  city,
  country_id,
  country,
  last_update,
  dbt_time
from stg_store_2
  );
2022-01-23 07:45:18.511479 (Thread-1): SQL status: SELECT 2 in 0.02 seconds
2022-01-23 07:45:18.527103 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 07:45:18.527103 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
alter table "sakila_wh"."dwh_dwh"."dim_store__dbt_tmp" rename to "dim_store"
2022-01-23 07:45:18.527103 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 07:45:18.527103 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 07:45:18.527103 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 07:45:18.527103 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */

        insert into "sakila_wh"."dwh_dwh"."dim_store"(store_id) VALUES (-1)
      
2022-01-23 07:45:18.542723 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 07:45:18.542723 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-23 07:45:18.542723 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 07:45:18.542723 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-23 07:45:18.542723 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 07:45:18.542723 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 07:45:18.542723 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
drop table if exists "sakila_wh"."dwh_dwh"."dim_store__dbt_backup" cascade
2022-01-23 07:45:18.542723 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 07:45:18.558343 (Thread-1): finished collecting timing info
2022-01-23 07:45:18.558343 (Thread-1): On model.sakila_dbt_project.dim_store: Close
2022-01-23 07:45:18.560353 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a576685b-6647-45a1-bb5c-587773ffa4ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A65C0A0>]}
2022-01-23 07:45:18.560353 (Thread-1): 13:15:18 | 8 of 9 OK created table model dwh_dwh.dim_store...................... [SELECT 2 in 0.18s]
2022-01-23 07:45:18.560353 (Thread-1): Finished running node model.sakila_dbt_project.dim_store
2022-01-23 07:45:18.560353 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-23 07:45:18.560353 (Thread-1): 13:15:18 | 9 of 9 START table model dwh_examples.my_second_dbt_model............ [RUN]
2022-01-23 07:45:18.560353 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 07:45:18.560353 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-23 07:45:18.560353 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-23 07:45:18.560353 (Thread-1): finished collecting timing info
2022-01-23 07:45:18.575981 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-23 07:45:18.575981 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 07:45:18.575981 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-23 07:45:18.575981 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 07:45:18.689088 (Thread-1): SQL status: BEGIN in 0.11 seconds
2022-01-23 07:45:18.689088 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 07:45:18.689088 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh_examples"."my_first_dbt_model"
where id = 1
  );
2022-01-23 07:45:18.720331 (Thread-1): SQL status: SELECT 1 in 0.03 seconds
2022-01-23 07:45:18.720331 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 07:45:18.720331 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-23 07:45:18.720331 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 07:45:18.720331 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 07:45:18.720331 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-23 07:45:18.720331 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 07:45:18.735955 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-23 07:45:18.735955 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 07:45:18.735955 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-23 07:45:18.735955 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 07:45:18.740465 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 07:45:18.740465 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh_examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-23 07:45:18.771721 (Thread-1): SQL status: DROP TABLE in 0.03 seconds
2022-01-23 07:45:18.771721 (Thread-1): finished collecting timing info
2022-01-23 07:45:18.771721 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-23 07:45:18.787340 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a576685b-6647-45a1-bb5c-587773ffa4ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A677430>]}
2022-01-23 07:45:18.787340 (Thread-1): 13:15:18 | 9 of 9 OK created table model dwh_examples.my_second_dbt_model....... [SELECT 1 in 0.23s]
2022-01-23 07:45:18.787340 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-23 07:45:18.802966 (MainThread): Acquiring new postgres connection "master".
2022-01-23 07:45:18.802966 (MainThread): Using postgres connection "master".
2022-01-23 07:45:18.802966 (MainThread): On master: BEGIN
2022-01-23 07:45:18.802966 (MainThread): Opening a new connection, currently in state closed
2022-01-23 07:45:18.982814 (MainThread): SQL status: BEGIN in 0.18 seconds
2022-01-23 07:45:18.982814 (MainThread): On master: COMMIT
2022-01-23 07:45:18.982814 (MainThread): Using postgres connection "master".
2022-01-23 07:45:18.982814 (MainThread): On master: COMMIT
2022-01-23 07:45:18.982814 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-23 07:45:18.982814 (MainThread): On master: Close
2022-01-23 07:45:18.982814 (MainThread): 13:15:18 | 
2022-01-23 07:45:18.982814 (MainThread): 13:15:18 | Finished running 3 incremental models, 6 table models in 6.06s.
2022-01-23 07:45:18.982814 (MainThread): Connection 'master' was properly closed.
2022-01-23 07:45:18.982814 (MainThread): Connection 'list_sakila_wh' was properly closed.
2022-01-23 07:45:18.982814 (MainThread): Connection 'list_sakila_wh_dwh_dwh' was properly closed.
2022-01-23 07:45:18.982814 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-23 07:45:19.014083 (MainThread): 
2022-01-23 07:45:19.014083 (MainThread): Completed successfully
2022-01-23 07:45:19.014083 (MainThread): 
Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
2022-01-23 07:45:19.014083 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A308790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A602A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001955A3161C0>]}
2022-01-23 07:45:19.014083 (MainThread): Flushing usage events
2022-01-23 08:01:56.263898 (MainThread): Running with dbt=0.21.1
2022-01-23 08:01:56.388904 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-23 08:01:56.388904 (MainThread): Tracking: tracking
2022-01-23 08:01:56.420105 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000250FD52CA30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000250FD635CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000250FD635250>]}
2022-01-23 08:01:56.435728 (MainThread): Partial parsing not enabled
2022-01-23 08:01:56.569917 (MainThread): Parsing macros\concat_it.sql
2022-01-23 08:01:56.569917 (MainThread): Parsing macros\delete_from_table.sql
2022-01-23 08:01:56.569917 (MainThread): Parsing macros\generate_schema_name.sql
2022-01-23 08:01:56.569917 (MainThread): Parsing macros\logit.sql
2022-01-23 08:01:56.569917 (MainThread): Parsing macros\adapters.sql
2022-01-23 08:01:56.631073 (MainThread): Parsing macros\catalog.sql
2022-01-23 08:01:56.646694 (MainThread): Parsing macros\relations.sql
2022-01-23 08:01:56.646694 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-23 08:01:56.662331 (MainThread): Parsing macros\core.sql
2022-01-23 08:01:56.662331 (MainThread): Parsing macros\adapters\common.sql
2022-01-23 08:01:56.771665 (MainThread): Parsing macros\etc\datetime.sql
2022-01-23 08:01:56.787286 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-23 08:01:56.787286 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-23 08:01:56.787286 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-23 08:01:56.802908 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-23 08:01:56.802908 (MainThread): Parsing macros\etc\query.sql
2022-01-23 08:01:56.802908 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-23 08:01:56.802908 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-23 08:01:56.818532 (MainThread): Parsing macros\materializations\test.sql
2022-01-23 08:01:56.834193 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-23 08:01:56.849771 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-23 08:01:56.865393 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-23 08:01:56.881014 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-23 08:01:56.912256 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-23 08:01:56.959120 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-23 08:01:57.005985 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-23 08:01:57.005985 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-23 08:01:57.052848 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-23 08:01:57.052848 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-23 08:01:57.068471 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-23 08:01:57.068471 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-23 08:01:57.084092 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-23 08:01:57.084092 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-23 08:01:57.084092 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-23 08:01:57.443383 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:01:57.474626 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.474626 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:01:57.474626 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.490246 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:01:57.490246 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.490246 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:01:57.505869 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.505869 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:01:57.505869 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.521491 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-23 08:01:57.521491 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.521491 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.521491 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test_macro".
2022-01-23 08:01:57.537113 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.537113 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:01:57.537113 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.537113 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:01:57.552737 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.552737 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:01:57.552737 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.552737 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:01:57.568357 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.568357 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:01:57.583980 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.583980 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:01:57.583980 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.583980 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:01:57.599599 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:01:57.615220 (MainThread): Acquiring new postgres connection "analysis.sakila_dbt_project.example".
2022-01-23 08:01:57.630842 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_cost_30".
2022-01-23 08:01:57.646459 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.693327 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.693327 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.693327 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.693327 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.708949 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.708949 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.708949 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.708949 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.724570 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.724570 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.740193 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.740193 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.755813 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.755813 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.755813 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.755813 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.771430 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.771430 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.771430 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.787052 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:01:57.787052 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000250FD708880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000250FD7087C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000250FD708D00>]}
2022-01-23 08:01:57.787052 (MainThread): Flushing usage events
2022-01-23 08:01:58.755658 (MainThread): Connection 'test.sakila_dbt_project.film_cost_30' was properly closed.
2022-01-23 08:01:58.755658 (MainThread): Encountered an error:
2022-01-23 08:01:58.755658 (MainThread): Compilation Error in model film_test (models\example\film_test.sql)
  Model 'model.sakila_dbt_project.film_test' (models\example\film_test.sql) depends on a source named 'stg_example.film' which was not found
2022-01-23 08:01:58.771203 (MainThread): Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\main.py", line 258, in run_from_args
    results = task.run()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 438, in run
    self._runtime_initialize()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 360, in load
    self.process_sources(self.root_project.project_name)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 783, in process_sources
    _process_sources_for_node(self.manifest, current_project, node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 1088, in _process_sources_for_node
    invalid_source_fail_unless_test(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\parser\manifest.py", line 828, in invalid_source_fail_unless_test
    source_target_not_found(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\exceptions.py", line 618, in source_target_not_found
    raise_compiler_error(msg, model)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\exceptions.py", line 447, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model film_test (models\example\film_test.sql)
  Model 'model.sakila_dbt_project.film_test' (models\example\film_test.sql) depends on a source named 'stg_example.film' which was not found

2022-01-23 08:06:04.725014 (MainThread): Running with dbt=0.21.1
2022-01-23 08:06:04.849983 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-23 08:06:04.849983 (MainThread): Tracking: tracking
2022-01-23 08:06:04.865570 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665A3C850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665B45280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665B45A90>]}
2022-01-23 08:06:04.881192 (MainThread): Partial parsing not enabled
2022-01-23 08:06:04.943678 (MainThread): Parsing macros\concat_it.sql
2022-01-23 08:06:04.943678 (MainThread): Parsing macros\delete_from_table.sql
2022-01-23 08:06:04.943678 (MainThread): Parsing macros\generate_schema_name.sql
2022-01-23 08:06:04.943678 (MainThread): Parsing macros\logit.sql
2022-01-23 08:06:04.943678 (MainThread): Parsing macros\adapters.sql
2022-01-23 08:06:04.990576 (MainThread): Parsing macros\catalog.sql
2022-01-23 08:06:04.990576 (MainThread): Parsing macros\relations.sql
2022-01-23 08:06:04.990576 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-23 08:06:04.990576 (MainThread): Parsing macros\core.sql
2022-01-23 08:06:05.006198 (MainThread): Parsing macros\adapters\common.sql
2022-01-23 08:06:05.115510 (MainThread): Parsing macros\etc\datetime.sql
2022-01-23 08:06:05.131136 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-23 08:06:05.146759 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-23 08:06:05.146759 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-23 08:06:05.146759 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-23 08:06:05.146759 (MainThread): Parsing macros\etc\query.sql
2022-01-23 08:06:05.146759 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-23 08:06:05.146759 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-23 08:06:05.177996 (MainThread): Parsing macros\materializations\test.sql
2022-01-23 08:06:05.177996 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-23 08:06:05.209239 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-23 08:06:05.209239 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-23 08:06:05.224897 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-23 08:06:05.256139 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-23 08:06:05.303000 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-23 08:06:05.365453 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-23 08:06:05.365453 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-23 08:06:05.396731 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-23 08:06:05.396731 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-23 08:06:05.412352 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-23 08:06:05.427973 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-23 08:06:05.427973 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-23 08:06:05.427973 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-23 08:06:05.427973 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-23 08:06:05.771610 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:06:05.787230 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.802851 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:06:05.802851 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.802851 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:06:05.818470 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.818470 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:06:05.834093 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.834093 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:06:05.834093 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.834093 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-23 08:06:05.849712 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.849712 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.849712 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test_macro".
2022-01-23 08:06:05.865335 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.865335 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:06:05.865335 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.865335 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:06:05.881031 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.881031 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:06:05.881031 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.881031 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:06:05.881031 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.896617 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:06:05.896617 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.896617 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:06:05.896617 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:05.896617 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:06:05.912238 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:06:05.927862 (MainThread): Acquiring new postgres connection "analysis.sakila_dbt_project.example".
2022-01-23 08:06:05.959063 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_cost_30".
2022-01-23 08:06:05.959063 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.005967 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.005967 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.005967 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.021582 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.021582 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.021582 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.021582 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.021582 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.037206 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.037206 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.068412 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.084033 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.084033 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.084033 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.084033 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.084033 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.115281 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.115281 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.115281 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.130895 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.130895 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.130895 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.146557 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.146557 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:06.235147 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665B1EFA0>]}
2022-01-23 08:06:06.266426 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-23 08:06:06.282010 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665B1E760>]}
2022-01-23 08:06:06.282010 (MainThread): Found 15 models, 25 tests, 0 snapshots, 1 analysis, 166 macros, 0 operations, 0 seed files, 15 sources, 0 exposures
2022-01-23 08:06:06.291503 (MainThread): 
2022-01-23 08:06:06.292670 (MainThread): Acquiring new postgres connection "master".
2022-01-23 08:06:06.292670 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-23 08:06:06.308297 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-23 08:06:06.323913 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-23 08:06:06.323913 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-23 08:06:06.458662 (ThreadPoolExecutor-0_0): SQL status: SELECT 9 in 0.13 seconds
2022-01-23 08:06:06.458662 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-23 08:06:06.458662 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-23 08:06:06.474279 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-23 08:06:06.474279 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-23 08:06:06.474279 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-23 08:06:06.568006 (ThreadPoolExecutor-0_0): SQL status: SELECT 9 in 0.09 seconds
2022-01-23 08:06:06.568006 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-23 08:06:06.568006 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-23 08:06:06.568006 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-23 08:06:06.568006 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-23 08:06:06.568006 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-23 08:06:06.646114 (ThreadPoolExecutor-0_0): SQL status: SELECT 9 in 0.08 seconds
2022-01-23 08:06:06.646114 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-23 08:06:06.646114 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_itamar".
2022-01-23 08:06:06.646114 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_itamar".
2022-01-23 08:06:06.646114 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."itamar""
2022-01-23 08:06:06.661736 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_itamar".
2022-01-23 08:06:06.661736 (ThreadPoolExecutor-0_0): On create_sakila_wh_itamar: BEGIN
2022-01-23 08:06:06.661736 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-23 08:06:06.724219 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.06 seconds
2022-01-23 08:06:06.724219 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_itamar".
2022-01-23 08:06:06.724219 (ThreadPoolExecutor-0_0): On create_sakila_wh_itamar: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_itamar"} */
create schema if not exists "itamar"
2022-01-23 08:06:06.771089 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.05 seconds
2022-01-23 08:06:06.771089 (ThreadPoolExecutor-0_0): On create_sakila_wh_itamar: COMMIT
2022-01-23 08:06:06.771089 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_itamar".
2022-01-23 08:06:06.771089 (ThreadPoolExecutor-0_0): On create_sakila_wh_itamar: COMMIT
2022-01-23 08:06:06.771089 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:06.771089 (ThreadPoolExecutor-0_0): On create_sakila_wh_itamar: Close
2022-01-23 08:06:06.771089 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_examples".
2022-01-23 08:06:06.771089 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_examples".
2022-01-23 08:06:06.771089 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."examples""
2022-01-23 08:06:06.786704 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_examples".
2022-01-23 08:06:06.786704 (ThreadPoolExecutor-0_0): On create_sakila_wh_examples: BEGIN
2022-01-23 08:06:06.786704 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-23 08:06:06.849190 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.06 seconds
2022-01-23 08:06:06.849190 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_examples".
2022-01-23 08:06:06.849190 (ThreadPoolExecutor-0_0): On create_sakila_wh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_examples"} */
create schema if not exists "examples"
2022-01-23 08:06:06.849190 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2022-01-23 08:06:06.849190 (ThreadPoolExecutor-0_0): On create_sakila_wh_examples: COMMIT
2022-01-23 08:06:06.849190 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_examples".
2022-01-23 08:06:06.849190 (ThreadPoolExecutor-0_0): On create_sakila_wh_examples: COMMIT
2022-01-23 08:06:06.849190 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:06.849190 (ThreadPoolExecutor-0_0): On create_sakila_wh_examples: Close
2022-01-23 08:06:06.849190 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh".
2022-01-23 08:06:06.864812 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh".
2022-01-23 08:06:06.864812 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."dwh""
2022-01-23 08:06:06.864812 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh".
2022-01-23 08:06:06.864812 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh: BEGIN
2022-01-23 08:06:06.864812 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-23 08:06:06.927295 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.06 seconds
2022-01-23 08:06:06.927295 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh".
2022-01-23 08:06:06.927295 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_dwh"} */
create schema if not exists "dwh"
2022-01-23 08:06:06.927295 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2022-01-23 08:06:06.927295 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh: COMMIT
2022-01-23 08:06:06.927295 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh".
2022-01-23 08:06:06.927295 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh: COMMIT
2022-01-23 08:06:06.927295 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:06.927295 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh: Close
2022-01-23 08:06:06.942917 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_itamar".
2022-01-23 08:06:06.942917 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_itamar".
2022-01-23 08:06:06.942917 (ThreadPoolExecutor-1_0): On list_sakila_wh_itamar: BEGIN
2022-01-23 08:06:06.942917 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-23 08:06:07.021025 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.08 seconds
2022-01-23 08:06:07.021025 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_itamar".
2022-01-23 08:06:07.021025 (ThreadPoolExecutor-1_0): On list_sakila_wh_itamar: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_itamar"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'itamar'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'itamar'
  
2022-01-23 08:06:07.021025 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.00 seconds
2022-01-23 08:06:07.021025 (ThreadPoolExecutor-1_0): On list_sakila_wh_itamar: ROLLBACK
2022-01-23 08:06:07.021025 (ThreadPoolExecutor-1_0): On list_sakila_wh_itamar: Close
2022-01-23 08:06:07.036646 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_examples".
2022-01-23 08:06:07.036646 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_examples".
2022-01-23 08:06:07.036646 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: BEGIN
2022-01-23 08:06:07.036646 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-23 08:06:07.099130 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.06 seconds
2022-01-23 08:06:07.099130 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_examples".
2022-01-23 08:06:07.099130 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'examples'
  
2022-01-23 08:06:07.114752 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.02 seconds
2022-01-23 08:06:07.114752 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: ROLLBACK
2022-01-23 08:06:07.114752 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: Close
2022-01-23 08:06:07.114752 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-23 08:06:07.114752 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-23 08:06:07.114752 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-23 08:06:07.114752 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-23 08:06:07.192859 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.08 seconds
2022-01-23 08:06:07.192859 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-23 08:06:07.192859 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-23 08:06:07.208480 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.02 seconds
2022-01-23 08:06:07.208480 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-23 08:06:07.208480 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-23 08:06:07.224103 (MainThread): Using postgres connection "master".
2022-01-23 08:06:07.224103 (MainThread): On master: BEGIN
2022-01-23 08:06:07.224103 (MainThread): Opening a new connection, currently in state init
2022-01-23 08:06:07.286586 (MainThread): SQL status: BEGIN in 0.06 seconds
2022-01-23 08:06:07.286586 (MainThread): Using postgres connection "master".
2022-01-23 08:06:07.286586 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-23 08:06:08.067654 (MainThread): SQL status: SELECT 43 in 0.78 seconds
2022-01-23 08:06:08.067654 (MainThread): On master: ROLLBACK
2022-01-23 08:06:08.067654 (MainThread): Using postgres connection "master".
2022-01-23 08:06:08.067654 (MainThread): On master: BEGIN
2022-01-23 08:06:08.067654 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-23 08:06:08.067654 (MainThread): On master: COMMIT
2022-01-23 08:06:08.067654 (MainThread): Using postgres connection "master".
2022-01-23 08:06:08.067654 (MainThread): On master: COMMIT
2022-01-23 08:06:08.067654 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:08.067654 (MainThread): On master: Close
2022-01-23 08:06:08.067654 (MainThread): 13:36:08 | Concurrency: 1 threads (target='dev')
2022-01-23 08:06:08.067654 (MainThread): 13:36:08 | 
2022-01-23 08:06:08.083274 (Thread-1): Began running node model.sakila_dbt_project.dim_customer
2022-01-23 08:06:08.083274 (Thread-1): 13:36:08 | 1 of 15 START incremental model dwh.dim_customer..................... [RUN]
2022-01-23 08:06:08.083274 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:06:08.083274 (Thread-1): Compiling model.sakila_dbt_project.dim_customer
2022-01-23 08:06:08.083274 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-23 08:06:08.083274 (Thread-1): finished collecting timing info
2022-01-23 08:06:08.205607 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-23 08:06:08.221235 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:06:08.221235 (Thread-1): On model.sakila_dbt_project.dim_customer: BEGIN
2022-01-23 08:06:08.221235 (Thread-1): Opening a new connection, currently in state init
2022-01-23 08:06:08.401824 (Thread-1): SQL status: BEGIN in 0.18 seconds
2022-01-23 08:06:08.401824 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:06:08.401824 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      

  create  table "sakila_wh"."dwh"."dim_customer"
  as (
    

with customer_base as (

select
 *,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.active::int as active_int,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
  '2022-01-23 08:06:04'::timestamp as dbt_time
from
	"sakila_wh"."stg"."customer" as customer),

  address as (
    select * from "sakila_wh"."stg"."address"
  ),

  city as (
    select * from "sakila_wh"."stg"."city"
  ),

  country as (
    select * from "sakila_wh"."stg"."country"
  )

  select
  customer_base.customer_id,
  customer_base.store_id,
  customer_base.first_name,
  customer_base.last_name,
  customer_base.full_name,
  customer_base.domain,
  customer_base.email,
  customer_base.active_int as active,
  customer_base.active_desc,

  address.address_id,
  address.address,
  city.city_id,
  city.city,
  country.country_id,
  country.country,

  customer_base.create_date,
  customer_base.last_update,
  customer_base.dbt_time

  from
  customer_base

	left join address on 1=1
	and customer_base.address_id =address.address_id

	left join city on 1=1
	and address.city_id = city.city_id

  left join country on 1=1
  and country.country_id = city.country_id

  where 1=1

  
  );
  
2022-01-23 08:06:08.698629 (Thread-1): SQL status: SELECT 599 in 0.30 seconds
2022-01-23 08:06:08.729913 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:08.729913 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:06:08.729913 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

        insert into "sakila_wh"."dwh"."dim_customer"(customer_id) VALUES (-1)
      
2022-01-23 08:06:08.729913 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 08:06:08.729913 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-23 08:06:08.729913 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:06:08.729913 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-23 08:06:08.745529 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:08.745529 (Thread-1): finished collecting timing info
2022-01-23 08:06:08.745529 (Thread-1): On model.sakila_dbt_project.dim_customer: Close
2022-01-23 08:06:08.745529 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665DF5B50>]}
2022-01-23 08:06:08.745529 (Thread-1): 13:36:08 | 1 of 15 OK created incremental model dwh.dim_customer................ [SELECT 599 in 0.66s]
2022-01-23 08:06:08.745529 (Thread-1): Finished running node model.sakila_dbt_project.dim_customer
2022-01-23 08:06:08.745529 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-23 08:06:08.745529 (Thread-1): 13:36:08 | 2 of 15 START table model dwh.dim_date............................... [RUN]
2022-01-23 08:06:08.745529 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:06:08.745529 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-23 08:06:08.745529 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-23 08:06:08.745529 (Thread-1): finished collecting timing info
2022-01-23 08:06:08.784616 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-23 08:06:08.784616 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:06:08.784616 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-23 08:06:08.784616 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:06:08.868843 (Thread-1): SQL status: BEGIN in 0.08 seconds
2022-01-23 08:06:08.868843 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:06:08.868843 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-23 08:06:09.321862 (Thread-1): SQL status: SELECT 8059 in 0.44 seconds
2022-01-23 08:06:09.337484 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:06:09.337484 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-23 08:06:09.337484 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:06:09.337484 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-23 08:06:09.337484 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:06:09.337484 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-23 08:06:09.368727 (Thread-1): SQL status: COMMIT in 0.03 seconds
2022-01-23 08:06:09.384349 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:06:09.384349 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-23 08:06:09.384349 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 08:06:09.384349 (Thread-1): finished collecting timing info
2022-01-23 08:06:09.384349 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-23 08:06:09.384349 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665D41880>]}
2022-01-23 08:06:09.384349 (Thread-1): 13:36:09 | 2 of 15 OK created table model dwh.dim_date.......................... [SELECT 8059 in 0.64s]
2022-01-23 08:06:09.384349 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-23 08:06:09.384349 (Thread-1): Began running node model.sakila_dbt_project.dim_film
2022-01-23 08:06:09.384349 (Thread-1): 13:36:09 | 3 of 15 START incremental model dwh.dim_film......................... [RUN]
2022-01-23 08:06:09.384349 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:06:09.384349 (Thread-1): Compiling model.sakila_dbt_project.dim_film
2022-01-23 08:06:09.400002 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_film"
2022-01-23 08:06:09.400002 (Thread-1): finished collecting timing info
2022-01-23 08:06:09.400002 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_film"
2022-01-23 08:06:09.415625 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:06:09.415625 (Thread-1): On model.sakila_dbt_project.dim_film: BEGIN
2022-01-23 08:06:09.415625 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:06:09.523571 (Thread-1): SQL status: BEGIN in 0.11 seconds
2022-01-23 08:06:09.523571 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:06:09.524569 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      

  create  table "sakila_wh"."dwh"."dim_film"
  as (
    

with stg_film as (
	select
	*,
	(case
	when length<=75 then 'short'
	when (length>75 and length<=120) then 'medium'
	when length>120 then 'long'
	else 'na' end) as length_desc,
	COALESCE(original_language_id,0) as original_language_id_zero,
	case when POSITION('Trailers' in special_features::varchar)>0 then 1 else 0 end  as has_trailers,
	case when POSITION('Commentaries' in special_features::varchar)>0 then 1 else 0 end  as has_commentaries,
	case when POSITION('Deleted Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_deleted_scenes,
	case when POSITION('Behind the Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_behind_the_scenes,
	'2022-01-23 08:06:04'::timestamp as dbt_time
	from
	"sakila_wh"."stg"."film"
),

language as (
	select * from "sakila_wh"."stg"."language"
),

category as (
	select * from "sakila_wh"."stg"."category"
),

film_category as (
	select * from "sakila_wh"."stg"."film_category"
),

stg_film_1 as (
	select
	stg_film.*,
	language.name as lang_name
	from
	stg_film
	left join language on 1=1
	and stg_film.language_id = language.language_id
),

stg_film_2 as (
	select
		stg_film_1.*,
		category.category_id,
		category.name as category_desc
	from
	stg_film_1

	left join film_category on 1=1
	and stg_film_1.film_id = film_category.film_id

	left join category on 1=1
	and film_category.category_id  = category.category_id
)


select
  film_id,
  title,
  description,
  release_year,
  language_id,
  lang_name,
  original_language_id_zero as original_language_id,
  rental_duration,
  rental_rate,
  length,
  length_desc,
  replacement_cost,
  rating,
  category_id,
  category_desc,
  special_features,
  has_trailers,
  has_commentaries,
  has_behind_the_scenes,
  has_deleted_scenes,
  last_update,
	dbt_time
from
stg_film_2

where 1=1


  );
  
2022-01-23 08:06:09.589200 (Thread-1): SQL status: SELECT 1000 in 0.06 seconds
2022-01-23 08:06:09.604816 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:09.604816 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:06:09.604816 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

        insert into "sakila_wh"."dwh"."dim_film"(film_id) VALUES (-1)
      
2022-01-23 08:06:09.604816 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 08:06:09.604816 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-23 08:06:09.604816 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:06:09.604816 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-23 08:06:09.604816 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:09.604816 (Thread-1): finished collecting timing info
2022-01-23 08:06:09.604816 (Thread-1): On model.sakila_dbt_project.dim_film: Close
2022-01-23 08:06:09.604816 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665D58880>]}
2022-01-23 08:06:09.620436 (Thread-1): 13:36:09 | 3 of 15 OK created incremental model dwh.dim_film.................... [SELECT 1000 in 0.22s]
2022-01-23 08:06:09.620436 (Thread-1): Finished running node model.sakila_dbt_project.dim_film
2022-01-23 08:06:09.620436 (Thread-1): Began running node model.sakila_dbt_project.dim_staff
2022-01-23 08:06:09.620436 (Thread-1): 13:36:09 | 4 of 15 START table model dwh.dim_staff.............................. [RUN]
2022-01-23 08:06:09.620436 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:06:09.620436 (Thread-1): Compiling model.sakila_dbt_project.dim_staff
2022-01-23 08:06:09.620436 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-23 08:06:09.636058 (Thread-1): finished collecting timing info
2022-01-23 08:06:09.642696 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-23 08:06:09.642696 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:06:09.642696 (Thread-1): On model.sakila_dbt_project.dim_staff: BEGIN
2022-01-23 08:06:09.642696 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:06:09.736426 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-23 08:06:09.740779 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:06:09.740779 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */


  create  table "sakila_wh"."dwh"."dim_staff__dbt_tmp"
  as (
    

with staff_base as (
select
*,
(case when active::int = 1 then 1 else 0 end) as "active_int",
(case when active::int = 1 then 'yes' else 'no' end) as "active_desc",
'2022-01-23 08:06:04'::timestamp as dbt_time
from
"sakila_wh"."stg"."staff"
)

select
	staff_id,
	first_name,
	last_name,
	email,
  active_int as active,
  active_desc,
	last_update,
  dbt_time
from
	staff_base
  );
2022-01-23 08:06:09.789818 (Thread-1): SQL status: SELECT 2 in 0.05 seconds
2022-01-23 08:06:09.805439 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:06:09.805439 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
alter table "sakila_wh"."dwh"."dim_staff__dbt_tmp" rename to "dim_staff"
2022-01-23 08:06:09.805439 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:06:09.805439 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:09.805439 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:06:09.805439 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */

        insert into "sakila_wh"."dwh"."dim_staff"(staff_id) VALUES (-1)
      
2022-01-23 08:06:09.805439 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 08:06:09.821060 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-23 08:06:09.821060 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:06:09.821060 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-23 08:06:09.821060 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:09.821060 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:06:09.821060 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
drop table if exists "sakila_wh"."dwh"."dim_staff__dbt_backup" cascade
2022-01-23 08:06:09.821060 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 08:06:09.821060 (Thread-1): finished collecting timing info
2022-01-23 08:06:09.821060 (Thread-1): On model.sakila_dbt_project.dim_staff: Close
2022-01-23 08:06:09.836683 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665D41B80>]}
2022-01-23 08:06:09.836683 (Thread-1): 13:36:09 | 4 of 15 OK created table model dwh.dim_staff......................... [SELECT 2 in 0.22s]
2022-01-23 08:06:09.836683 (Thread-1): Finished running node model.sakila_dbt_project.dim_staff
2022-01-23 08:06:09.836683 (Thread-1): Began running node model.sakila_dbt_project.fact_payment
2022-01-23 08:06:09.836683 (Thread-1): 13:36:09 | 5 of 15 START incremental model dwh.fact_payment..................... [RUN]
2022-01-23 08:06:09.836683 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:06:09.836683 (Thread-1): Compiling model.sakila_dbt_project.fact_payment
2022-01-23 08:06:09.836683 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.fact_payment"
2022-01-23 08:06:09.836683 (Thread-1): finished collecting timing info
2022-01-23 08:06:09.852306 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.fact_payment"
2022-01-23 08:06:09.852306 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:06:09.852306 (Thread-1): On model.sakila_dbt_project.fact_payment: BEGIN
2022-01-23 08:06:09.852306 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:06:10.003686 (Thread-1): SQL status: BEGIN in 0.15 seconds
2022-01-23 08:06:10.003686 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:06:10.003686 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      

  create  table "sakila_wh"."dwh"."fact_payment"
  as (
    

select
*,
'2022-01-23 08:06:04' as dbt_time
from
"sakila_wh"."stg"."payment"
where 1=1


  );
  
2022-01-23 08:06:10.316114 (Thread-1): SQL status: SELECT 16049 in 0.31 seconds
2022-01-23 08:06:10.316114 (Thread-1): On model.sakila_dbt_project.fact_payment: COMMIT
2022-01-23 08:06:10.316114 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:06:10.316114 (Thread-1): On model.sakila_dbt_project.fact_payment: COMMIT
2022-01-23 08:06:10.316114 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:10.316114 (Thread-1): finished collecting timing info
2022-01-23 08:06:10.331734 (Thread-1): On model.sakila_dbt_project.fact_payment: Close
2022-01-23 08:06:10.331734 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665DCC9D0>]}
2022-01-23 08:06:10.331734 (Thread-1): 13:36:10 | 5 of 15 OK created incremental model dwh.fact_payment................ [SELECT 16049 in 0.50s]
2022-01-23 08:06:10.331734 (Thread-1): Finished running node model.sakila_dbt_project.fact_payment
2022-01-23 08:06:10.331734 (Thread-1): Began running node model.sakila_dbt_project.film_test
2022-01-23 08:06:10.331734 (Thread-1): 13:36:10 | 6 of 15 START table model examples.film_test......................... [RUN]
2022-01-23 08:06:10.331734 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:06:10.331734 (Thread-1): Compiling model.sakila_dbt_project.film_test
2022-01-23 08:06:10.331734 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.film_test"
2022-01-23 08:06:10.347357 (Thread-1): finished collecting timing info
2022-01-23 08:06:10.362977 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.film_test"
2022-01-23 08:06:10.362977 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:06:10.362977 (Thread-1): On model.sakila_dbt_project.film_test: BEGIN
2022-01-23 08:06:10.362977 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:06:10.458334 (Thread-1): SQL status: BEGIN in 0.10 seconds
2022-01-23 08:06:10.473955 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:06:10.473955 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */


  create  table "sakila_wh"."examples"."film_test__dbt_tmp"
  as (
    select
*
from
-- sakila_wh.stg.film
"sakila_wh"."stg"."film"
  );
2022-01-23 08:06:10.723946 (Thread-1): SQL status: SELECT 1000 in 0.25 seconds
2022-01-23 08:06:10.739524 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:06:10.739524 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."examples"."film_test__dbt_tmp" rename to "film_test"
2022-01-23 08:06:10.739524 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:06:10.739524 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-23 08:06:10.739524 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:06:10.739524 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-23 08:06:10.739524 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:10.739524 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:06:10.739524 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
drop table if exists "sakila_wh"."examples"."film_test__dbt_backup" cascade
2022-01-23 08:06:10.755144 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 08:06:10.755144 (Thread-1): finished collecting timing info
2022-01-23 08:06:10.755144 (Thread-1): On model.sakila_dbt_project.film_test: Close
2022-01-23 08:06:10.755144 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665DCC9D0>]}
2022-01-23 08:06:10.755144 (Thread-1): 13:36:10 | 6 of 15 OK created table model examples.film_test.................... [SELECT 1000 in 0.42s]
2022-01-23 08:06:10.755144 (Thread-1): Finished running node model.sakila_dbt_project.film_test
2022-01-23 08:06:10.755144 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-23 08:06:10.755144 (Thread-1): 13:36:10 | 7 of 15 START table model examples.hello_world....................... [RUN]
2022-01-23 08:06:10.755144 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:06:10.755144 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-23 08:06:10.755144 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-23 08:06:10.755144 (Thread-1): finished collecting timing info
2022-01-23 08:06:10.770764 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-23 08:06:10.770764 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:06:10.770764 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-23 08:06:10.770764 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:06:10.846934 (Thread-1): SQL status: BEGIN in 0.08 seconds
2022-01-23 08:06:10.846934 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:06:10.846934 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."examples"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-23 08:06:10.971956 (Thread-1): SQL status: SELECT 599 in 0.13 seconds
2022-01-23 08:06:10.987495 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:06:11.003116 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-23 08:06:11.003116 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:06:11.003116 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-23 08:06:11.018737 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:06:11.018737 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-23 08:06:11.018737 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:11.018737 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:06:11.018737 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."examples"."hello_world__dbt_backup" cascade
2022-01-23 08:06:11.018737 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 08:06:11.018737 (Thread-1): finished collecting timing info
2022-01-23 08:06:11.018737 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-23 08:06:11.034355 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665DA5160>]}
2022-01-23 08:06:11.034355 (Thread-1): 13:36:11 | 7 of 15 OK created table model examples.hello_world.................. [SELECT 599 in 0.26s]
2022-01-23 08:06:11.034355 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-23 08:06:11.034355 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-23 08:06:11.034355 (Thread-1): 13:36:11 | 8 of 15 START table model examples.my_first_dbt_model................ [RUN]
2022-01-23 08:06:11.034355 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:06:11.034355 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-23 08:06:11.034355 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-23 08:06:11.034355 (Thread-1): finished collecting timing info
2022-01-23 08:06:11.049977 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-23 08:06:11.049977 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:06:11.049977 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-23 08:06:11.049977 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:06:11.122848 (Thread-1): SQL status: BEGIN in 0.07 seconds
2022-01-23 08:06:11.138468 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:06:11.138468 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-23 08:06:11.138468 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2022-01-23 08:06:11.154091 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:06:11.154091 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-23 08:06:11.154091 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:06:11.154091 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-23 08:06:11.154091 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:06:11.154091 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-23 08:06:11.154091 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:11.169712 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:06:11.169712 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-23 08:06:11.169712 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 08:06:11.169712 (Thread-1): finished collecting timing info
2022-01-23 08:06:11.169712 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-23 08:06:11.169712 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665C1E3A0>]}
2022-01-23 08:06:11.169712 (Thread-1): 13:36:11 | 8 of 15 OK created table model examples.my_first_dbt_model........... [SELECT 2 in 0.14s]
2022-01-23 08:06:11.169712 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-23 08:06:11.169712 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-23 08:06:11.169712 (Thread-1): 13:36:11 | 9 of 15 START incremental model examples.payment_inc................. [RUN]
2022-01-23 08:06:11.169712 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:06:11.169712 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-23 08:06:11.185331 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-23 08:06:11.185331 (Thread-1): finished collecting timing info
2022-01-23 08:06:11.200952 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-23 08:06:11.206317 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:06:11.206317 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-23 08:06:11.207255 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:06:11.300983 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-23 08:06:11.300983 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:06:11.300983 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      

  create  table "sakila_wh"."examples"."payment_inc"
  as (
    

select
*,
'2022-01-23 08:06:04' as dbt_time
from
stg.payment
where 1=1




-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-23 08:06:11.744471 (Thread-1): SQL status: SELECT 16049 in 0.44 seconds
2022-01-23 08:06:11.744471 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-23 08:06:11.744471 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:06:11.744471 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-23 08:06:11.744471 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:11.744471 (Thread-1): finished collecting timing info
2022-01-23 08:06:11.744471 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-23 08:06:11.744471 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665CB5A60>]}
2022-01-23 08:06:11.744471 (Thread-1): 13:36:11 | 9 of 15 OK created incremental model examples.payment_inc............ [SELECT 16049 in 0.57s]
2022-01-23 08:06:11.760092 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-23 08:06:11.760092 (Thread-1): Began running node model.sakila_dbt_project.dim_date_inc
2022-01-23 08:06:11.760092 (Thread-1): 13:36:11 | 10 of 15 START incremental model examples.dim_date_inc............... [RUN]
2022-01-23 08:06:11.760092 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:06:11.760092 (Thread-1): Compiling model.sakila_dbt_project.dim_date_inc
2022-01-23 08:06:11.775715 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date_inc"
2022-01-23 08:06:11.775715 (Thread-1): finished collecting timing info
2022-01-23 08:06:11.775715 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date_inc"
2022-01-23 08:06:11.791333 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:06:11.791333 (Thread-1): On model.sakila_dbt_project.dim_date_inc: BEGIN
2022-01-23 08:06:11.791333 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:06:11.923453 (Thread-1): SQL status: BEGIN in 0.13 seconds
2022-01-23 08:06:11.923453 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:06:11.923453 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      

  create  table "sakila_wh"."examples"."dim_date_inc"
  as (
    


SELECT
*
from "sakila_wh"."dwh"."dim_date"
where 1=1



  );
  
2022-01-23 08:06:12.157772 (Thread-1): SQL status: SELECT 8059 in 0.23 seconds
2022-01-23 08:06:12.157772 (Thread-1): On model.sakila_dbt_project.dim_date_inc: COMMIT
2022-01-23 08:06:12.157772 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:06:12.157772 (Thread-1): On model.sakila_dbt_project.dim_date_inc: COMMIT
2022-01-23 08:06:12.157772 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:12.157772 (Thread-1): finished collecting timing info
2022-01-23 08:06:12.157772 (Thread-1): On model.sakila_dbt_project.dim_date_inc: Close
2022-01-23 08:06:12.157772 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665E14FA0>]}
2022-01-23 08:06:12.157772 (Thread-1): 13:36:12 | 10 of 15 OK created incremental model examples.dim_date_inc.......... [SELECT 8059 in 0.40s]
2022-01-23 08:06:12.157772 (Thread-1): Finished running node model.sakila_dbt_project.dim_date_inc
2022-01-23 08:06:12.157772 (Thread-1): Began running node model.sakila_dbt_project.dim_store
2022-01-23 08:06:12.173395 (Thread-1): 13:36:12 | 11 of 15 START table model dwh.dim_store............................. [RUN]
2022-01-23 08:06:12.173395 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:06:12.173395 (Thread-1): Compiling model.sakila_dbt_project.dim_store
2022-01-23 08:06:12.173395 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_store"
2022-01-23 08:06:12.173395 (Thread-1): finished collecting timing info
2022-01-23 08:06:12.189016 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_store"
2022-01-23 08:06:12.189016 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:06:12.189016 (Thread-1): On model.sakila_dbt_project.dim_store: BEGIN
2022-01-23 08:06:12.189016 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:06:12.278442 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-23 08:06:12.278442 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:06:12.278442 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */


  create  table "sakila_wh"."dwh"."dim_store__dbt_tmp"
  as (
    

with stg_store as (
		select
    *,
    '2022-01-23 08:06:04'::timestamp as dbt_time
     from "sakila_wh"."stg"."store"
),

staff as (
 select * from "sakila_wh"."dwh"."dim_staff"
),

address as (
  select * from "sakila_wh"."stg"."address"
),

city as (
  select * from "sakila_wh"."stg"."city"
),

country as (
  select * from "sakila_wh"."stg"."country"
),
stg_store_1 as (-- add staff
		select
		stg_store.*,
		staff.first_name as staff_first_name,
		staff.last_name as staff_last_name
		from
		stg_store
		left join staff  on 1=1
		and stg_store.manager_staff_id = staff.staff_id
),
stg_store_2 as (-- add adress
		select
		stg_store_1.*,
		address.address,
		city.city_id,
		city.city,
		country.country_id,
		country.country
		from
		stg_store_1

		left join address on 1=1
		and stg_store_1.address_id =address.address_id

		left join city on 1=1
		and address.city_id = city.city_id

		left join country on  1=1
		and city.country_id = country.country_id
)

select
  store_id,
  manager_staff_id,
  staff_first_name,
  staff_last_name,
  address_id,
  address,
  city_id,
  city,
  country_id,
  country,
  last_update,
  dbt_time
from stg_store_2
  );
2022-01-23 08:06:12.294061 (Thread-1): SQL status: SELECT 2 in 0.02 seconds
2022-01-23 08:06:12.309685 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:06:12.309685 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
alter table "sakila_wh"."dwh"."dim_store__dbt_tmp" rename to "dim_store"
2022-01-23 08:06:12.309685 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:06:12.309685 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:06:12.309685 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:06:12.309685 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */

        insert into "sakila_wh"."dwh"."dim_store"(store_id) VALUES (-1)
      
2022-01-23 08:06:12.309685 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 08:06:12.309685 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-23 08:06:12.325305 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:06:12.325305 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-23 08:06:12.325305 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:12.325305 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:06:12.325305 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
drop table if exists "sakila_wh"."dwh"."dim_store__dbt_backup" cascade
2022-01-23 08:06:12.325305 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 08:06:12.325305 (Thread-1): finished collecting timing info
2022-01-23 08:06:12.325305 (Thread-1): On model.sakila_dbt_project.dim_store: Close
2022-01-23 08:06:12.325305 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665E09160>]}
2022-01-23 08:06:12.325305 (Thread-1): 13:36:12 | 11 of 15 OK created table model dwh.dim_store........................ [SELECT 2 in 0.15s]
2022-01-23 08:06:12.325305 (Thread-1): Finished running node model.sakila_dbt_project.dim_store
2022-01-23 08:06:12.325305 (Thread-1): Began running node model.sakila_dbt_project.customer_test
2022-01-23 08:06:12.325305 (Thread-1): 13:36:12 | 12 of 15 START table model itamar.customers_alias.................... [RUN]
2022-01-23 08:06:12.340925 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-23 08:06:12.340925 (Thread-1): Compiling model.sakila_dbt_project.customer_test
2022-01-23 08:06:12.403418 (Thread-1): finished collecting timing info
2022-01-23 08:06:12.403418 (Thread-1): Compilation Error in model customer_test (models\example\customer_test.sql)
  Required var 'cust_id' not found in config:
  Vars supplied to customer_test = {}
  
  > in model customer_test (models\example\customer_test.sql)
  > called by model customer_test (models\example\customer_test.sql)
Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\base.py", line 285, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\compile.py", line 33, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\compilation.py", line 544, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\compilation.py", line 384, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\jinja.py", line 598, in get_rendered
    return render_template(template, ctx, node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\jinja.py", line 549, in render_template
    return template.render(ctx)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\environment.py", line 1090, in render
    self.environment.handle_exception()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 7, in top-level template code
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\context\base.py", line 159, in __call__
    return self.get_missing_var(var_name)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\context\base.py", line 140, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\exceptions.py", line 447, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model customer_test (models\example\customer_test.sql)
  Required var 'cust_id' not found in config:
  Vars supplied to customer_test = {}
  
  > in model customer_test (models\example\customer_test.sql)
  > called by model customer_test (models\example\customer_test.sql)
2022-01-23 08:06:12.981399 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665D41B80>]}
2022-01-23 08:06:12.981399 (Thread-1): 13:36:12 | 12 of 15 ERROR creating table model itamar.customers_alias........... [ERROR in 0.64s]
2022-01-23 08:06:12.981399 (Thread-1): Finished running node model.sakila_dbt_project.customer_test
2022-01-23 08:06:12.981399 (Thread-1): Began running node model.sakila_dbt_project.customer_test_macro
2022-01-23 08:06:12.981399 (Thread-1): 13:36:12 | 13 of 15 START table model examples.customer_test_macro.............. [RUN]
2022-01-23 08:06:12.981399 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.customer_test_macro".
2022-01-23 08:06:12.981399 (Thread-1): Compiling model.sakila_dbt_project.customer_test_macro
2022-01-23 08:06:12.981399 (Thread-1): finished collecting timing info
2022-01-23 08:06:12.981399 (Thread-1): Compilation Error in model customer_test_macro (models\example\customer_test_macro.sql)
  Required var 'cust_id' not found in config:
  Vars supplied to customer_test_macro = {}
  
  > in model customer_test_macro (models\example\customer_test_macro.sql)
  > called by model customer_test_macro (models\example\customer_test_macro.sql)
Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\base.py", line 285, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\compile.py", line 33, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\compilation.py", line 544, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\compilation.py", line 384, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\jinja.py", line 598, in get_rendered
    return render_template(template, ctx, node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\jinja.py", line 549, in render_template
    return template.render(ctx)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\environment.py", line 1090, in render
    self.environment.handle_exception()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\context\base.py", line 159, in __call__
    return self.get_missing_var(var_name)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\context\base.py", line 140, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\exceptions.py", line 447, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model customer_test_macro (models\example\customer_test_macro.sql)
  Required var 'cust_id' not found in config:
  Vars supplied to customer_test_macro = {}
  
  > in model customer_test_macro (models\example\customer_test_macro.sql)
  > called by model customer_test_macro (models\example\customer_test_macro.sql)
2022-01-23 08:06:12.997057 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665D41FD0>]}
2022-01-23 08:06:12.997057 (Thread-1): 13:36:12 | 13 of 15 ERROR creating table model examples.customer_test_macro..... [ERROR in 0.02s]
2022-01-23 08:06:12.997057 (Thread-1): Finished running node model.sakila_dbt_project.customer_test_macro
2022-01-23 08:06:12.997057 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-23 08:06:12.997057 (Thread-1): 13:36:12 | 14 of 15 START table model examples.my_second_dbt_model.............. [RUN]
2022-01-23 08:06:12.997057 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:06:12.997057 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-23 08:06:12.997057 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-23 08:06:12.997057 (Thread-1): finished collecting timing info
2022-01-23 08:06:12.997057 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-23 08:06:12.997057 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:06:12.997057 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-23 08:06:12.997057 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:06:13.118301 (Thread-1): SQL status: BEGIN in 0.12 seconds
2022-01-23 08:06:13.118301 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:06:13.118301 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."examples"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."examples"."my_first_dbt_model"
where id = 1
  );
2022-01-23 08:06:13.149541 (Thread-1): SQL status: SELECT 1 in 0.03 seconds
2022-01-23 08:06:13.165167 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:06:13.165167 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-23 08:06:13.165167 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:06:13.165167 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-23 08:06:13.165167 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:06:13.165167 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-23 08:06:13.165167 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:13.165167 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:06:13.165167 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-23 08:06:13.180784 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-01-23 08:06:13.180784 (Thread-1): finished collecting timing info
2022-01-23 08:06:13.180784 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-23 08:06:13.180784 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665D92D60>]}
2022-01-23 08:06:13.180784 (Thread-1): 13:36:13 | 14 of 15 OK created table model examples.my_second_dbt_model......... [SELECT 1 in 0.18s]
2022-01-23 08:06:13.180784 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-23 08:06:13.180784 (Thread-1): Began running node model.sakila_dbt_project.fact_rental
2022-01-23 08:06:13.180784 (Thread-1): 13:36:13 | 15 of 15 START incremental model dwh.fact_rental..................... [RUN]
2022-01-23 08:06:13.180784 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:06:13.180784 (Thread-1): Compiling model.sakila_dbt_project.fact_rental
2022-01-23 08:06:13.196404 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.fact_rental"
2022-01-23 08:06:13.196404 (Thread-1): finished collecting timing info
2022-01-23 08:06:13.212026 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.fact_rental"
2022-01-23 08:06:13.212026 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:06:13.212026 (Thread-1): On model.sakila_dbt_project.fact_rental: BEGIN
2022-01-23 08:06:13.212026 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:06:13.287511 (Thread-1): SQL status: BEGIN in 0.08 seconds
2022-01-23 08:06:13.287511 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:06:13.303129 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      

  create  table "sakila_wh"."dwh"."fact_rental"
  as (
    

with rental_base as (--base
select
	*,
	EXTRACT(EPOCH from rental_date::timestamp) as rental_epoch,
	EXTRACT(EPOCH from return_date::timestamp) as return_epoch,
	EXTRACT(EPOCH from return_date::timestamp)-EXTRACT(EPOCH from rental_date::timestamp) as diff,
	(case when return_date is not null then 1 else 0 end) as is_return,
	to_char(rental_date::timestamp, 'YYYYMMDD')::integer as date_key,
  '2022-01-23 08:06:04'::timestamp as dbt_time

	from
	"sakila_wh"."stg"."rental"
),

inventory as (
	select * from "sakila_wh"."stg"."inventory"
),

dim_film as (
	select * from "sakila_wh"."dwh"."dim_film"
),

dim_store as (
	select * from "sakila_wh"."dwh"."dim_store"
),

dim_staff as (
	select * from "sakila_wh"."dwh"."dim_staff"
),

dim_customer as (
	select * from "sakila_wh"."dwh"."dim_customer"
),

rental_base_1 as (-- join base with inventory
	select
	rental_base.*,
	inventory.store_id,
  inventory.film_id
	from
	rental_base

	inner join inventory on 1=1
	and inventory.inventory_id = rental_base.inventory_id
),


rental_base_2 as (--check direct integrity
	select
	rental_base_1.*,
	(case when dim_staff.staff_id is not null then dim_staff.staff_id else -1 end) as staff_id_rental_check,
	(case when dim_customer.customer_id is not null then dim_customer.customer_id else -1 end) as customer_id_check,
  (case when dim_film.film_id is not null then dim_film.film_id else -1 end) as film_id_check,
	(case when dim_store.store_id is not null then dim_store.store_id else -1 end) as store_id_check
	from
	rental_base_1

	left join
  dim_staff
  on 1=1
	and rental_base_1.staff_id = dim_staff.staff_id

	left join
  dim_customer
  on 1=1
	and rental_base_1.customer_id = dim_customer.customer_id

  left join
  dim_film
  on 1=1
  and  rental_base_1.film_id = dim_film.film_id

  left join
  dim_store
  on 1=1
  and  rental_base_1.store_id = dim_store.store_id
)

select
  rental_id,
  rental_date,
  date_key,
  inventory_id,
  customer_id_check as customer_id,
  film_id_check as film_id,
  store_id_check as store_id,
  staff_id_rental_check as staff_id_rental,
  return_date,
  case when return_date is not null then diff/3600 else null end rental_hours,
  is_return,
  last_update,
  dbt_time
from
 rental_base_2
 where 1=1

 

 --  - INTERVAL '10 minutes'
  );
  
2022-01-23 08:06:13.600070 (Thread-1): SQL status: SELECT 16044 in 0.30 seconds
2022-01-23 08:06:13.615591 (Thread-1): On model.sakila_dbt_project.fact_rental: COMMIT
2022-01-23 08:06:13.615591 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:06:13.615591 (Thread-1): On model.sakila_dbt_project.fact_rental: COMMIT
2022-01-23 08:06:13.662424 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-23 08:06:13.662424 (Thread-1): finished collecting timing info
2022-01-23 08:06:13.662424 (Thread-1): On model.sakila_dbt_project.fact_rental: Close
2022-01-23 08:06:13.662424 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cf5bcd8-34f7-434c-916e-0a0e79f93e16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665B1B9A0>]}
2022-01-23 08:06:13.662424 (Thread-1): 13:36:13 | 15 of 15 OK created incremental model dwh.fact_rental................ [SELECT 16044 in 0.48s]
2022-01-23 08:06:13.662424 (Thread-1): Finished running node model.sakila_dbt_project.fact_rental
2022-01-23 08:06:13.662424 (MainThread): Acquiring new postgres connection "master".
2022-01-23 08:06:13.662424 (MainThread): Using postgres connection "master".
2022-01-23 08:06:13.678051 (MainThread): On master: BEGIN
2022-01-23 08:06:13.678051 (MainThread): Opening a new connection, currently in state closed
2022-01-23 08:06:13.771770 (MainThread): SQL status: BEGIN in 0.09 seconds
2022-01-23 08:06:13.771770 (MainThread): On master: COMMIT
2022-01-23 08:06:13.771770 (MainThread): Using postgres connection "master".
2022-01-23 08:06:13.771770 (MainThread): On master: COMMIT
2022-01-23 08:06:13.771770 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:06:13.771770 (MainThread): On master: Close
2022-01-23 08:06:13.771770 (MainThread): 13:36:13 | 
2022-01-23 08:06:13.771770 (MainThread): 13:36:13 | Finished running 6 incremental models, 9 table models in 7.48s.
2022-01-23 08:06:13.771770 (MainThread): Connection 'master' was properly closed.
2022-01-23 08:06:13.771770 (MainThread): Connection 'create_sakila_wh_dwh' was properly closed.
2022-01-23 08:06:13.771770 (MainThread): Connection 'list_sakila_wh_dwh' was properly closed.
2022-01-23 08:06:13.771770 (MainThread): Connection 'model.sakila_dbt_project.fact_rental' was properly closed.
2022-01-23 08:06:13.787396 (MainThread): 
2022-01-23 08:06:13.787396 (MainThread): Completed with 2 errors and 0 warnings:
2022-01-23 08:06:13.787396 (MainThread): 
2022-01-23 08:06:13.787396 (MainThread): Compilation Error in model customer_test (models\example\customer_test.sql)
2022-01-23 08:06:13.787396 (MainThread):   Required var 'cust_id' not found in config:
2022-01-23 08:06:13.787396 (MainThread):   Vars supplied to customer_test = {}
2022-01-23 08:06:13.787396 (MainThread):   
2022-01-23 08:06:13.787396 (MainThread):   > in model customer_test (models\example\customer_test.sql)
2022-01-23 08:06:13.787396 (MainThread):   > called by model customer_test (models\example\customer_test.sql)
2022-01-23 08:06:13.787396 (MainThread): 
2022-01-23 08:06:13.787396 (MainThread): Compilation Error in model customer_test_macro (models\example\customer_test_macro.sql)
2022-01-23 08:06:13.787396 (MainThread):   Required var 'cust_id' not found in config:
2022-01-23 08:06:13.787396 (MainThread):   Vars supplied to customer_test_macro = {}
2022-01-23 08:06:13.787396 (MainThread):   
2022-01-23 08:06:13.787396 (MainThread):   > in model customer_test_macro (models\example\customer_test_macro.sql)
2022-01-23 08:06:13.803015 (MainThread):   > called by model customer_test_macro (models\example\customer_test_macro.sql)
2022-01-23 08:06:13.803015 (MainThread): 
Done. PASS=13 WARN=0 ERROR=2 SKIP=0 TOTAL=15
2022-01-23 08:06:13.803015 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665DF5040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665DF59D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B665DF0BE0>]}
2022-01-23 08:06:13.803015 (MainThread): Flushing usage events
2022-01-23 08:11:09.997181 (MainThread): Running with dbt=0.21.1
2022-01-23 08:11:10.122115 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-23 08:11:10.122115 (MainThread): Tracking: tracking
2022-01-23 08:11:10.137734 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E18A98670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B2696A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B2697C0>]}
2022-01-23 08:11:10.153395 (MainThread): Partial parsing not enabled
2022-01-23 08:11:10.215873 (MainThread): Parsing macros\concat_it.sql
2022-01-23 08:11:10.215873 (MainThread): Parsing macros\delete_from_table.sql
2022-01-23 08:11:10.215873 (MainThread): Parsing macros\generate_schema_name.sql
2022-01-23 08:11:10.231503 (MainThread): Parsing macros\logit.sql
2022-01-23 08:11:10.231503 (MainThread): Parsing macros\adapters.sql
2022-01-23 08:11:10.278400 (MainThread): Parsing macros\catalog.sql
2022-01-23 08:11:10.278400 (MainThread): Parsing macros\relations.sql
2022-01-23 08:11:10.278400 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-23 08:11:10.278400 (MainThread): Parsing macros\core.sql
2022-01-23 08:11:10.293953 (MainThread): Parsing macros\adapters\common.sql
2022-01-23 08:11:10.418957 (MainThread): Parsing macros\etc\datetime.sql
2022-01-23 08:11:10.434578 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-23 08:11:10.434578 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-23 08:11:10.434578 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-23 08:11:10.450199 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-23 08:11:10.450199 (MainThread): Parsing macros\etc\query.sql
2022-01-23 08:11:10.450199 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-23 08:11:10.450199 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-23 08:11:10.465782 (MainThread): Parsing macros\materializations\test.sql
2022-01-23 08:11:10.481403 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-23 08:11:10.497061 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-23 08:11:10.512683 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-23 08:11:10.528306 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-23 08:11:10.559521 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-23 08:11:10.590756 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-23 08:11:10.653277 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-23 08:11:10.653277 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-23 08:11:10.684521 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-23 08:11:10.700102 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-23 08:11:10.700102 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-23 08:11:10.715723 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-23 08:11:10.715723 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-23 08:11:10.715723 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-23 08:11:10.731383 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-23 08:11:11.059393 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:11:11.090637 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.090637 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:11:11.090637 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.090637 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:11:11.106258 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.106258 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:11:11.121878 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.121878 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:11:11.121878 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.137540 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-23 08:11:11.137540 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.137540 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.137540 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test_macro".
2022-01-23 08:11:11.153163 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.153163 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:11:11.153163 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.153163 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:11:11.168779 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.168779 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:11:11.168779 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.168779 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:11:11.184399 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.184399 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:11:11.184399 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.184399 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:11:11.200055 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.200055 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:11:11.200055 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:11:11.215646 (MainThread): Acquiring new postgres connection "analysis.sakila_dbt_project.example".
2022-01-23 08:11:11.246885 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_cost_30".
2022-01-23 08:11:11.246885 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.293711 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.293711 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.309336 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.309336 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.309336 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.309336 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.324968 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.324968 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.324968 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.324968 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.356197 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.371819 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.371819 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.387441 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.387441 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.387441 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.403062 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.403062 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.418683 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.418683 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.434305 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.434305 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.434305 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.434305 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:11.481167 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B2750A0>]}
2022-01-23 08:11:11.496837 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-23 08:11:11.496837 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B3A13A0>]}
2022-01-23 08:11:11.496837 (MainThread): Found 15 models, 25 tests, 0 snapshots, 1 analysis, 166 macros, 0 operations, 0 seed files, 15 sources, 0 exposures
2022-01-23 08:11:11.496837 (MainThread): 
2022-01-23 08:11:11.496837 (MainThread): Acquiring new postgres connection "master".
2022-01-23 08:11:11.496837 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-23 08:11:11.512446 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-23 08:11:11.512446 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-23 08:11:11.512446 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-23 08:11:11.619438 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.11 seconds
2022-01-23 08:11:11.619438 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-23 08:11:11.619438 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-23 08:11:11.619438 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-23 08:11:11.619438 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-23 08:11:11.619438 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-23 08:11:11.697545 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.08 seconds
2022-01-23 08:11:11.697545 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-23 08:11:11.713167 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-23 08:11:11.713167 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-23 08:11:11.713167 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-23 08:11:11.713167 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-23 08:11:11.775652 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.06 seconds
2022-01-23 08:11:11.775652 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-23 08:11:11.791273 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_itamar".
2022-01-23 08:11:11.791273 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_itamar".
2022-01-23 08:11:11.791273 (ThreadPoolExecutor-1_0): On list_sakila_wh_itamar: BEGIN
2022-01-23 08:11:11.791273 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-23 08:11:11.869383 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.08 seconds
2022-01-23 08:11:11.869383 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_itamar".
2022-01-23 08:11:11.869383 (ThreadPoolExecutor-1_0): On list_sakila_wh_itamar: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_itamar"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'itamar'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'itamar'
  
2022-01-23 08:11:11.885008 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.02 seconds
2022-01-23 08:11:11.885008 (ThreadPoolExecutor-1_0): On list_sakila_wh_itamar: ROLLBACK
2022-01-23 08:11:11.885008 (ThreadPoolExecutor-1_0): On list_sakila_wh_itamar: Close
2022-01-23 08:11:11.885008 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_examples".
2022-01-23 08:11:11.885008 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_examples".
2022-01-23 08:11:11.885008 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: BEGIN
2022-01-23 08:11:11.885008 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-23 08:11:11.947488 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.06 seconds
2022-01-23 08:11:11.947488 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_examples".
2022-01-23 08:11:11.947488 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'examples'
  
2022-01-23 08:11:11.963110 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.02 seconds
2022-01-23 08:11:11.963110 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: ROLLBACK
2022-01-23 08:11:11.963110 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: Close
2022-01-23 08:11:11.963110 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-23 08:11:11.963110 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-23 08:11:11.963110 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-23 08:11:11.963110 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-23 08:11:12.041219 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.08 seconds
2022-01-23 08:11:12.041219 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-23 08:11:12.041219 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-23 08:11:12.041219 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2022-01-23 08:11:12.041219 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-23 08:11:12.041219 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-23 08:11:12.056834 (MainThread): Using postgres connection "master".
2022-01-23 08:11:12.056834 (MainThread): On master: BEGIN
2022-01-23 08:11:12.056834 (MainThread): Opening a new connection, currently in state init
2022-01-23 08:11:12.119323 (MainThread): SQL status: BEGIN in 0.06 seconds
2022-01-23 08:11:12.119323 (MainThread): Using postgres connection "master".
2022-01-23 08:11:12.119323 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-23 08:11:13.275298 (MainThread): SQL status: SELECT 43 in 1.16 seconds
2022-01-23 08:11:13.275298 (MainThread): On master: ROLLBACK
2022-01-23 08:11:13.275298 (MainThread): Using postgres connection "master".
2022-01-23 08:11:13.275298 (MainThread): On master: BEGIN
2022-01-23 08:11:13.275298 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-23 08:11:13.275298 (MainThread): On master: COMMIT
2022-01-23 08:11:13.275298 (MainThread): Using postgres connection "master".
2022-01-23 08:11:13.275298 (MainThread): On master: COMMIT
2022-01-23 08:11:13.275298 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:13.275298 (MainThread): On master: Close
2022-01-23 08:11:13.275298 (MainThread): 13:41:13 | Concurrency: 1 threads (target='dev')
2022-01-23 08:11:13.275298 (MainThread): 13:41:13 | 
2022-01-23 08:11:13.290921 (Thread-1): Began running node model.sakila_dbt_project.dim_customer
2022-01-23 08:11:13.290921 (Thread-1): 13:41:13 | 1 of 15 START incremental model dwh.dim_customer..................... [RUN]
2022-01-23 08:11:13.290921 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:11:13.290921 (Thread-1): Compiling model.sakila_dbt_project.dim_customer
2022-01-23 08:11:13.290921 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-23 08:11:13.290921 (Thread-1): finished collecting timing info
2022-01-23 08:11:13.394123 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:11:13.394123 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

    

  create temporary table "dim_customer__dbt_tmp134113347255"
  as (
    

with customer_base as (

select
 *,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.active::int as active_int,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
  '2022-01-23 08:11:09'::timestamp as dbt_time
from
	"sakila_wh"."stg"."customer" as customer),

  address as (
    select * from "sakila_wh"."stg"."address"
  ),

  city as (
    select * from "sakila_wh"."stg"."city"
  ),

  country as (
    select * from "sakila_wh"."stg"."country"
  )

  select
  customer_base.customer_id,
  customer_base.store_id,
  customer_base.first_name,
  customer_base.last_name,
  customer_base.full_name,
  customer_base.domain,
  customer_base.email,
  customer_base.active_int as active,
  customer_base.active_desc,

  address.address_id,
  address.address,
  city.city_id,
  city.city,
  country.country_id,
  country.country,

  customer_base.create_date,
  customer_base.last_update,
  customer_base.dbt_time

  from
  customer_base

	left join address on 1=1
	and customer_base.address_id =address.address_id

	left join city on 1=1
	and address.city_id = city.city_id

  left join country on 1=1
  and country.country_id = city.country_id

  where 1=1

  
  and customer_base.last_update::timestamp > (select max(last_update) from "sakila_wh"."dwh"."dim_customer")
  
  );
  
2022-01-23 08:11:13.394123 (Thread-1): Opening a new connection, currently in state init
2022-01-23 08:11:13.565963 (Thread-1): SQL status: SELECT 0 in 0.17 seconds
2022-01-23 08:11:13.597197 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:11:13.597197 (Thread-1): On model.sakila_dbt_project.dim_customer: BEGIN
2022-01-23 08:11:13.597197 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-23 08:11:13.597197 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:11:13.597197 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer__dbt_tmp134113347255'
        
      order by ordinal_position

  
2022-01-23 08:11:13.706564 (Thread-1): SQL status: SELECT 18 in 0.11 seconds
2022-01-23 08:11:13.722210 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:11:13.722210 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 08:11:13.737798 (Thread-1): SQL status: SELECT 18 in 0.02 seconds
2022-01-23 08:11:13.815935 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:11:13.815935 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 08:11:13.815935 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2022-01-23 08:11:13.815935 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-23 08:11:13.815935 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:11:13.815935 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      delete
    from "sakila_wh"."dwh"."dim_customer"
    where (customer_id) in (
        select (customer_id)
        from "dim_customer__dbt_tmp134113347255"
    );

    insert into "sakila_wh"."dwh"."dim_customer" ("customer_id", "store_id", "first_name", "last_name", "full_name", "domain", "email", "active", "active_desc", "address_id", "address", "city_id", "city", "country_id", "country", "create_date", "last_update", "dbt_time")
    (
       select "customer_id", "store_id", "first_name", "last_name", "full_name", "domain", "email", "active", "active_desc", "address_id", "address", "city_id", "city", "country_id", "country", "create_date", "last_update", "dbt_time"
       from "dim_customer__dbt_tmp134113347255"
    );
  
2022-01-23 08:11:13.847161 (Thread-1): SQL status: INSERT 0 0 in 0.02 seconds
2022-01-23 08:11:13.847161 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:13.847161 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:11:13.847161 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

        insert into "sakila_wh"."dwh"."dim_customer"(customer_id) VALUES (-1)
      
2022-01-23 08:11:13.847161 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 08:11:13.862791 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-23 08:11:13.862791 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 08:11:13.862791 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-23 08:11:13.862791 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:13.862791 (Thread-1): finished collecting timing info
2022-01-23 08:11:13.862791 (Thread-1): On model.sakila_dbt_project.dim_customer: Close
2022-01-23 08:11:13.862791 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B512340>]}
2022-01-23 08:11:13.862791 (Thread-1): 13:41:13 | 1 of 15 OK created incremental model dwh.dim_customer................ [INSERT 0 0 in 0.57s]
2022-01-23 08:11:13.862791 (Thread-1): Finished running node model.sakila_dbt_project.dim_customer
2022-01-23 08:11:13.874973 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-23 08:11:13.876968 (Thread-1): 13:41:13 | 2 of 15 START table model dwh.dim_date............................... [RUN]
2022-01-23 08:11:13.878034 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:11:13.878034 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-23 08:11:13.878034 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-23 08:11:13.878034 (Thread-1): finished collecting timing info
2022-01-23 08:11:13.924900 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-23 08:11:13.940520 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:11:13.940520 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-23 08:11:13.940520 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:11:14.025286 (Thread-1): SQL status: BEGIN in 0.08 seconds
2022-01-23 08:11:14.025286 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:11:14.025286 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-23 08:11:14.290861 (Thread-1): SQL status: SELECT 8059 in 0.27 seconds
2022-01-23 08:11:14.306519 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:11:14.306519 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-23 08:11:14.306519 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:14.306519 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:11:14.306519 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-23 08:11:14.322098 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:14.337753 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-23 08:11:14.337753 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:11:14.337753 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-23 08:11:14.337753 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:14.353369 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 08:11:14.353369 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-23 08:11:14.400199 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-23 08:11:14.400199 (Thread-1): finished collecting timing info
2022-01-23 08:11:14.400199 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-23 08:11:14.400199 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B4C4F70>]}
2022-01-23 08:11:14.400199 (Thread-1): 13:41:14 | 2 of 15 OK created table model dwh.dim_date.......................... [SELECT 8059 in 0.52s]
2022-01-23 08:11:14.400199 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-23 08:11:14.400199 (Thread-1): Began running node model.sakila_dbt_project.dim_film
2022-01-23 08:11:14.415829 (Thread-1): 13:41:14 | 3 of 15 START incremental model dwh.dim_film......................... [RUN]
2022-01-23 08:11:14.415829 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:11:14.415829 (Thread-1): Compiling model.sakila_dbt_project.dim_film
2022-01-23 08:11:14.415829 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_film"
2022-01-23 08:11:14.415829 (Thread-1): finished collecting timing info
2022-01-23 08:11:14.431479 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:11:14.431479 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

    

  create temporary table "dim_film__dbt_tmp134114431479"
  as (
    

with stg_film as (
	select
	*,
	(case
	when length<=75 then 'short'
	when (length>75 and length<=120) then 'medium'
	when length>120 then 'long'
	else 'na' end) as length_desc,
	COALESCE(original_language_id,0) as original_language_id_zero,
	case when POSITION('Trailers' in special_features::varchar)>0 then 1 else 0 end  as has_trailers,
	case when POSITION('Commentaries' in special_features::varchar)>0 then 1 else 0 end  as has_commentaries,
	case when POSITION('Deleted Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_deleted_scenes,
	case when POSITION('Behind the Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_behind_the_scenes,
	'2022-01-23 08:11:09'::timestamp as dbt_time
	from
	"sakila_wh"."stg"."film"
),

language as (
	select * from "sakila_wh"."stg"."language"
),

category as (
	select * from "sakila_wh"."stg"."category"
),

film_category as (
	select * from "sakila_wh"."stg"."film_category"
),

stg_film_1 as (
	select
	stg_film.*,
	language.name as lang_name
	from
	stg_film
	left join language on 1=1
	and stg_film.language_id = language.language_id
),

stg_film_2 as (
	select
		stg_film_1.*,
		category.category_id,
		category.name as category_desc
	from
	stg_film_1

	left join film_category on 1=1
	and stg_film_1.film_id = film_category.film_id

	left join category on 1=1
	and film_category.category_id  = category.category_id
)


select
  film_id,
  title,
  description,
  release_year,
  language_id,
  lang_name,
  original_language_id_zero as original_language_id,
  rental_duration,
  rental_rate,
  length,
  length_desc,
  replacement_cost,
  rating,
  category_id,
  category_desc,
  special_features,
  has_trailers,
  has_commentaries,
  has_behind_the_scenes,
  has_deleted_scenes,
  last_update,
	dbt_time
from
stg_film_2

where 1=1


and last_update::timestamp > (select max(last_update) from "sakila_wh"."dwh"."dim_film")

  );
  
2022-01-23 08:11:14.431479 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:11:14.566281 (Thread-1): SQL status: SELECT 0 in 0.13 seconds
2022-01-23 08:11:14.581903 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:11:14.581903 (Thread-1): On model.sakila_dbt_project.dim_film: BEGIN
2022-01-23 08:11:14.581903 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-23 08:11:14.581903 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:11:14.581903 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dim_film__dbt_tmp134114431479'
        
      order by ordinal_position

  
2022-01-23 08:11:14.628766 (Thread-1): SQL status: SELECT 22 in 0.05 seconds
2022-01-23 08:11:14.628766 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:11:14.628766 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_film'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 08:11:14.644388 (Thread-1): SQL status: SELECT 22 in 0.02 seconds
2022-01-23 08:11:14.644388 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:11:14.644388 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_film'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 08:11:14.660008 (Thread-1): SQL status: SELECT 22 in 0.02 seconds
2022-01-23 08:11:14.660008 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_film"
2022-01-23 08:11:14.660008 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:11:14.660008 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      delete
    from "sakila_wh"."dwh"."dim_film"
    where (film_id) in (
        select (film_id)
        from "dim_film__dbt_tmp134114431479"
    );

    insert into "sakila_wh"."dwh"."dim_film" ("film_id", "title", "description", "release_year", "language_id", "lang_name", "original_language_id", "rental_duration", "rental_rate", "length", "length_desc", "replacement_cost", "rating", "category_id", "category_desc", "special_features", "has_trailers", "has_commentaries", "has_behind_the_scenes", "has_deleted_scenes", "last_update", "dbt_time")
    (
       select "film_id", "title", "description", "release_year", "language_id", "lang_name", "original_language_id", "rental_duration", "rental_rate", "length", "length_desc", "replacement_cost", "rating", "category_id", "category_desc", "special_features", "has_trailers", "has_commentaries", "has_behind_the_scenes", "has_deleted_scenes", "last_update", "dbt_time"
       from "dim_film__dbt_tmp134114431479"
    );
  
2022-01-23 08:11:14.675632 (Thread-1): SQL status: INSERT 0 0 in 0.02 seconds
2022-01-23 08:11:14.675632 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:14.682381 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:11:14.682381 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

        insert into "sakila_wh"."dwh"."dim_film"(film_id) VALUES (-1)
      
2022-01-23 08:11:14.685099 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 08:11:14.685099 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-23 08:11:14.685099 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 08:11:14.685099 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-23 08:11:14.685099 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:14.685099 (Thread-1): finished collecting timing info
2022-01-23 08:11:14.685099 (Thread-1): On model.sakila_dbt_project.dim_film: Close
2022-01-23 08:11:14.685099 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B512EB0>]}
2022-01-23 08:11:14.685099 (Thread-1): 13:41:14 | 3 of 15 OK created incremental model dwh.dim_film.................... [INSERT 0 0 in 0.27s]
2022-01-23 08:11:14.685099 (Thread-1): Finished running node model.sakila_dbt_project.dim_film
2022-01-23 08:11:14.685099 (Thread-1): Began running node model.sakila_dbt_project.dim_staff
2022-01-23 08:11:14.685099 (Thread-1): 13:41:14 | 4 of 15 START table model dwh.dim_staff.............................. [RUN]
2022-01-23 08:11:14.685099 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:11:14.700721 (Thread-1): Compiling model.sakila_dbt_project.dim_staff
2022-01-23 08:11:14.700721 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-23 08:11:14.700721 (Thread-1): finished collecting timing info
2022-01-23 08:11:14.716344 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-23 08:11:14.716344 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:11:14.716344 (Thread-1): On model.sakila_dbt_project.dim_staff: BEGIN
2022-01-23 08:11:14.716344 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:11:14.816156 (Thread-1): SQL status: BEGIN in 0.10 seconds
2022-01-23 08:11:14.831775 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:11:14.831775 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */


  create  table "sakila_wh"."dwh"."dim_staff__dbt_tmp"
  as (
    

with staff_base as (
select
*,
(case when active::int = 1 then 1 else 0 end) as "active_int",
(case when active::int = 1 then 'yes' else 'no' end) as "active_desc",
'2022-01-23 08:11:09'::timestamp as dbt_time
from
"sakila_wh"."stg"."staff"
)

select
	staff_id,
	first_name,
	last_name,
	email,
  active_int as active,
  active_desc,
	last_update,
  dbt_time
from
	staff_base
  );
2022-01-23 08:11:14.909881 (Thread-1): SQL status: SELECT 2 in 0.08 seconds
2022-01-23 08:11:14.909881 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:11:14.909881 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
alter table "sakila_wh"."dwh"."dim_staff" rename to "dim_staff__dbt_backup"
2022-01-23 08:11:14.909881 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:14.909881 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:11:14.909881 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
alter table "sakila_wh"."dwh"."dim_staff__dbt_tmp" rename to "dim_staff"
2022-01-23 08:11:14.909881 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:14.909881 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:14.925503 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:11:14.925503 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */

        insert into "sakila_wh"."dwh"."dim_staff"(staff_id) VALUES (-1)
      
2022-01-23 08:11:14.925503 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 08:11:14.925503 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-23 08:11:14.925503 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:11:14.925503 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-23 08:11:14.925503 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:14.925503 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 08:11:14.925503 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
drop table if exists "sakila_wh"."dwh"."dim_staff__dbt_backup" cascade
2022-01-23 08:11:14.925503 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 08:11:14.941125 (Thread-1): finished collecting timing info
2022-01-23 08:11:14.941125 (Thread-1): On model.sakila_dbt_project.dim_staff: Close
2022-01-23 08:11:14.941125 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B244F10>]}
2022-01-23 08:11:14.941125 (Thread-1): 13:41:14 | 4 of 15 OK created table model dwh.dim_staff......................... [SELECT 2 in 0.26s]
2022-01-23 08:11:14.941125 (Thread-1): Finished running node model.sakila_dbt_project.dim_staff
2022-01-23 08:11:14.941125 (Thread-1): Began running node model.sakila_dbt_project.fact_payment
2022-01-23 08:11:14.941125 (Thread-1): 13:41:14 | 5 of 15 START incremental model dwh.fact_payment..................... [RUN]
2022-01-23 08:11:14.941125 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:11:14.941125 (Thread-1): Compiling model.sakila_dbt_project.fact_payment
2022-01-23 08:11:14.956786 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.fact_payment"
2022-01-23 08:11:14.956786 (Thread-1): finished collecting timing info
2022-01-23 08:11:14.956786 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:11:14.956786 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

    

  create temporary table "fact_payment__dbt_tmp134114956786"
  as (
    

select
*,
'2022-01-23 08:11:09' as dbt_time
from
"sakila_wh"."stg"."payment"
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."dwh"."fact_payment")

  );
  
2022-01-23 08:11:14.956786 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:11:15.076967 (Thread-1): SQL status: SELECT 0 in 0.12 seconds
2022-01-23 08:11:15.092588 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:11:15.092588 (Thread-1): On model.sakila_dbt_project.fact_payment: BEGIN
2022-01-23 08:11:15.092588 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-23 08:11:15.092588 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:11:15.092588 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_payment__dbt_tmp134114956786'
        
      order by ordinal_position

  
2022-01-23 08:11:15.139452 (Thread-1): SQL status: SELECT 7 in 0.05 seconds
2022-01-23 08:11:15.139452 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:11:15.155074 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'fact_payment'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 08:11:15.155074 (Thread-1): SQL status: SELECT 7 in 0.00 seconds
2022-01-23 08:11:15.155074 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:11:15.170699 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'fact_payment'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 08:11:15.170699 (Thread-1): SQL status: SELECT 7 in 0.00 seconds
2022-01-23 08:11:15.170699 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.fact_payment"
2022-01-23 08:11:15.170699 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:11:15.170699 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      delete
    from "sakila_wh"."dwh"."fact_payment"
    where (payment_id) in (
        select (payment_id)
        from "fact_payment__dbt_tmp134114956786"
    );

    insert into "sakila_wh"."dwh"."fact_payment" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time"
       from "fact_payment__dbt_tmp134114956786"
    );
  
2022-01-23 08:11:15.186319 (Thread-1): SQL status: INSERT 0 0 in 0.02 seconds
2022-01-23 08:11:15.186319 (Thread-1): On model.sakila_dbt_project.fact_payment: COMMIT
2022-01-23 08:11:15.186319 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 08:11:15.186319 (Thread-1): On model.sakila_dbt_project.fact_payment: COMMIT
2022-01-23 08:11:15.194103 (Thread-1): SQL status: COMMIT in 0.01 seconds
2022-01-23 08:11:15.195100 (Thread-1): finished collecting timing info
2022-01-23 08:11:15.196248 (Thread-1): On model.sakila_dbt_project.fact_payment: Close
2022-01-23 08:11:15.196248 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B244D00>]}
2022-01-23 08:11:15.196248 (Thread-1): 13:41:15 | 5 of 15 OK created incremental model dwh.fact_payment................ [INSERT 0 0 in 0.26s]
2022-01-23 08:11:15.196248 (Thread-1): Finished running node model.sakila_dbt_project.fact_payment
2022-01-23 08:11:15.196248 (Thread-1): Began running node model.sakila_dbt_project.film_test
2022-01-23 08:11:15.196248 (Thread-1): 13:41:15 | 6 of 15 START table model examples.film_test......................... [RUN]
2022-01-23 08:11:15.196248 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:11:15.196248 (Thread-1): Compiling model.sakila_dbt_project.film_test
2022-01-23 08:11:15.196248 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.film_test"
2022-01-23 08:11:15.211870 (Thread-1): finished collecting timing info
2022-01-23 08:11:15.211870 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.film_test"
2022-01-23 08:11:15.211870 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:11:15.211870 (Thread-1): On model.sakila_dbt_project.film_test: BEGIN
2022-01-23 08:11:15.211870 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:11:15.311572 (Thread-1): SQL status: BEGIN in 0.10 seconds
2022-01-23 08:11:15.311572 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:11:15.311572 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */


  create  table "sakila_wh"."examples"."film_test__dbt_tmp"
  as (
    select
*
from
-- sakila_wh.stg.film
"sakila_wh"."stg"."film"
  );
2022-01-23 08:11:15.452169 (Thread-1): SQL status: SELECT 1000 in 0.14 seconds
2022-01-23 08:11:15.467789 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:11:15.467789 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."examples"."film_test" rename to "film_test__dbt_backup"
2022-01-23 08:11:15.467789 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:15.483413 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:11:15.483413 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."examples"."film_test__dbt_tmp" rename to "film_test"
2022-01-23 08:11:15.483413 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:15.483413 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-23 08:11:15.483413 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:11:15.483413 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-23 08:11:15.483413 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:15.499029 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 08:11:15.499029 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
drop table if exists "sakila_wh"."examples"."film_test__dbt_backup" cascade
2022-01-23 08:11:15.514688 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-01-23 08:11:15.514688 (Thread-1): finished collecting timing info
2022-01-23 08:11:15.514688 (Thread-1): On model.sakila_dbt_project.film_test: Close
2022-01-23 08:11:15.514688 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B537A00>]}
2022-01-23 08:11:15.514688 (Thread-1): 13:41:15 | 6 of 15 OK created table model examples.film_test.................... [SELECT 1000 in 0.32s]
2022-01-23 08:11:15.514688 (Thread-1): Finished running node model.sakila_dbt_project.film_test
2022-01-23 08:11:15.514688 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-23 08:11:15.514688 (Thread-1): 13:41:15 | 7 of 15 START table model examples.hello_world....................... [RUN]
2022-01-23 08:11:15.514688 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:11:15.514688 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-23 08:11:15.514688 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-23 08:11:15.530281 (Thread-1): finished collecting timing info
2022-01-23 08:11:15.530281 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-23 08:11:15.530281 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:11:15.530281 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-23 08:11:15.530281 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:11:15.657244 (Thread-1): SQL status: BEGIN in 0.13 seconds
2022-01-23 08:11:15.657244 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:11:15.657244 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."examples"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-23 08:11:15.735352 (Thread-1): SQL status: SELECT 599 in 0.08 seconds
2022-01-23 08:11:15.735352 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:11:15.735352 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."examples"."hello_world" rename to "hello_world__dbt_backup"
2022-01-23 08:11:15.750971 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:15.750971 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:11:15.750971 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-23 08:11:15.750971 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:15.750971 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-23 08:11:15.750971 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:11:15.750971 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-23 08:11:15.750971 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:15.766593 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 08:11:15.766593 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."examples"."hello_world__dbt_backup" cascade
2022-01-23 08:11:15.766593 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 08:11:15.766593 (Thread-1): finished collecting timing info
2022-01-23 08:11:15.766593 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-23 08:11:15.766593 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B52FCD0>]}
2022-01-23 08:11:15.766593 (Thread-1): 13:41:15 | 7 of 15 OK created table model examples.hello_world.................. [SELECT 599 in 0.25s]
2022-01-23 08:11:15.766593 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-23 08:11:15.766593 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-23 08:11:15.766593 (Thread-1): 13:41:15 | 8 of 15 START table model examples.my_first_dbt_model................ [RUN]
2022-01-23 08:11:15.766593 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:11:15.766593 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-23 08:11:15.782214 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-23 08:11:15.782214 (Thread-1): finished collecting timing info
2022-01-23 08:11:15.782214 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-23 08:11:15.782214 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:11:15.782214 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-23 08:11:15.782214 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:11:15.857673 (Thread-1): SQL status: BEGIN in 0.08 seconds
2022-01-23 08:11:15.873294 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:11:15.873294 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-23 08:11:15.888916 (Thread-1): SQL status: SELECT 2 in 0.02 seconds
2022-01-23 08:11:15.904536 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:11:15.904536 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."examples"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-23 08:11:15.904536 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:15.904536 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:11:15.904536 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-23 08:11:15.904536 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:15.904536 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-23 08:11:15.904536 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:11:15.904536 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-23 08:11:15.904536 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:15.920157 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 08:11:15.920157 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-23 08:11:15.920157 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 08:11:15.920157 (Thread-1): finished collecting timing info
2022-01-23 08:11:15.920157 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-23 08:11:15.920157 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B557190>]}
2022-01-23 08:11:15.935779 (Thread-1): 13:41:15 | 8 of 15 OK created table model examples.my_first_dbt_model........... [SELECT 2 in 0.15s]
2022-01-23 08:11:15.935779 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-23 08:11:15.935779 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-23 08:11:15.935779 (Thread-1): 13:41:15 | 9 of 15 START incremental model examples.payment_inc................. [RUN]
2022-01-23 08:11:15.935779 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:11:15.935779 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-23 08:11:15.935779 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-23 08:11:15.935779 (Thread-1): finished collecting timing info
2022-01-23 08:11:15.951401 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:11:15.951401 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

    

  create temporary table "payment_inc__dbt_tmp134115951401"
  as (
    

select
*,
'2022-01-23 08:11:09' as dbt_time
from
stg.payment
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."examples"."payment_inc")



-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-23 08:11:15.951401 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:11:16.090047 (Thread-1): SQL status: SELECT 0 in 0.14 seconds
2022-01-23 08:11:16.090047 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:11:16.090047 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-23 08:11:16.105668 (Thread-1): SQL status: BEGIN in 0.02 seconds
2022-01-23 08:11:16.105668 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:11:16.105668 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc__dbt_tmp134115951401'
        
      order by ordinal_position

  
2022-01-23 08:11:16.121288 (Thread-1): SQL status: SELECT 7 in 0.02 seconds
2022-01-23 08:11:16.136913 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:11:16.136913 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'examples'
        
      order by ordinal_position

  
2022-01-23 08:11:16.136913 (Thread-1): SQL status: SELECT 7 in 0.00 seconds
2022-01-23 08:11:16.152537 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:11:16.152537 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'examples'
        
      order by ordinal_position

  
2022-01-23 08:11:16.152537 (Thread-1): SQL status: SELECT 7 in 0.00 seconds
2022-01-23 08:11:16.152537 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-23 08:11:16.152537 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:11:16.152537 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      delete
    from "sakila_wh"."examples"."payment_inc"
    where (payment_id) in (
        select (payment_id)
        from "payment_inc__dbt_tmp134115951401"
    );

    insert into "sakila_wh"."examples"."payment_inc" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time"
       from "payment_inc__dbt_tmp134115951401"
    );
  
2022-01-23 08:11:16.168153 (Thread-1): SQL status: INSERT 0 0 in 0.00 seconds
2022-01-23 08:11:16.168153 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-23 08:11:16.168153 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 08:11:16.168153 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-23 08:11:16.168153 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:16.168153 (Thread-1): finished collecting timing info
2022-01-23 08:11:16.168153 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-23 08:11:16.168153 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B52FCD0>]}
2022-01-23 08:11:16.168153 (Thread-1): 13:41:16 | 9 of 15 OK created incremental model examples.payment_inc............ [INSERT 0 0 in 0.23s]
2022-01-23 08:11:16.168153 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-23 08:11:16.168153 (Thread-1): Began running node model.sakila_dbt_project.dim_date_inc
2022-01-23 08:11:16.168153 (Thread-1): 13:41:16 | 10 of 15 START incremental model examples.dim_date_inc............... [RUN]
2022-01-23 08:11:16.183774 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:11:16.183774 (Thread-1): Compiling model.sakila_dbt_project.dim_date_inc
2022-01-23 08:11:16.183774 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date_inc"
2022-01-23 08:11:16.183774 (Thread-1): finished collecting timing info
2022-01-23 08:11:16.183774 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:11:16.183774 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

    

  create temporary table "dim_date_inc__dbt_tmp134116183774"
  as (
    


SELECT
*
from "sakila_wh"."dwh"."dim_date"
where 1=1



and date_key::timestamp > (select max(date_key) - INTERVAL '3 DAY' from "sakila_wh"."examples"."dim_date_inc")

  );
  
2022-01-23 08:11:16.183774 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:11:16.304408 (Thread-1): SQL status: SELECT 3 in 0.12 seconds
2022-01-23 08:11:16.304408 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:11:16.304408 (Thread-1): On model.sakila_dbt_project.dim_date_inc: BEGIN
2022-01-23 08:11:16.304408 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-23 08:11:16.304408 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:11:16.304408 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dim_date_inc__dbt_tmp134116183774'
        
      order by ordinal_position

  
2022-01-23 08:11:16.335649 (Thread-1): SQL status: SELECT 26 in 0.03 seconds
2022-01-23 08:11:16.351271 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:11:16.351271 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_date_inc'
        
        and table_schema = 'examples'
        
      order by ordinal_position

  
2022-01-23 08:11:16.351271 (Thread-1): SQL status: SELECT 26 in 0.00 seconds
2022-01-23 08:11:16.366893 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:11:16.366893 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_date_inc'
        
        and table_schema = 'examples'
        
      order by ordinal_position

  
2022-01-23 08:11:16.366893 (Thread-1): SQL status: SELECT 26 in 0.00 seconds
2022-01-23 08:11:16.382516 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date_inc"
2022-01-23 08:11:16.382516 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:11:16.382516 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      delete
    from "sakila_wh"."examples"."dim_date_inc"
    where (date_dim_id) in (
        select (date_dim_id)
        from "dim_date_inc__dbt_tmp134116183774"
    );

    insert into "sakila_wh"."examples"."dim_date_inc" ("date_dim_id", "date_key", "epoch", "day_name", "day_of_week", "day_of_month", "day_of_quarter", "day_of_year", "week_of_month", "week_of_year", "month_actual", "month_name", "month_name_abbreviated", "quarter_actual", "quarter_name", "year_actual", "first_day_of_week", "last_day_of_week", "first_day_of_month", "last_day_of_month", "first_day_of_quarter", "last_day_of_quarter", "first_day_of_year", "last_day_of_year", "yyyymm", "weekend_indr")
    (
       select "date_dim_id", "date_key", "epoch", "day_name", "day_of_week", "day_of_month", "day_of_quarter", "day_of_year", "week_of_month", "week_of_year", "month_actual", "month_name", "month_name_abbreviated", "quarter_actual", "quarter_name", "year_actual", "first_day_of_week", "last_day_of_week", "first_day_of_month", "last_day_of_month", "first_day_of_quarter", "last_day_of_quarter", "first_day_of_year", "last_day_of_year", "yyyymm", "weekend_indr"
       from "dim_date_inc__dbt_tmp134116183774"
    );
  
2022-01-23 08:11:16.382516 (Thread-1): SQL status: INSERT 0 3 in 0.00 seconds
2022-01-23 08:11:16.382516 (Thread-1): On model.sakila_dbt_project.dim_date_inc: COMMIT
2022-01-23 08:11:16.382516 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 08:11:16.382516 (Thread-1): On model.sakila_dbt_project.dim_date_inc: COMMIT
2022-01-23 08:11:16.382516 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:16.382516 (Thread-1): finished collecting timing info
2022-01-23 08:11:16.382516 (Thread-1): On model.sakila_dbt_project.dim_date_inc: Close
2022-01-23 08:11:16.382516 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B570130>]}
2022-01-23 08:11:16.398136 (Thread-1): 13:41:16 | 10 of 15 OK created incremental model examples.dim_date_inc.......... [INSERT 0 3 in 0.21s]
2022-01-23 08:11:16.398136 (Thread-1): Finished running node model.sakila_dbt_project.dim_date_inc
2022-01-23 08:11:16.398136 (Thread-1): Began running node model.sakila_dbt_project.dim_store
2022-01-23 08:11:16.398136 (Thread-1): 13:41:16 | 11 of 15 START table model dwh.dim_store............................. [RUN]
2022-01-23 08:11:16.398136 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:11:16.398136 (Thread-1): Compiling model.sakila_dbt_project.dim_store
2022-01-23 08:11:16.398136 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_store"
2022-01-23 08:11:16.413758 (Thread-1): finished collecting timing info
2022-01-23 08:11:16.413758 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_store"
2022-01-23 08:11:16.413758 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:11:16.413758 (Thread-1): On model.sakila_dbt_project.dim_store: BEGIN
2022-01-23 08:11:16.413758 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:11:16.523857 (Thread-1): SQL status: BEGIN in 0.11 seconds
2022-01-23 08:11:16.523857 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:11:16.523857 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */


  create  table "sakila_wh"."dwh"."dim_store__dbt_tmp"
  as (
    

with stg_store as (
		select
    *,
    '2022-01-23 08:11:09'::timestamp as dbt_time
     from "sakila_wh"."stg"."store"
),

staff as (
 select * from "sakila_wh"."dwh"."dim_staff"
),

address as (
  select * from "sakila_wh"."stg"."address"
),

city as (
  select * from "sakila_wh"."stg"."city"
),

country as (
  select * from "sakila_wh"."stg"."country"
),
stg_store_1 as (-- add staff
		select
		stg_store.*,
		staff.first_name as staff_first_name,
		staff.last_name as staff_last_name
		from
		stg_store
		left join staff  on 1=1
		and stg_store.manager_staff_id = staff.staff_id
),
stg_store_2 as (-- add adress
		select
		stg_store_1.*,
		address.address,
		city.city_id,
		city.city,
		country.country_id,
		country.country
		from
		stg_store_1

		left join address on 1=1
		and stg_store_1.address_id =address.address_id

		left join city on 1=1
		and address.city_id = city.city_id

		left join country on  1=1
		and city.country_id = country.country_id
)

select
  store_id,
  manager_staff_id,
  staff_first_name,
  staff_last_name,
  address_id,
  address,
  city_id,
  city,
  country_id,
  country,
  last_update,
  dbt_time
from stg_store_2
  );
2022-01-23 08:11:16.555099 (Thread-1): SQL status: SELECT 2 in 0.03 seconds
2022-01-23 08:11:16.555099 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:11:16.555099 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
alter table "sakila_wh"."dwh"."dim_store" rename to "dim_store__dbt_backup"
2022-01-23 08:11:16.555099 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:16.555099 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:11:16.570723 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
alter table "sakila_wh"."dwh"."dim_store__dbt_tmp" rename to "dim_store"
2022-01-23 08:11:16.570723 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:16.570723 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 08:11:16.570723 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:11:16.570723 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */

        insert into "sakila_wh"."dwh"."dim_store"(store_id) VALUES (-1)
      
2022-01-23 08:11:16.570723 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 08:11:16.570723 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-23 08:11:16.570723 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:11:16.570723 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-23 08:11:16.633206 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-23 08:11:16.633206 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 08:11:16.633206 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
drop table if exists "sakila_wh"."dwh"."dim_store__dbt_backup" cascade
2022-01-23 08:11:16.633206 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 08:11:16.633206 (Thread-1): finished collecting timing info
2022-01-23 08:11:16.633206 (Thread-1): On model.sakila_dbt_project.dim_store: Close
2022-01-23 08:11:16.633206 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B4FE4C0>]}
2022-01-23 08:11:16.633206 (Thread-1): 13:41:16 | 11 of 15 OK created table model dwh.dim_store........................ [SELECT 2 in 0.24s]
2022-01-23 08:11:16.633206 (Thread-1): Finished running node model.sakila_dbt_project.dim_store
2022-01-23 08:11:16.633206 (Thread-1): Began running node model.sakila_dbt_project.customer_test
2022-01-23 08:11:16.633206 (Thread-1): 13:41:16 | 12 of 15 START table model itamar.customers_alias.................... [RUN]
2022-01-23 08:11:16.633206 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-23 08:11:16.633206 (Thread-1): Compiling model.sakila_dbt_project.customer_test
2022-01-23 08:11:16.648827 (Thread-1): finished collecting timing info
2022-01-23 08:11:16.648827 (Thread-1): Compilation Error in model customer_test (models\example\customer_test.sql)
  Required var 'customer_id' not found in config:
  Vars supplied to customer_test = {}
  
  > in model customer_test (models\example\customer_test.sql)
  > called by model customer_test (models\example\customer_test.sql)
Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\base.py", line 285, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\compile.py", line 33, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\compilation.py", line 544, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\compilation.py", line 384, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\jinja.py", line 598, in get_rendered
    return render_template(template, ctx, node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\jinja.py", line 549, in render_template
    return template.render(ctx)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\environment.py", line 1090, in render
    self.environment.handle_exception()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 7, in top-level template code
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\context\base.py", line 159, in __call__
    return self.get_missing_var(var_name)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\context\base.py", line 140, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\exceptions.py", line 447, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model customer_test (models\example\customer_test.sql)
  Required var 'customer_id' not found in config:
  Vars supplied to customer_test = {}
  
  > in model customer_test (models\example\customer_test.sql)
  > called by model customer_test (models\example\customer_test.sql)
2022-01-23 08:11:16.664454 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B3F5C40>]}
2022-01-23 08:11:16.664454 (Thread-1): 13:41:16 | 12 of 15 ERROR creating table model itamar.customers_alias........... [ERROR in 0.03s]
2022-01-23 08:11:16.664454 (Thread-1): Finished running node model.sakila_dbt_project.customer_test
2022-01-23 08:11:16.664454 (Thread-1): Began running node model.sakila_dbt_project.customer_test_macro
2022-01-23 08:11:16.664454 (Thread-1): 13:41:16 | 13 of 15 START table model examples.customer_test_macro.............. [RUN]
2022-01-23 08:11:16.664454 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.customer_test_macro".
2022-01-23 08:11:16.664454 (Thread-1): Compiling model.sakila_dbt_project.customer_test_macro
2022-01-23 08:11:16.680070 (Thread-1): finished collecting timing info
2022-01-23 08:11:16.680070 (Thread-1): Compilation Error in model customer_test_macro (models\example\customer_test_macro.sql)
  Required var 'customer_id' not found in config:
  Vars supplied to customer_test_macro = {}
  
  > in model customer_test_macro (models\example\customer_test_macro.sql)
  > called by model customer_test_macro (models\example\customer_test_macro.sql)
Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\base.py", line 285, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\compile.py", line 33, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\compilation.py", line 544, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\compilation.py", line 384, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\jinja.py", line 598, in get_rendered
    return render_template(template, ctx, node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\jinja.py", line 549, in render_template
    return template.render(ctx)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\environment.py", line 1090, in render
    self.environment.handle_exception()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\context\base.py", line 159, in __call__
    return self.get_missing_var(var_name)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\context\base.py", line 140, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\exceptions.py", line 447, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model customer_test_macro (models\example\customer_test_macro.sql)
  Required var 'customer_id' not found in config:
  Vars supplied to customer_test_macro = {}
  
  > in model customer_test_macro (models\example\customer_test_macro.sql)
  > called by model customer_test_macro (models\example\customer_test_macro.sql)
2022-01-23 08:11:16.680070 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B25FD60>]}
2022-01-23 08:11:16.680070 (Thread-1): 13:41:16 | 13 of 15 ERROR creating table model examples.customer_test_macro..... [ERROR in 0.02s]
2022-01-23 08:11:16.680070 (Thread-1): Finished running node model.sakila_dbt_project.customer_test_macro
2022-01-23 08:11:16.680070 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-23 08:11:16.695692 (Thread-1): 13:41:16 | 14 of 15 START table model examples.my_second_dbt_model.............. [RUN]
2022-01-23 08:11:16.695692 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:11:16.695692 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-23 08:11:16.695692 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-23 08:11:16.695692 (Thread-1): finished collecting timing info
2022-01-23 08:11:16.711368 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-23 08:11:16.711368 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:11:16.711368 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-23 08:11:16.711368 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:11:16.829360 (Thread-1): SQL status: BEGIN in 0.12 seconds
2022-01-23 08:11:16.829360 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:11:16.829360 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."examples"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."examples"."my_first_dbt_model"
where id = 1
  );
2022-01-23 08:11:16.844980 (Thread-1): SQL status: SELECT 1 in 0.02 seconds
2022-01-23 08:11:16.844980 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:11:16.844980 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."examples"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-23 08:11:16.844980 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:16.860603 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:11:16.860603 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-23 08:11:16.860603 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 08:11:16.860603 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-23 08:11:16.860603 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:11:16.860603 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-23 08:11:16.860603 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:16.876224 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 08:11:16.876224 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-23 08:11:16.876224 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 08:11:16.876224 (Thread-1): finished collecting timing info
2022-01-23 08:11:16.876224 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-23 08:11:16.876224 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B4D3EE0>]}
2022-01-23 08:11:16.876224 (Thread-1): 13:41:16 | 14 of 15 OK created table model examples.my_second_dbt_model......... [SELECT 1 in 0.18s]
2022-01-23 08:11:16.876224 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-23 08:11:16.891844 (Thread-1): Began running node model.sakila_dbt_project.fact_rental
2022-01-23 08:11:16.891844 (Thread-1): 13:41:16 | 15 of 15 START incremental model dwh.fact_rental..................... [RUN]
2022-01-23 08:11:16.891844 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:11:16.891844 (Thread-1): Compiling model.sakila_dbt_project.fact_rental
2022-01-23 08:11:16.907466 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.fact_rental"
2022-01-23 08:11:16.907466 (Thread-1): finished collecting timing info
2022-01-23 08:11:16.907466 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:11:16.907466 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

    

  create temporary table "fact_rental__dbt_tmp134116907466"
  as (
    

with rental_base as (--base
select
	*,
	EXTRACT(EPOCH from rental_date::timestamp) as rental_epoch,
	EXTRACT(EPOCH from return_date::timestamp) as return_epoch,
	EXTRACT(EPOCH from return_date::timestamp)-EXTRACT(EPOCH from rental_date::timestamp) as diff,
	(case when return_date is not null then 1 else 0 end) as is_return,
	to_char(rental_date::timestamp, 'YYYYMMDD')::integer as date_key,
  '2022-01-23 08:11:09'::timestamp as dbt_time

	from
	"sakila_wh"."stg"."rental"
),

inventory as (
	select * from "sakila_wh"."stg"."inventory"
),

dim_film as (
	select * from "sakila_wh"."dwh"."dim_film"
),

dim_store as (
	select * from "sakila_wh"."dwh"."dim_store"
),

dim_staff as (
	select * from "sakila_wh"."dwh"."dim_staff"
),

dim_customer as (
	select * from "sakila_wh"."dwh"."dim_customer"
),

rental_base_1 as (-- join base with inventory
	select
	rental_base.*,
	inventory.store_id,
  inventory.film_id
	from
	rental_base

	inner join inventory on 1=1
	and inventory.inventory_id = rental_base.inventory_id
),


rental_base_2 as (--check direct integrity
	select
	rental_base_1.*,
	(case when dim_staff.staff_id is not null then dim_staff.staff_id else -1 end) as staff_id_rental_check,
	(case when dim_customer.customer_id is not null then dim_customer.customer_id else -1 end) as customer_id_check,
  (case when dim_film.film_id is not null then dim_film.film_id else -1 end) as film_id_check,
	(case when dim_store.store_id is not null then dim_store.store_id else -1 end) as store_id_check
	from
	rental_base_1

	left join
  dim_staff
  on 1=1
	and rental_base_1.staff_id = dim_staff.staff_id

	left join
  dim_customer
  on 1=1
	and rental_base_1.customer_id = dim_customer.customer_id

  left join
  dim_film
  on 1=1
  and  rental_base_1.film_id = dim_film.film_id

  left join
  dim_store
  on 1=1
  and  rental_base_1.store_id = dim_store.store_id
)

select
  rental_id,
  rental_date,
  date_key,
  inventory_id,
  customer_id_check as customer_id,
  film_id_check as film_id,
  store_id_check as store_id,
  staff_id_rental_check as staff_id_rental,
  return_date,
  case when return_date is not null then diff/3600 else null end rental_hours,
  is_return,
  last_update,
  dbt_time
from
 rental_base_2
 where 1=1

 
 and last_update::timestamp > (select max(last_update) from "sakila_wh"."dwh"."fact_rental")
 

 --  - INTERVAL '10 minutes'
  );
  
2022-01-23 08:11:16.907466 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 08:11:17.025491 (Thread-1): SQL status: SELECT 0 in 0.12 seconds
2022-01-23 08:11:17.025491 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:11:17.025491 (Thread-1): On model.sakila_dbt_project.fact_rental: BEGIN
2022-01-23 08:11:17.025491 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-23 08:11:17.025491 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:11:17.025491 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_rental__dbt_tmp134116907466'
        
      order by ordinal_position

  
2022-01-23 08:11:17.072354 (Thread-1): SQL status: SELECT 13 in 0.05 seconds
2022-01-23 08:11:17.072354 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:11:17.072354 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'fact_rental'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 08:11:17.087975 (Thread-1): SQL status: SELECT 13 in 0.02 seconds
2022-01-23 08:11:17.087975 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:11:17.087975 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'fact_rental'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 08:11:17.103602 (Thread-1): SQL status: SELECT 13 in 0.02 seconds
2022-01-23 08:11:17.103602 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.fact_rental"
2022-01-23 08:11:17.103602 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:11:17.103602 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      delete
    from "sakila_wh"."dwh"."fact_rental"
    where (rental_id) in (
        select (rental_id)
        from "fact_rental__dbt_tmp134116907466"
    );

    insert into "sakila_wh"."dwh"."fact_rental" ("rental_id", "rental_date", "date_key", "inventory_id", "customer_id", "film_id", "store_id", "staff_id_rental", "return_date", "rental_hours", "is_return", "last_update", "dbt_time")
    (
       select "rental_id", "rental_date", "date_key", "inventory_id", "customer_id", "film_id", "store_id", "staff_id_rental", "return_date", "rental_hours", "is_return", "last_update", "dbt_time"
       from "fact_rental__dbt_tmp134116907466"
    );
  
2022-01-23 08:11:17.103602 (Thread-1): SQL status: INSERT 0 0 in 0.00 seconds
2022-01-23 08:11:17.103602 (Thread-1): On model.sakila_dbt_project.fact_rental: COMMIT
2022-01-23 08:11:17.103602 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 08:11:17.103602 (Thread-1): On model.sakila_dbt_project.fact_rental: COMMIT
2022-01-23 08:11:17.103602 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:17.103602 (Thread-1): finished collecting timing info
2022-01-23 08:11:17.103602 (Thread-1): On model.sakila_dbt_project.fact_rental: Close
2022-01-23 08:11:17.103602 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '447166c0-a8cd-47ed-9ecd-448e2e147720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B3F5790>]}
2022-01-23 08:11:17.103602 (Thread-1): 13:41:17 | 15 of 15 OK created incremental model dwh.fact_rental................ [INSERT 0 0 in 0.21s]
2022-01-23 08:11:17.103602 (Thread-1): Finished running node model.sakila_dbt_project.fact_rental
2022-01-23 08:11:17.119219 (MainThread): Acquiring new postgres connection "master".
2022-01-23 08:11:17.119219 (MainThread): Using postgres connection "master".
2022-01-23 08:11:17.119219 (MainThread): On master: BEGIN
2022-01-23 08:11:17.119219 (MainThread): Opening a new connection, currently in state closed
2022-01-23 08:11:17.202567 (MainThread): SQL status: BEGIN in 0.08 seconds
2022-01-23 08:11:17.202567 (MainThread): On master: COMMIT
2022-01-23 08:11:17.202567 (MainThread): Using postgres connection "master".
2022-01-23 08:11:17.202567 (MainThread): On master: COMMIT
2022-01-23 08:11:17.202567 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-23 08:11:17.202567 (MainThread): On master: Close
2022-01-23 08:11:17.218188 (MainThread): 13:41:17 | 
2022-01-23 08:11:17.218188 (MainThread): 13:41:17 | Finished running 6 incremental models, 9 table models in 5.72s.
2022-01-23 08:11:17.218188 (MainThread): Connection 'master' was properly closed.
2022-01-23 08:11:17.218188 (MainThread): Connection 'list_sakila_wh' was properly closed.
2022-01-23 08:11:17.218188 (MainThread): Connection 'list_sakila_wh_dwh' was properly closed.
2022-01-23 08:11:17.218188 (MainThread): Connection 'model.sakila_dbt_project.fact_rental' was properly closed.
2022-01-23 08:11:17.233807 (MainThread): 
2022-01-23 08:11:17.233807 (MainThread): Completed with 2 errors and 0 warnings:
2022-01-23 08:11:17.233807 (MainThread): 
2022-01-23 08:11:17.233807 (MainThread): Compilation Error in model customer_test (models\example\customer_test.sql)
2022-01-23 08:11:17.233807 (MainThread):   Required var 'customer_id' not found in config:
2022-01-23 08:11:17.233807 (MainThread):   Vars supplied to customer_test = {}
2022-01-23 08:11:17.233807 (MainThread):   
2022-01-23 08:11:17.233807 (MainThread):   > in model customer_test (models\example\customer_test.sql)
2022-01-23 08:11:17.233807 (MainThread):   > called by model customer_test (models\example\customer_test.sql)
2022-01-23 08:11:17.233807 (MainThread): 
2022-01-23 08:11:17.233807 (MainThread): Compilation Error in model customer_test_macro (models\example\customer_test_macro.sql)
2022-01-23 08:11:17.233807 (MainThread):   Required var 'customer_id' not found in config:
2022-01-23 08:11:17.233807 (MainThread):   Vars supplied to customer_test_macro = {}
2022-01-23 08:11:17.233807 (MainThread):   
2022-01-23 08:11:17.249427 (MainThread):   > in model customer_test_macro (models\example\customer_test_macro.sql)
2022-01-23 08:11:17.249427 (MainThread):   > called by model customer_test_macro (models\example\customer_test_macro.sql)
2022-01-23 08:11:17.249427 (MainThread): 
Done. PASS=13 WARN=0 ERROR=2 SKIP=0 TOTAL=15
2022-01-23 08:11:17.249427 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B3F9B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B520520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023E1B5203D0>]}
2022-01-23 08:11:17.249427 (MainThread): Flushing usage events
2022-01-23 18:14:36.535150 (MainThread): Running with dbt=0.21.1
2022-01-23 18:14:36.847582 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-23 18:14:36.894572 (MainThread): Tracking: tracking
2022-01-23 18:14:36.925691 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B6E9CA60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B6FA44F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B6FA4FA0>]}
2022-01-23 18:14:36.956927 (MainThread): Partial parsing not enabled
2022-01-23 18:14:37.996657 (MainThread): Parsing macros\concat_it.sql
2022-01-23 18:14:37.996657 (MainThread): Parsing macros\delete_from_table.sql
2022-01-23 18:14:37.996657 (MainThread): Parsing macros\generate_schema_name.sql
2022-01-23 18:14:37.996657 (MainThread): Parsing macros\logit.sql
2022-01-23 18:14:38.033854 (MainThread): Parsing macros\adapters.sql
2022-01-23 18:14:38.062858 (MainThread): Parsing macros\catalog.sql
2022-01-23 18:14:38.062858 (MainThread): Parsing macros\relations.sql
2022-01-23 18:14:38.078520 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-23 18:14:38.078520 (MainThread): Parsing macros\core.sql
2022-01-23 18:14:38.078520 (MainThread): Parsing macros\adapters\common.sql
2022-01-23 18:14:38.203486 (MainThread): Parsing macros\etc\datetime.sql
2022-01-23 18:14:38.203486 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-23 18:14:38.219116 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-23 18:14:38.219116 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-23 18:14:38.219116 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-23 18:14:38.219116 (MainThread): Parsing macros\etc\query.sql
2022-01-23 18:14:38.219116 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-23 18:14:38.234732 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-23 18:14:38.250354 (MainThread): Parsing macros\materializations\test.sql
2022-01-23 18:14:38.250354 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-23 18:14:38.281595 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-23 18:14:38.281595 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-23 18:14:38.297220 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-23 18:14:38.328460 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-23 18:14:38.375285 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-23 18:14:38.437771 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-23 18:14:38.437771 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-23 18:14:38.469052 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-23 18:14:38.484635 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-23 18:14:38.484635 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-23 18:14:38.500294 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-23 18:14:38.500294 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-23 18:14:38.500294 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-23 18:14:38.515917 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-23 18:14:38.843960 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 18:14:38.859589 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.859589 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 18:14:38.875208 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.875208 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 18:14:38.875208 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.890831 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 18:14:38.890831 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.890831 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 18:14:38.906467 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.906467 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-23 18:14:38.906467 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.906467 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.906467 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test_macro".
2022-01-23 18:14:38.922074 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.922074 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 18:14:38.922074 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.937695 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 18:14:38.937695 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.937695 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 18:14:38.937695 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.937695 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 18:14:38.953321 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.953321 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 18:14:38.953321 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.953321 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 18:14:38.968944 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:38.968944 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 18:14:38.984560 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 18:14:39.000180 (MainThread): Acquiring new postgres connection "analysis.sakila_dbt_project.example".
2022-01-23 18:14:39.015808 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_cost_30".
2022-01-23 18:14:39.031421 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.078290 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.078290 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.078290 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.093906 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.093906 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.093906 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.093906 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.093906 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.109529 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.109529 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.140770 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.156395 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.156395 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.156395 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.156395 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.156395 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.187641 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.187641 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.187641 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.187641 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.203259 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.203259 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.218843 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.218843 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:39.265702 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B6F7DE50>]}
2022-01-23 18:14:39.296945 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-23 18:14:39.296945 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B6F7D280>]}
2022-01-23 18:14:39.296945 (MainThread): Found 15 models, 25 tests, 0 snapshots, 1 analysis, 166 macros, 0 operations, 0 seed files, 15 sources, 0 exposures
2022-01-23 18:14:39.312571 (MainThread): 
2022-01-23 18:14:39.312571 (MainThread): Acquiring new postgres connection "master".
2022-01-23 18:14:39.312571 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-23 18:14:39.343809 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-23 18:14:39.343809 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-23 18:14:39.343809 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-23 18:14:39.484401 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.14 seconds
2022-01-23 18:14:39.484401 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-23 18:14:39.484401 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-23 18:14:39.500035 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-23 18:14:39.500035 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-23 18:14:39.500035 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-23 18:14:39.578136 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.08 seconds
2022-01-23 18:14:39.578136 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-23 18:14:39.578136 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-23 18:14:39.578136 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-23 18:14:39.593750 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-23 18:14:39.593750 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-23 18:14:39.656235 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.06 seconds
2022-01-23 18:14:39.656235 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-23 18:14:39.656235 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_examples".
2022-01-23 18:14:39.671856 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_examples".
2022-01-23 18:14:39.671856 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: BEGIN
2022-01-23 18:14:39.671856 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-23 18:14:39.765649 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.09 seconds
2022-01-23 18:14:39.765649 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_examples".
2022-01-23 18:14:39.765649 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'examples'
  
2022-01-23 18:14:39.953096 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.19 seconds
2022-01-23 18:14:39.953096 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: ROLLBACK
2022-01-23 18:14:39.953096 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: Close
2022-01-23 18:14:39.953096 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-23 18:14:39.968665 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-23 18:14:39.968665 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-23 18:14:39.968665 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-23 18:14:40.031179 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.06 seconds
2022-01-23 18:14:40.031179 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-23 18:14:40.046826 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-23 18:14:40.046826 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2022-01-23 18:14:40.046826 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-23 18:14:40.046826 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-23 18:14:40.046826 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_itamar".
2022-01-23 18:14:40.062392 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_itamar".
2022-01-23 18:14:40.062392 (ThreadPoolExecutor-1_0): On list_sakila_wh_itamar: BEGIN
2022-01-23 18:14:40.062392 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-23 18:14:40.124874 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.06 seconds
2022-01-23 18:14:40.124874 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_itamar".
2022-01-23 18:14:40.124874 (ThreadPoolExecutor-1_0): On list_sakila_wh_itamar: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_itamar"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'itamar'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'itamar'
  
2022-01-23 18:14:40.140495 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.02 seconds
2022-01-23 18:14:40.140495 (ThreadPoolExecutor-1_0): On list_sakila_wh_itamar: ROLLBACK
2022-01-23 18:14:40.140495 (ThreadPoolExecutor-1_0): On list_sakila_wh_itamar: Close
2022-01-23 18:14:40.140495 (MainThread): Using postgres connection "master".
2022-01-23 18:14:40.140495 (MainThread): On master: BEGIN
2022-01-23 18:14:40.140495 (MainThread): Opening a new connection, currently in state init
2022-01-23 18:14:40.218605 (MainThread): SQL status: BEGIN in 0.08 seconds
2022-01-23 18:14:40.218605 (MainThread): Using postgres connection "master".
2022-01-23 18:14:40.218605 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-23 18:14:41.515175 (MainThread): SQL status: SELECT 43 in 1.30 seconds
2022-01-23 18:14:41.515175 (MainThread): On master: ROLLBACK
2022-01-23 18:14:41.515175 (MainThread): Using postgres connection "master".
2022-01-23 18:14:41.515175 (MainThread): On master: BEGIN
2022-01-23 18:14:41.530796 (MainThread): SQL status: BEGIN in 0.02 seconds
2022-01-23 18:14:41.530796 (MainThread): On master: COMMIT
2022-01-23 18:14:41.530796 (MainThread): Using postgres connection "master".
2022-01-23 18:14:41.530796 (MainThread): On master: COMMIT
2022-01-23 18:14:41.530796 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-23 18:14:41.530796 (MainThread): On master: Close
2022-01-23 18:14:41.530796 (MainThread): 23:44:41 | Concurrency: 1 threads (target='dev')
2022-01-23 18:14:41.530796 (MainThread): 23:44:41 | 
2022-01-23 18:14:41.593374 (Thread-1): Began running node model.sakila_dbt_project.dim_customer
2022-01-23 18:14:41.593374 (Thread-1): 23:44:41 | 1 of 15 START incremental model dwh.dim_customer..................... [RUN]
2022-01-23 18:14:41.593374 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 18:14:41.593374 (Thread-1): Compiling model.sakila_dbt_project.dim_customer
2022-01-23 18:14:41.624560 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-23 18:14:41.655856 (Thread-1): finished collecting timing info
2022-01-23 18:14:41.796358 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 18:14:41.796358 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

    

  create temporary table "dim_customer__dbt_tmp234441733873"
  as (
    

with customer_base as (

select
 *,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.active::int as active_int,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
  '2022-01-23 18:14:36'::timestamp as dbt_time
from
	"sakila_wh"."stg"."customer" as customer),

  address as (
    select * from "sakila_wh"."stg"."address"
  ),

  city as (
    select * from "sakila_wh"."stg"."city"
  ),

  country as (
    select * from "sakila_wh"."stg"."country"
  )

  select
  customer_base.customer_id,
  customer_base.store_id,
  customer_base.first_name,
  customer_base.last_name,
  customer_base.full_name,
  customer_base.domain,
  customer_base.email,
  customer_base.active_int as active,
  customer_base.active_desc,

  address.address_id,
  address.address,
  city.city_id,
  city.city,
  country.country_id,
  country.country,

  customer_base.create_date,
  customer_base.last_update,
  customer_base.dbt_time

  from
  customer_base

	left join address on 1=1
	and customer_base.address_id =address.address_id

	left join city on 1=1
	and address.city_id = city.city_id

  left join country on 1=1
  and country.country_id = city.country_id

  where 1=1

  
  and customer_base.last_update::timestamp > (select max(last_update) from "sakila_wh"."dwh"."dim_customer")
  
  );
  
2022-01-23 18:14:41.796358 (Thread-1): Opening a new connection, currently in state init
2022-01-23 18:14:42.733678 (Thread-1): SQL status: SELECT 0 in 0.94 seconds
2022-01-23 18:14:42.749263 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 18:14:42.749263 (Thread-1): On model.sakila_dbt_project.dim_customer: BEGIN
2022-01-23 18:14:42.749263 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-23 18:14:42.749263 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 18:14:42.749263 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer__dbt_tmp234441733873'
        
      order by ordinal_position

  
2022-01-23 18:14:42.983582 (Thread-1): SQL status: SELECT 18 in 0.23 seconds
2022-01-23 18:14:42.999204 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 18:14:42.999204 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 18:14:43.030499 (Thread-1): SQL status: SELECT 18 in 0.03 seconds
2022-01-23 18:14:43.046065 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 18:14:43.046065 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 18:14:43.061735 (Thread-1): SQL status: SELECT 18 in 0.02 seconds
2022-01-23 18:14:43.061735 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-23 18:14:43.093036 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 18:14:43.093036 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      delete
    from "sakila_wh"."dwh"."dim_customer"
    where (customer_id) in (
        select (customer_id)
        from "dim_customer__dbt_tmp234441733873"
    );

    insert into "sakila_wh"."dwh"."dim_customer" ("customer_id", "store_id", "first_name", "last_name", "full_name", "domain", "email", "active", "active_desc", "address_id", "address", "city_id", "city", "country_id", "country", "create_date", "last_update", "dbt_time")
    (
       select "customer_id", "store_id", "first_name", "last_name", "full_name", "domain", "email", "active", "active_desc", "address_id", "address", "city_id", "city", "country_id", "country", "create_date", "last_update", "dbt_time"
       from "dim_customer__dbt_tmp234441733873"
    );
  
2022-01-23 18:14:43.155447 (Thread-1): SQL status: INSERT 0 0 in 0.06 seconds
2022-01-23 18:14:43.186677 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:43.186677 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 18:14:43.186677 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

        insert into "sakila_wh"."dwh"."dim_customer"(customer_id) VALUES (-1)
      
2022-01-23 18:14:43.186677 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 18:14:43.202278 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-23 18:14:43.202278 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-23 18:14:43.202278 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-23 18:14:43.217931 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-23 18:14:43.217931 (Thread-1): finished collecting timing info
2022-01-23 18:14:43.217931 (Thread-1): On model.sakila_dbt_project.dim_customer: Close
2022-01-23 18:14:43.217931 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B6E969D0>]}
2022-01-23 18:14:43.217931 (Thread-1): 23:44:43 | 1 of 15 OK created incremental model dwh.dim_customer................ [INSERT 0 0 in 1.62s]
2022-01-23 18:14:43.217931 (Thread-1): Finished running node model.sakila_dbt_project.dim_customer
2022-01-23 18:14:43.217931 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-23 18:14:43.217931 (Thread-1): 23:44:43 | 2 of 15 START table model dwh.dim_date............................... [RUN]
2022-01-23 18:14:43.217931 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 18:14:43.217931 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-23 18:14:43.217931 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-23 18:14:43.233640 (Thread-1): finished collecting timing info
2022-01-23 18:14:43.264763 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-23 18:14:43.280513 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 18:14:43.280513 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-23 18:14:43.280513 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 18:14:43.374112 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-23 18:14:43.374112 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 18:14:43.374112 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-23 18:14:43.795888 (Thread-1): SQL status: SELECT 8059 in 0.42 seconds
2022-01-23 18:14:43.811545 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 18:14:43.811545 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-23 18:14:43.858492 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-23 18:14:43.858492 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 18:14:43.858492 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-23 18:14:43.858492 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:43.889622 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-23 18:14:43.889622 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 18:14:43.889622 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-23 18:14:43.889622 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 18:14:43.905239 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-23 18:14:43.905239 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-23 18:14:44.061536 (Thread-1): SQL status: DROP TABLE in 0.16 seconds
2022-01-23 18:14:44.061536 (Thread-1): finished collecting timing info
2022-01-23 18:14:44.061536 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-23 18:14:44.061536 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B71F06D0>]}
2022-01-23 18:14:44.077111 (Thread-1): 23:44:44 | 2 of 15 OK created table model dwh.dim_date.......................... [SELECT 8059 in 0.84s]
2022-01-23 18:14:44.077111 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-23 18:14:44.077111 (Thread-1): Began running node model.sakila_dbt_project.dim_film
2022-01-23 18:14:44.077111 (Thread-1): 23:44:44 | 3 of 15 START incremental model dwh.dim_film......................... [RUN]
2022-01-23 18:14:44.077111 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 18:14:44.077111 (Thread-1): Compiling model.sakila_dbt_project.dim_film
2022-01-23 18:14:44.108324 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_film"
2022-01-23 18:14:44.123968 (Thread-1): finished collecting timing info
2022-01-23 18:14:44.123968 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 18:14:44.123968 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

    

  create temporary table "dim_film__dbt_tmp234444123968"
  as (
    

with stg_film as (
	select
	*,
	(case
	when length<=75 then 'short'
	when (length>75 and length<=120) then 'medium'
	when length>120 then 'long'
	else 'na' end) as length_desc,
	COALESCE(original_language_id,0) as original_language_id_zero,
	case when POSITION('Trailers' in special_features::varchar)>0 then 1 else 0 end  as has_trailers,
	case when POSITION('Commentaries' in special_features::varchar)>0 then 1 else 0 end  as has_commentaries,
	case when POSITION('Deleted Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_deleted_scenes,
	case when POSITION('Behind the Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_behind_the_scenes,
	'2022-01-23 18:14:36'::timestamp as dbt_time
	from
	"sakila_wh"."stg"."film"
),

language as (
	select * from "sakila_wh"."stg"."language"
),

category as (
	select * from "sakila_wh"."stg"."category"
),

film_category as (
	select * from "sakila_wh"."stg"."film_category"
),

stg_film_1 as (
	select
	stg_film.*,
	language.name as lang_name
	from
	stg_film
	left join language on 1=1
	and stg_film.language_id = language.language_id
),

stg_film_2 as (
	select
		stg_film_1.*,
		category.category_id,
		category.name as category_desc
	from
	stg_film_1

	left join film_category on 1=1
	and stg_film_1.film_id = film_category.film_id

	left join category on 1=1
	and film_category.category_id  = category.category_id
)


select
  film_id,
  title,
  description,
  release_year,
  language_id,
  lang_name,
  original_language_id_zero as original_language_id,
  rental_duration,
  rental_rate,
  length,
  length_desc,
  replacement_cost,
  rating,
  category_id,
  category_desc,
  special_features,
  has_trailers,
  has_commentaries,
  has_behind_the_scenes,
  has_deleted_scenes,
  last_update,
	dbt_time
from
stg_film_2

where 1=1


and last_update::timestamp > (select max(last_update) from "sakila_wh"."dwh"."dim_film")

  );
  
2022-01-23 18:14:44.123968 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 18:14:44.670695 (Thread-1): SQL status: SELECT 0 in 0.55 seconds
2022-01-23 18:14:44.670695 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 18:14:44.670695 (Thread-1): On model.sakila_dbt_project.dim_film: BEGIN
2022-01-23 18:14:44.686314 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-23 18:14:44.686314 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 18:14:44.686314 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dim_film__dbt_tmp234444123968'
        
      order by ordinal_position

  
2022-01-23 18:14:44.717586 (Thread-1): SQL status: SELECT 22 in 0.03 seconds
2022-01-23 18:14:44.717586 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 18:14:44.717586 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_film'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 18:14:44.733302 (Thread-1): SQL status: SELECT 22 in 0.02 seconds
2022-01-23 18:14:44.748790 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 18:14:44.748790 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_film'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 18:14:44.748790 (Thread-1): SQL status: SELECT 22 in 0.00 seconds
2022-01-23 18:14:44.764412 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_film"
2022-01-23 18:14:44.764412 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 18:14:44.764412 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      delete
    from "sakila_wh"."dwh"."dim_film"
    where (film_id) in (
        select (film_id)
        from "dim_film__dbt_tmp234444123968"
    );

    insert into "sakila_wh"."dwh"."dim_film" ("film_id", "title", "description", "release_year", "language_id", "lang_name", "original_language_id", "rental_duration", "rental_rate", "length", "length_desc", "replacement_cost", "rating", "category_id", "category_desc", "special_features", "has_trailers", "has_commentaries", "has_behind_the_scenes", "has_deleted_scenes", "last_update", "dbt_time")
    (
       select "film_id", "title", "description", "release_year", "language_id", "lang_name", "original_language_id", "rental_duration", "rental_rate", "length", "length_desc", "replacement_cost", "rating", "category_id", "category_desc", "special_features", "has_trailers", "has_commentaries", "has_behind_the_scenes", "has_deleted_scenes", "last_update", "dbt_time"
       from "dim_film__dbt_tmp234444123968"
    );
  
2022-01-23 18:14:44.780067 (Thread-1): SQL status: INSERT 0 0 in 0.02 seconds
2022-01-23 18:14:44.780067 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:44.780067 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 18:14:44.780067 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

        insert into "sakila_wh"."dwh"."dim_film"(film_id) VALUES (-1)
      
2022-01-23 18:14:44.811391 (Thread-1): SQL status: INSERT 0 1 in 0.03 seconds
2022-01-23 18:14:44.811391 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-23 18:14:44.811391 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-23 18:14:44.811391 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-23 18:14:44.811391 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 18:14:44.811391 (Thread-1): finished collecting timing info
2022-01-23 18:14:44.811391 (Thread-1): On model.sakila_dbt_project.dim_film: Close
2022-01-23 18:14:44.811391 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B6E96100>]}
2022-01-23 18:14:44.811391 (Thread-1): 23:44:44 | 3 of 15 OK created incremental model dwh.dim_film.................... [INSERT 0 0 in 0.73s]
2022-01-23 18:14:44.811391 (Thread-1): Finished running node model.sakila_dbt_project.dim_film
2022-01-23 18:14:44.811391 (Thread-1): Began running node model.sakila_dbt_project.dim_staff
2022-01-23 18:14:44.811391 (Thread-1): 23:44:44 | 4 of 15 START table model dwh.dim_staff.............................. [RUN]
2022-01-23 18:14:44.811391 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 18:14:44.811391 (Thread-1): Compiling model.sakila_dbt_project.dim_staff
2022-01-23 18:14:44.826896 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-23 18:14:44.842518 (Thread-1): finished collecting timing info
2022-01-23 18:14:44.842518 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-23 18:14:44.873761 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 18:14:44.873761 (Thread-1): On model.sakila_dbt_project.dim_staff: BEGIN
2022-01-23 18:14:44.873761 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 18:14:44.967488 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-23 18:14:44.967488 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 18:14:44.967488 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */


  create  table "sakila_wh"."dwh"."dim_staff__dbt_tmp"
  as (
    

with staff_base as (
select
*,
(case when active::int = 1 then 1 else 0 end) as "active_int",
(case when active::int = 1 then 'yes' else 'no' end) as "active_desc",
'2022-01-23 18:14:36'::timestamp as dbt_time
from
"sakila_wh"."stg"."staff"
)

select
	staff_id,
	first_name,
	last_name,
	email,
  active_int as active,
  active_desc,
	last_update,
  dbt_time
from
	staff_base
  );
2022-01-23 18:14:45.061216 (Thread-1): SQL status: SELECT 2 in 0.09 seconds
2022-01-23 18:14:45.076839 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 18:14:45.076839 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
alter table "sakila_wh"."dwh"."dim_staff" rename to "dim_staff__dbt_backup"
2022-01-23 18:14:45.076839 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:45.076839 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 18:14:45.076839 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
alter table "sakila_wh"."dwh"."dim_staff__dbt_tmp" rename to "dim_staff"
2022-01-23 18:14:45.076839 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:45.092459 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:45.092459 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 18:14:45.092459 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */

        insert into "sakila_wh"."dwh"."dim_staff"(staff_id) VALUES (-1)
      
2022-01-23 18:14:45.092459 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 18:14:45.092459 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-23 18:14:45.092459 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 18:14:45.092459 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-23 18:14:45.108079 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-23 18:14:45.108079 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-23 18:14:45.108079 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
drop table if exists "sakila_wh"."dwh"."dim_staff__dbt_backup" cascade
2022-01-23 18:14:45.123703 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-01-23 18:14:45.123703 (Thread-1): finished collecting timing info
2022-01-23 18:14:45.123703 (Thread-1): On model.sakila_dbt_project.dim_staff: Close
2022-01-23 18:14:45.123703 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B7229B80>]}
2022-01-23 18:14:45.123703 (Thread-1): 23:44:45 | 4 of 15 OK created table model dwh.dim_staff......................... [SELECT 2 in 0.31s]
2022-01-23 18:14:45.123703 (Thread-1): Finished running node model.sakila_dbt_project.dim_staff
2022-01-23 18:14:45.123703 (Thread-1): Began running node model.sakila_dbt_project.fact_payment
2022-01-23 18:14:45.123703 (Thread-1): 23:44:45 | 5 of 15 START incremental model dwh.fact_payment..................... [RUN]
2022-01-23 18:14:45.123703 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 18:14:45.123703 (Thread-1): Compiling model.sakila_dbt_project.fact_payment
2022-01-23 18:14:45.139324 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.fact_payment"
2022-01-23 18:14:45.154945 (Thread-1): finished collecting timing info
2022-01-23 18:14:45.154945 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 18:14:45.170567 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

    

  create temporary table "fact_payment__dbt_tmp234445154945"
  as (
    

select
*,
'2022-01-23 18:14:36' as dbt_time
from
"sakila_wh"."stg"."payment"
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."dwh"."fact_payment")

  );
  
2022-01-23 18:14:45.170567 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 18:14:45.748557 (Thread-1): SQL status: SELECT 0 in 0.58 seconds
2022-01-23 18:14:45.748557 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 18:14:45.748557 (Thread-1): On model.sakila_dbt_project.fact_payment: BEGIN
2022-01-23 18:14:45.748557 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-23 18:14:45.748557 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 18:14:45.748557 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_payment__dbt_tmp234445154945'
        
      order by ordinal_position

  
2022-01-23 18:14:45.779797 (Thread-1): SQL status: SELECT 7 in 0.03 seconds
2022-01-23 18:14:45.779797 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 18:14:45.779797 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'fact_payment'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 18:14:45.795420 (Thread-1): SQL status: SELECT 7 in 0.02 seconds
2022-01-23 18:14:45.795420 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 18:14:45.795420 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'fact_payment'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 18:14:45.795420 (Thread-1): SQL status: SELECT 7 in 0.00 seconds
2022-01-23 18:14:45.811079 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.fact_payment"
2022-01-23 18:14:45.826793 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 18:14:45.826793 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      delete
    from "sakila_wh"."dwh"."fact_payment"
    where (payment_id) in (
        select (payment_id)
        from "fact_payment__dbt_tmp234445154945"
    );

    insert into "sakila_wh"."dwh"."fact_payment" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time"
       from "fact_payment__dbt_tmp234445154945"
    );
  
2022-01-23 18:14:45.842284 (Thread-1): SQL status: INSERT 0 0 in 0.00 seconds
2022-01-23 18:14:45.842284 (Thread-1): On model.sakila_dbt_project.fact_payment: COMMIT
2022-01-23 18:14:45.842284 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-23 18:14:45.842284 (Thread-1): On model.sakila_dbt_project.fact_payment: COMMIT
2022-01-23 18:14:45.842284 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 18:14:45.842284 (Thread-1): finished collecting timing info
2022-01-23 18:14:45.842284 (Thread-1): On model.sakila_dbt_project.fact_payment: Close
2022-01-23 18:14:45.842284 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B720BAF0>]}
2022-01-23 18:14:45.842284 (Thread-1): 23:44:45 | 5 of 15 OK created incremental model dwh.fact_payment................ [INSERT 0 0 in 0.72s]
2022-01-23 18:14:45.842284 (Thread-1): Finished running node model.sakila_dbt_project.fact_payment
2022-01-23 18:14:45.857904 (Thread-1): Began running node model.sakila_dbt_project.film_test
2022-01-23 18:14:45.857904 (Thread-1): 23:44:45 | 6 of 15 START table model examples.film_test......................... [RUN]
2022-01-23 18:14:45.857904 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 18:14:45.857904 (Thread-1): Compiling model.sakila_dbt_project.film_test
2022-01-23 18:14:45.857904 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.film_test"
2022-01-23 18:14:45.889149 (Thread-1): finished collecting timing info
2022-01-23 18:14:45.904768 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.film_test"
2022-01-23 18:14:45.904768 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 18:14:45.904768 (Thread-1): On model.sakila_dbt_project.film_test: BEGIN
2022-01-23 18:14:45.904768 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 18:14:45.998498 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-23 18:14:45.998498 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 18:14:45.998498 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */


  create  table "sakila_wh"."examples"."film_test__dbt_tmp"
  as (
    select
*
from
-- sakila_wh.stg.film
"sakila_wh"."stg"."film"
  );
2022-01-23 18:14:46.092247 (Thread-1): SQL status: SELECT 1000 in 0.09 seconds
2022-01-23 18:14:46.107848 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 18:14:46.107848 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."examples"."film_test" rename to "film_test__dbt_backup"
2022-01-23 18:14:46.107848 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:46.107848 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 18:14:46.107848 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."examples"."film_test__dbt_tmp" rename to "film_test"
2022-01-23 18:14:46.107848 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:46.107848 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-23 18:14:46.107848 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 18:14:46.107848 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-23 18:14:46.123468 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-23 18:14:46.123468 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-23 18:14:46.123468 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
drop table if exists "sakila_wh"."examples"."film_test__dbt_backup" cascade
2022-01-23 18:14:46.217197 (Thread-1): SQL status: DROP TABLE in 0.09 seconds
2022-01-23 18:14:46.217197 (Thread-1): finished collecting timing info
2022-01-23 18:14:46.217197 (Thread-1): On model.sakila_dbt_project.film_test: Close
2022-01-23 18:14:46.217197 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B724F550>]}
2022-01-23 18:14:46.217197 (Thread-1): 23:44:46 | 6 of 15 OK created table model examples.film_test.................... [SELECT 1000 in 0.36s]
2022-01-23 18:14:46.217197 (Thread-1): Finished running node model.sakila_dbt_project.film_test
2022-01-23 18:14:46.217197 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-23 18:14:46.217197 (Thread-1): 23:44:46 | 7 of 15 START table model examples.hello_world....................... [RUN]
2022-01-23 18:14:46.217197 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 18:14:46.232868 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-23 18:14:46.232868 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-23 18:14:46.248534 (Thread-1): finished collecting timing info
2022-01-23 18:14:46.264063 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-23 18:14:46.295304 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 18:14:46.295304 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-23 18:14:46.295304 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 18:14:46.389031 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-23 18:14:46.389031 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 18:14:46.389031 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."examples"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-23 18:14:46.529740 (Thread-1): SQL status: SELECT 599 in 0.14 seconds
2022-01-23 18:14:46.545248 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 18:14:46.545248 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."examples"."hello_world" rename to "hello_world__dbt_backup"
2022-01-23 18:14:46.545248 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:46.560870 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 18:14:46.560870 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-23 18:14:46.560870 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:46.560870 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-23 18:14:46.560870 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 18:14:46.560870 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-23 18:14:46.560870 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 18:14:46.560870 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-23 18:14:46.560870 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."examples"."hello_world__dbt_backup" cascade
2022-01-23 18:14:46.592212 (Thread-1): SQL status: DROP TABLE in 0.03 seconds
2022-01-23 18:14:46.592212 (Thread-1): finished collecting timing info
2022-01-23 18:14:46.592212 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-23 18:14:46.592212 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B720F190>]}
2022-01-23 18:14:46.592212 (Thread-1): 23:44:46 | 7 of 15 OK created table model examples.hello_world.................. [SELECT 599 in 0.38s]
2022-01-23 18:14:46.607766 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-23 18:14:46.607766 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-23 18:14:46.607766 (Thread-1): 23:44:46 | 8 of 15 START table model examples.my_first_dbt_model................ [RUN]
2022-01-23 18:14:46.607766 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 18:14:46.607766 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-23 18:14:46.607766 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-23 18:14:46.639064 (Thread-1): finished collecting timing info
2022-01-23 18:14:46.639064 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-23 18:14:46.639064 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 18:14:46.639064 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-23 18:14:46.639064 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 18:14:46.732700 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-23 18:14:46.732700 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 18:14:46.732700 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-23 18:14:46.763941 (Thread-1): SQL status: SELECT 2 in 0.03 seconds
2022-01-23 18:14:46.763941 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 18:14:46.763941 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."examples"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-23 18:14:46.763941 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:46.779563 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 18:14:46.779563 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-23 18:14:46.779563 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:46.779563 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-23 18:14:46.779563 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 18:14:46.779563 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-23 18:14:46.779563 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 18:14:46.795186 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-23 18:14:46.795186 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-23 18:14:46.795186 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 18:14:46.795186 (Thread-1): finished collecting timing info
2022-01-23 18:14:46.795186 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-23 18:14:46.795186 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B72778B0>]}
2022-01-23 18:14:46.795186 (Thread-1): 23:44:46 | 8 of 15 OK created table model examples.my_first_dbt_model........... [SELECT 2 in 0.19s]
2022-01-23 18:14:46.795186 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-23 18:14:46.795186 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-23 18:14:46.795186 (Thread-1): 23:44:46 | 9 of 15 START incremental model examples.payment_inc................. [RUN]
2022-01-23 18:14:46.795186 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 18:14:46.795186 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-23 18:14:46.810806 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-23 18:14:46.826431 (Thread-1): finished collecting timing info
2022-01-23 18:14:46.826431 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 18:14:46.826431 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

    

  create temporary table "payment_inc__dbt_tmp234446826431"
  as (
    

select
*,
'2022-01-23 18:14:36' as dbt_time
from
stg.payment
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."examples"."payment_inc")



-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-23 18:14:46.826431 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 18:14:47.123285 (Thread-1): SQL status: SELECT 0 in 0.30 seconds
2022-01-23 18:14:47.123285 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 18:14:47.123285 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-23 18:14:47.123285 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-23 18:14:47.123285 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 18:14:47.123285 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc__dbt_tmp234446826431'
        
      order by ordinal_position

  
2022-01-23 18:14:47.154517 (Thread-1): SQL status: SELECT 7 in 0.03 seconds
2022-01-23 18:14:47.170097 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 18:14:47.170097 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'examples'
        
      order by ordinal_position

  
2022-01-23 18:14:47.170097 (Thread-1): SQL status: SELECT 7 in 0.00 seconds
2022-01-23 18:14:47.170097 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 18:14:47.170097 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'examples'
        
      order by ordinal_position

  
2022-01-23 18:14:47.185720 (Thread-1): SQL status: SELECT 7 in 0.02 seconds
2022-01-23 18:14:47.185720 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-23 18:14:47.201463 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 18:14:47.201463 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      delete
    from "sakila_wh"."examples"."payment_inc"
    where (payment_id) in (
        select (payment_id)
        from "payment_inc__dbt_tmp234446826431"
    );

    insert into "sakila_wh"."examples"."payment_inc" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time"
       from "payment_inc__dbt_tmp234446826431"
    );
  
2022-01-23 18:14:47.201463 (Thread-1): SQL status: INSERT 0 0 in 0.00 seconds
2022-01-23 18:14:47.201463 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-23 18:14:47.201463 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-23 18:14:47.201463 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-23 18:14:47.201463 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 18:14:47.201463 (Thread-1): finished collecting timing info
2022-01-23 18:14:47.201463 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-23 18:14:47.216961 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B7277160>]}
2022-01-23 18:14:47.216961 (Thread-1): 23:44:47 | 9 of 15 OK created incremental model examples.payment_inc............ [INSERT 0 0 in 0.42s]
2022-01-23 18:14:47.216961 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-23 18:14:47.216961 (Thread-1): Began running node model.sakila_dbt_project.dim_date_inc
2022-01-23 18:14:47.216961 (Thread-1): 23:44:47 | 10 of 15 START incremental model examples.dim_date_inc............... [RUN]
2022-01-23 18:14:47.216961 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 18:14:47.216961 (Thread-1): Compiling model.sakila_dbt_project.dim_date_inc
2022-01-23 18:14:47.216961 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date_inc"
2022-01-23 18:14:47.232620 (Thread-1): finished collecting timing info
2022-01-23 18:14:47.232620 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 18:14:47.232620 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

    

  create temporary table "dim_date_inc__dbt_tmp234447232620"
  as (
    


SELECT
*
from "sakila_wh"."dwh"."dim_date"
where 1=1



and date_key::timestamp > (select max(date_key) - INTERVAL '3 DAY' from "sakila_wh"."examples"."dim_date_inc")

  );
  
2022-01-23 18:14:47.232620 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 18:14:47.466907 (Thread-1): SQL status: SELECT 3 in 0.23 seconds
2022-01-23 18:14:47.466907 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 18:14:47.466907 (Thread-1): On model.sakila_dbt_project.dim_date_inc: BEGIN
2022-01-23 18:14:47.466907 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-23 18:14:47.482578 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 18:14:47.482578 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dim_date_inc__dbt_tmp234447232620'
        
      order by ordinal_position

  
2022-01-23 18:14:47.529390 (Thread-1): SQL status: SELECT 26 in 0.05 seconds
2022-01-23 18:14:47.529390 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 18:14:47.529390 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_date_inc'
        
        and table_schema = 'examples'
        
      order by ordinal_position

  
2022-01-23 18:14:47.529390 (Thread-1): SQL status: SELECT 26 in 0.00 seconds
2022-01-23 18:14:47.545062 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 18:14:47.545062 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_date_inc'
        
        and table_schema = 'examples'
        
      order by ordinal_position

  
2022-01-23 18:14:47.545062 (Thread-1): SQL status: SELECT 26 in 0.00 seconds
2022-01-23 18:14:47.545062 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date_inc"
2022-01-23 18:14:47.560764 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 18:14:47.560764 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      delete
    from "sakila_wh"."examples"."dim_date_inc"
    where (date_dim_id) in (
        select (date_dim_id)
        from "dim_date_inc__dbt_tmp234447232620"
    );

    insert into "sakila_wh"."examples"."dim_date_inc" ("date_dim_id", "date_key", "epoch", "day_name", "day_of_week", "day_of_month", "day_of_quarter", "day_of_year", "week_of_month", "week_of_year", "month_actual", "month_name", "month_name_abbreviated", "quarter_actual", "quarter_name", "year_actual", "first_day_of_week", "last_day_of_week", "first_day_of_month", "last_day_of_month", "first_day_of_quarter", "last_day_of_quarter", "first_day_of_year", "last_day_of_year", "yyyymm", "weekend_indr")
    (
       select "date_dim_id", "date_key", "epoch", "day_name", "day_of_week", "day_of_month", "day_of_quarter", "day_of_year", "week_of_month", "week_of_year", "month_actual", "month_name", "month_name_abbreviated", "quarter_actual", "quarter_name", "year_actual", "first_day_of_week", "last_day_of_week", "first_day_of_month", "last_day_of_month", "first_day_of_quarter", "last_day_of_quarter", "first_day_of_year", "last_day_of_year", "yyyymm", "weekend_indr"
       from "dim_date_inc__dbt_tmp234447232620"
    );
  
2022-01-23 18:14:47.592007 (Thread-1): SQL status: INSERT 0 3 in 0.03 seconds
2022-01-23 18:14:47.592007 (Thread-1): On model.sakila_dbt_project.dim_date_inc: COMMIT
2022-01-23 18:14:47.592007 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-23 18:14:47.592007 (Thread-1): On model.sakila_dbt_project.dim_date_inc: COMMIT
2022-01-23 18:14:47.592007 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 18:14:47.592007 (Thread-1): finished collecting timing info
2022-01-23 18:14:47.592007 (Thread-1): On model.sakila_dbt_project.dim_date_inc: Close
2022-01-23 18:14:47.607495 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B6F831C0>]}
2022-01-23 18:14:47.607495 (Thread-1): 23:44:47 | 10 of 15 OK created incremental model examples.dim_date_inc.......... [INSERT 0 3 in 0.39s]
2022-01-23 18:14:47.607495 (Thread-1): Finished running node model.sakila_dbt_project.dim_date_inc
2022-01-23 18:14:47.607495 (Thread-1): Began running node model.sakila_dbt_project.dim_store
2022-01-23 18:14:47.607495 (Thread-1): 23:44:47 | 11 of 15 START table model dwh.dim_store............................. [RUN]
2022-01-23 18:14:47.607495 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 18:14:47.607495 (Thread-1): Compiling model.sakila_dbt_project.dim_store
2022-01-23 18:14:47.607495 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_store"
2022-01-23 18:14:47.638736 (Thread-1): finished collecting timing info
2022-01-23 18:14:47.638736 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_store"
2022-01-23 18:14:47.654357 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 18:14:47.654357 (Thread-1): On model.sakila_dbt_project.dim_store: BEGIN
2022-01-23 18:14:47.654357 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 18:14:47.732464 (Thread-1): SQL status: BEGIN in 0.08 seconds
2022-01-23 18:14:47.732464 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 18:14:47.732464 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */


  create  table "sakila_wh"."dwh"."dim_store__dbt_tmp"
  as (
    

with stg_store as (
		select
    *,
    '2022-01-23 18:14:36'::timestamp as dbt_time
     from "sakila_wh"."stg"."store"
),

staff as (
 select * from "sakila_wh"."dwh"."dim_staff"
),

address as (
  select * from "sakila_wh"."stg"."address"
),

city as (
  select * from "sakila_wh"."stg"."city"
),

country as (
  select * from "sakila_wh"."stg"."country"
),
stg_store_1 as (-- add staff
		select
		stg_store.*,
		staff.first_name as staff_first_name,
		staff.last_name as staff_last_name
		from
		stg_store
		left join staff  on 1=1
		and stg_store.manager_staff_id = staff.staff_id
),
stg_store_2 as (-- add adress
		select
		stg_store_1.*,
		address.address,
		city.city_id,
		city.city,
		country.country_id,
		country.country
		from
		stg_store_1

		left join address on 1=1
		and stg_store_1.address_id =address.address_id

		left join city on 1=1
		and address.city_id = city.city_id

		left join country on  1=1
		and city.country_id = country.country_id
)

select
  store_id,
  manager_staff_id,
  staff_first_name,
  staff_last_name,
  address_id,
  address,
  city_id,
  city,
  country_id,
  country,
  last_update,
  dbt_time
from stg_store_2
  );
2022-01-23 18:14:47.857436 (Thread-1): SQL status: SELECT 2 in 0.12 seconds
2022-01-23 18:14:47.857436 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 18:14:47.857436 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
alter table "sakila_wh"."dwh"."dim_store" rename to "dim_store__dbt_backup"
2022-01-23 18:14:47.857436 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:47.857436 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 18:14:47.857436 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
alter table "sakila_wh"."dwh"."dim_store__dbt_tmp" rename to "dim_store"
2022-01-23 18:14:47.857436 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:47.873058 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-23 18:14:47.873058 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 18:14:47.873058 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */

        insert into "sakila_wh"."dwh"."dim_store"(store_id) VALUES (-1)
      
2022-01-23 18:14:47.873058 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-23 18:14:47.873058 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-23 18:14:47.873058 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 18:14:47.873058 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-23 18:14:47.873058 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-23 18:14:47.888679 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-23 18:14:47.888679 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
drop table if exists "sakila_wh"."dwh"."dim_store__dbt_backup" cascade
2022-01-23 18:14:47.904300 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-01-23 18:14:47.904300 (Thread-1): finished collecting timing info
2022-01-23 18:14:47.904300 (Thread-1): On model.sakila_dbt_project.dim_store: Close
2022-01-23 18:14:47.904300 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B7088CA0>]}
2022-01-23 18:14:47.904300 (Thread-1): 23:44:47 | 11 of 15 OK created table model dwh.dim_store........................ [SELECT 2 in 0.30s]
2022-01-23 18:14:47.904300 (Thread-1): Finished running node model.sakila_dbt_project.dim_store
2022-01-23 18:14:47.904300 (Thread-1): Began running node model.sakila_dbt_project.customer_test
2022-01-23 18:14:47.904300 (Thread-1): 23:44:47 | 12 of 15 START table model itamar.customers_alias.................... [RUN]
2022-01-23 18:14:47.904300 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-23 18:14:47.904300 (Thread-1): Compiling model.sakila_dbt_project.customer_test
2022-01-23 18:14:47.966797 (Thread-1): finished collecting timing info
2022-01-23 18:14:47.966797 (Thread-1): Compilation Error in model customer_test (models\example\customer_test.sql)
  Required var 'customer_id' not found in config:
  Vars supplied to customer_test = {}
  
  > in model customer_test (models\example\customer_test.sql)
  > called by model customer_test (models\example\customer_test.sql)
Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\base.py", line 285, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\compile.py", line 33, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\compilation.py", line 544, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\compilation.py", line 384, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\jinja.py", line 598, in get_rendered
    return render_template(template, ctx, node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\jinja.py", line 549, in render_template
    return template.render(ctx)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\environment.py", line 1090, in render
    self.environment.handle_exception()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 7, in top-level template code
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\context\base.py", line 159, in __call__
    return self.get_missing_var(var_name)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\context\base.py", line 140, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\exceptions.py", line 447, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model customer_test (models\example\customer_test.sql)
  Required var 'customer_id' not found in config:
  Vars supplied to customer_test = {}
  
  > in model customer_test (models\example\customer_test.sql)
  > called by model customer_test (models\example\customer_test.sql)
2022-01-23 18:14:48.435467 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B711A850>]}
2022-01-23 18:14:48.435467 (Thread-1): 23:44:48 | 12 of 15 ERROR creating table model itamar.customers_alias........... [ERROR in 0.53s]
2022-01-23 18:14:48.435467 (Thread-1): Finished running node model.sakila_dbt_project.customer_test
2022-01-23 18:14:48.435467 (Thread-1): Began running node model.sakila_dbt_project.customer_test_macro
2022-01-23 18:14:48.435467 (Thread-1): 23:44:48 | 13 of 15 START table model examples.customer_test_macro.............. [RUN]
2022-01-23 18:14:48.435467 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.customer_test_macro".
2022-01-23 18:14:48.435467 (Thread-1): Compiling model.sakila_dbt_project.customer_test_macro
2022-01-23 18:14:48.435467 (Thread-1): finished collecting timing info
2022-01-23 18:14:48.435467 (Thread-1): Compilation Error in model customer_test_macro (models\example\customer_test_macro.sql)
  Required var 'customer_id' not found in config:
  Vars supplied to customer_test_macro = {}
  
  > in model customer_test_macro (models\example\customer_test_macro.sql)
  > called by model customer_test_macro (models\example\customer_test_macro.sql)
Traceback (most recent call last):
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\base.py", line 285, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\task\compile.py", line 33, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\compilation.py", line 544, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\compilation.py", line 384, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\jinja.py", line 598, in get_rendered
    return render_template(template, ctx, node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\clients\jinja.py", line 549, in render_template
    return template.render(ctx)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\environment.py", line 1090, in render
    self.environment.handle_exception()
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\context\base.py", line 159, in __call__
    return self.get_missing_var(var_name)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\context\base.py", line 140, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "C:\Users\DELL\AppData\Local\Programs\Python\Python39\lib\site-packages\dbt\exceptions.py", line 447, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model customer_test_macro (models\example\customer_test_macro.sql)
  Required var 'customer_id' not found in config:
  Vars supplied to customer_test_macro = {}
  
  > in model customer_test_macro (models\example\customer_test_macro.sql)
  > called by model customer_test_macro (models\example\customer_test_macro.sql)
2022-01-23 18:14:48.435467 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B711AD60>]}
2022-01-23 18:14:48.435467 (Thread-1): 23:44:48 | 13 of 15 ERROR creating table model examples.customer_test_macro..... [ERROR in 0.00s]
2022-01-23 18:14:48.451049 (Thread-1): Finished running node model.sakila_dbt_project.customer_test_macro
2022-01-23 18:14:48.451049 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-23 18:14:48.451049 (Thread-1): 23:44:48 | 14 of 15 START table model examples.my_second_dbt_model.............. [RUN]
2022-01-23 18:14:48.451049 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 18:14:48.451049 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-23 18:14:48.451049 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-23 18:14:48.466773 (Thread-1): finished collecting timing info
2022-01-23 18:14:48.466773 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-23 18:14:48.466773 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 18:14:48.466773 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-23 18:14:48.466773 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 18:14:48.544776 (Thread-1): SQL status: BEGIN in 0.08 seconds
2022-01-23 18:14:48.544776 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 18:14:48.544776 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."examples"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."examples"."my_first_dbt_model"
where id = 1
  );
2022-01-23 18:14:48.560395 (Thread-1): SQL status: SELECT 1 in 0.02 seconds
2022-01-23 18:14:48.560395 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 18:14:48.576018 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."examples"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-23 18:14:48.576018 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:48.576018 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 18:14:48.576018 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-23 18:14:48.576018 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-23 18:14:48.576018 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-23 18:14:48.576018 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 18:14:48.576018 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-23 18:14:48.591643 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-23 18:14:48.591643 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-23 18:14:48.591643 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-23 18:14:48.591643 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-23 18:14:48.607260 (Thread-1): finished collecting timing info
2022-01-23 18:14:48.607260 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-23 18:14:48.607260 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B7213730>]}
2022-01-23 18:14:48.607260 (Thread-1): 23:44:48 | 14 of 15 OK created table model examples.my_second_dbt_model......... [SELECT 1 in 0.16s]
2022-01-23 18:14:48.607260 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-23 18:14:48.607260 (Thread-1): Began running node model.sakila_dbt_project.fact_rental
2022-01-23 18:14:48.607260 (Thread-1): 23:44:48 | 15 of 15 START incremental model dwh.fact_rental..................... [RUN]
2022-01-23 18:14:48.607260 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 18:14:48.607260 (Thread-1): Compiling model.sakila_dbt_project.fact_rental
2022-01-23 18:14:48.622881 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.fact_rental"
2022-01-23 18:14:48.622881 (Thread-1): finished collecting timing info
2022-01-23 18:14:48.638503 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 18:14:48.638503 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

    

  create temporary table "fact_rental__dbt_tmp234448638503"
  as (
    

with rental_base as (--base
select
	*,
	EXTRACT(EPOCH from rental_date::timestamp) as rental_epoch,
	EXTRACT(EPOCH from return_date::timestamp) as return_epoch,
	EXTRACT(EPOCH from return_date::timestamp)-EXTRACT(EPOCH from rental_date::timestamp) as diff,
	(case when return_date is not null then 1 else 0 end) as is_return,
	to_char(rental_date::timestamp, 'YYYYMMDD')::integer as date_key,
  '2022-01-23 18:14:36'::timestamp as dbt_time

	from
	"sakila_wh"."stg"."rental"
),

inventory as (
	select * from "sakila_wh"."stg"."inventory"
),

dim_film as (
	select * from "sakila_wh"."dwh"."dim_film"
),

dim_store as (
	select * from "sakila_wh"."dwh"."dim_store"
),

dim_staff as (
	select * from "sakila_wh"."dwh"."dim_staff"
),

dim_customer as (
	select * from "sakila_wh"."dwh"."dim_customer"
),

rental_base_1 as (-- join base with inventory
	select
	rental_base.*,
	inventory.store_id,
  inventory.film_id
	from
	rental_base

	inner join inventory on 1=1
	and inventory.inventory_id = rental_base.inventory_id
),


rental_base_2 as (--check direct integrity
	select
	rental_base_1.*,
	(case when dim_staff.staff_id is not null then dim_staff.staff_id else -1 end) as staff_id_rental_check,
	(case when dim_customer.customer_id is not null then dim_customer.customer_id else -1 end) as customer_id_check,
  (case when dim_film.film_id is not null then dim_film.film_id else -1 end) as film_id_check,
	(case when dim_store.store_id is not null then dim_store.store_id else -1 end) as store_id_check
	from
	rental_base_1

	left join
  dim_staff
  on 1=1
	and rental_base_1.staff_id = dim_staff.staff_id

	left join
  dim_customer
  on 1=1
	and rental_base_1.customer_id = dim_customer.customer_id

  left join
  dim_film
  on 1=1
  and  rental_base_1.film_id = dim_film.film_id

  left join
  dim_store
  on 1=1
  and  rental_base_1.store_id = dim_store.store_id
)

select
  rental_id,
  rental_date,
  date_key,
  inventory_id,
  customer_id_check as customer_id,
  film_id_check as film_id,
  store_id_check as store_id,
  staff_id_rental_check as staff_id_rental,
  return_date,
  case when return_date is not null then diff/3600 else null end rental_hours,
  is_return,
  last_update,
  dbt_time
from
 rental_base_2
 where 1=1

 
 and last_update::timestamp > (select max(last_update) from "sakila_wh"."dwh"."fact_rental")
 

 --  - INTERVAL '10 minutes'
  );
  
2022-01-23 18:14:48.638503 (Thread-1): Opening a new connection, currently in state closed
2022-01-23 18:14:49.169676 (Thread-1): SQL status: SELECT 0 in 0.53 seconds
2022-01-23 18:14:49.169676 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 18:14:49.169676 (Thread-1): On model.sakila_dbt_project.fact_rental: BEGIN
2022-01-23 18:14:49.169676 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-23 18:14:49.185258 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 18:14:49.185258 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_rental__dbt_tmp234448638503'
        
      order by ordinal_position

  
2022-01-23 18:14:49.216497 (Thread-1): SQL status: SELECT 13 in 0.03 seconds
2022-01-23 18:14:49.232113 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 18:14:49.232113 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'fact_rental'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 18:14:49.232113 (Thread-1): SQL status: SELECT 13 in 0.00 seconds
2022-01-23 18:14:49.232113 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 18:14:49.247734 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'fact_rental'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-23 18:14:49.247734 (Thread-1): SQL status: SELECT 13 in 0.00 seconds
2022-01-23 18:14:49.247734 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.fact_rental"
2022-01-23 18:14:49.247734 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 18:14:49.247734 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      delete
    from "sakila_wh"."dwh"."fact_rental"
    where (rental_id) in (
        select (rental_id)
        from "fact_rental__dbt_tmp234448638503"
    );

    insert into "sakila_wh"."dwh"."fact_rental" ("rental_id", "rental_date", "date_key", "inventory_id", "customer_id", "film_id", "store_id", "staff_id_rental", "return_date", "rental_hours", "is_return", "last_update", "dbt_time")
    (
       select "rental_id", "rental_date", "date_key", "inventory_id", "customer_id", "film_id", "store_id", "staff_id_rental", "return_date", "rental_hours", "is_return", "last_update", "dbt_time"
       from "fact_rental__dbt_tmp234448638503"
    );
  
2022-01-23 18:14:49.247734 (Thread-1): SQL status: INSERT 0 0 in 0.00 seconds
2022-01-23 18:14:49.247734 (Thread-1): On model.sakila_dbt_project.fact_rental: COMMIT
2022-01-23 18:14:49.247734 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-23 18:14:49.247734 (Thread-1): On model.sakila_dbt_project.fact_rental: COMMIT
2022-01-23 18:14:49.263356 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-23 18:14:49.263356 (Thread-1): finished collecting timing info
2022-01-23 18:14:49.263356 (Thread-1): On model.sakila_dbt_project.fact_rental: Close
2022-01-23 18:14:49.263356 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b7ead6b-eafc-4cae-b9d0-e2bde99e94ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B6F808B0>]}
2022-01-23 18:14:49.263356 (Thread-1): 23:44:49 | 15 of 15 OK created incremental model dwh.fact_rental................ [INSERT 0 0 in 0.66s]
2022-01-23 18:14:49.263356 (Thread-1): Finished running node model.sakila_dbt_project.fact_rental
2022-01-23 18:14:49.279104 (MainThread): Acquiring new postgres connection "master".
2022-01-23 18:14:49.279104 (MainThread): Using postgres connection "master".
2022-01-23 18:14:49.279104 (MainThread): On master: BEGIN
2022-01-23 18:14:49.279104 (MainThread): Opening a new connection, currently in state closed
2022-01-23 18:14:49.372705 (MainThread): SQL status: BEGIN in 0.09 seconds
2022-01-23 18:14:49.372705 (MainThread): On master: COMMIT
2022-01-23 18:14:49.372705 (MainThread): Using postgres connection "master".
2022-01-23 18:14:49.372705 (MainThread): On master: COMMIT
2022-01-23 18:14:49.372705 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-23 18:14:49.372705 (MainThread): On master: Close
2022-01-23 18:14:49.372705 (MainThread): 23:44:49 | 
2022-01-23 18:14:49.372705 (MainThread): 23:44:49 | Finished running 6 incremental models, 9 table models in 10.06s.
2022-01-23 18:14:49.372705 (MainThread): Connection 'master' was properly closed.
2022-01-23 18:14:49.372705 (MainThread): Connection 'list_sakila_wh' was properly closed.
2022-01-23 18:14:49.372705 (MainThread): Connection 'list_sakila_wh_itamar' was properly closed.
2022-01-23 18:14:49.372705 (MainThread): Connection 'model.sakila_dbt_project.fact_rental' was properly closed.
2022-01-23 18:14:49.450811 (MainThread): 
2022-01-23 18:14:49.450811 (MainThread): Completed with 2 errors and 0 warnings:
2022-01-23 18:14:49.450811 (MainThread): 
2022-01-23 18:14:49.450811 (MainThread): Compilation Error in model customer_test (models\example\customer_test.sql)
2022-01-23 18:14:49.450811 (MainThread):   Required var 'customer_id' not found in config:
2022-01-23 18:14:49.450811 (MainThread):   Vars supplied to customer_test = {}
2022-01-23 18:14:49.450811 (MainThread):   
2022-01-23 18:14:49.450811 (MainThread):   > in model customer_test (models\example\customer_test.sql)
2022-01-23 18:14:49.450811 (MainThread):   > called by model customer_test (models\example\customer_test.sql)
2022-01-23 18:14:49.450811 (MainThread): 
2022-01-23 18:14:49.450811 (MainThread): Compilation Error in model customer_test_macro (models\example\customer_test_macro.sql)
2022-01-23 18:14:49.450811 (MainThread):   Required var 'customer_id' not found in config:
2022-01-23 18:14:49.450811 (MainThread):   Vars supplied to customer_test_macro = {}
2022-01-23 18:14:49.450811 (MainThread):   
2022-01-23 18:14:49.450811 (MainThread):   > in model customer_test_macro (models\example\customer_test_macro.sql)
2022-01-23 18:14:49.450811 (MainThread):   > called by model customer_test_macro (models\example\customer_test_macro.sql)
2022-01-23 18:14:49.450811 (MainThread): 
Done. PASS=13 WARN=0 ERROR=2 SKIP=0 TOTAL=15
2022-01-23 18:14:49.450811 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B7117BB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B71174F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291B6C063D0>]}
2022-01-23 18:14:49.466433 (MainThread): Flushing usage events
2022-01-24 04:09:26.266963 (MainThread): Running with dbt=0.21.1
2022-01-24 04:09:26.485658 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='C:\\Users\\DELL\\.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-24 04:09:26.516900 (MainThread): Tracking: tracking
2022-01-24 04:09:26.532523 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8BF1C850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C025A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C025280>]}
2022-01-24 04:09:26.548145 (MainThread): Partial parsing not enabled
2022-01-24 04:09:26.800311 (MainThread): Parsing macros\concat_it.sql
2022-01-24 04:09:26.815936 (MainThread): Parsing macros\delete_from_table.sql
2022-01-24 04:09:26.820908 (MainThread): Parsing macros\generate_schema_name.sql
2022-01-24 04:09:26.823068 (MainThread): Parsing macros\logit.sql
2022-01-24 04:09:26.838689 (MainThread): Parsing macros\adapters.sql
2022-01-24 04:09:26.885553 (MainThread): Parsing macros\catalog.sql
2022-01-24 04:09:26.885553 (MainThread): Parsing macros\relations.sql
2022-01-24 04:09:26.885553 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2022-01-24 04:09:26.901175 (MainThread): Parsing macros\core.sql
2022-01-24 04:09:26.901175 (MainThread): Parsing macros\adapters\common.sql
2022-01-24 04:09:27.073012 (MainThread): Parsing macros\etc\datetime.sql
2022-01-24 04:09:27.088634 (MainThread): Parsing macros\etc\get_custom_alias.sql
2022-01-24 04:09:27.104257 (MainThread): Parsing macros\etc\get_custom_database.sql
2022-01-24 04:09:27.104257 (MainThread): Parsing macros\etc\get_custom_schema.sql
2022-01-24 04:09:27.104257 (MainThread): Parsing macros\etc\is_incremental.sql
2022-01-24 04:09:27.119876 (MainThread): Parsing macros\etc\query.sql
2022-01-24 04:09:27.119876 (MainThread): Parsing macros\etc\where_subquery.sql
2022-01-24 04:09:27.119876 (MainThread): Parsing macros\materializations\helpers.sql
2022-01-24 04:09:27.135500 (MainThread): Parsing macros\materializations\test.sql
2022-01-24 04:09:27.151124 (MainThread): Parsing macros\materializations\common\merge.sql
2022-01-24 04:09:27.213601 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2022-01-24 04:09:27.213601 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2022-01-24 04:09:27.244846 (MainThread): Parsing macros\materializations\incremental\on_schema_change.sql
2022-01-24 04:09:27.291712 (MainThread): Parsing macros\materializations\seed\seed.sql
2022-01-24 04:09:27.369817 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2022-01-24 04:09:27.463546 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2022-01-24 04:09:27.479195 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2022-01-24 04:09:27.510410 (MainThread): Parsing macros\materializations\table\table.sql
2022-01-24 04:09:27.541653 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2022-01-24 04:09:27.541653 (MainThread): Parsing macros\materializations\view\view.sql
2022-01-24 04:09:27.557276 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2022-01-24 04:09:27.557276 (MainThread): Parsing macros\schema_tests\not_null.sql
2022-01-24 04:09:27.557276 (MainThread): Parsing macros\schema_tests\relationships.sql
2022-01-24 04:09:27.572898 (MainThread): Parsing macros\schema_tests\unique.sql
2022-01-24 04:09:27.994673 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-24 04:09:28.010296 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.025912 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-24 04:09:28.025912 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.041532 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-24 04:09:28.057154 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.057154 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-24 04:09:28.072780 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.072780 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-24 04:09:28.088397 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.088397 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-24 04:09:28.104021 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.104021 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-24 04:09:28.104021 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.104021 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-24 04:09:28.104021 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.119644 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-24 04:09:28.119644 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.119644 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-24 04:09:28.135267 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.135267 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-24 04:09:28.135267 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.135267 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-24 04:09:28.150888 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-24 04:09:28.182127 (MainThread): Acquiring new postgres connection "analysis.sakila_dbt_project.example".
2022-01-24 04:09:28.213369 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_cost_30".
2022-01-24 04:09:28.213369 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.291477 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.291477 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.307103 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.307103 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.307103 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.307103 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.322730 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.322730 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.322730 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.322730 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.369587 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.385204 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.400828 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.400828 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.400828 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.416447 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.432069 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.447689 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.447689 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.463310 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.478934 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.494552 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.494552 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.494552 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:28.557037 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C0F0D00>]}
2022-01-24 04:09:28.572660 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-24 04:09:28.572660 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C0F0A00>]}
2022-01-24 04:09:28.572660 (MainThread): Found 13 models, 25 tests, 0 snapshots, 1 analysis, 166 macros, 0 operations, 0 seed files, 15 sources, 0 exposures
2022-01-24 04:09:28.572660 (MainThread): 
2022-01-24 04:09:28.572660 (MainThread): Acquiring new postgres connection "master".
2022-01-24 04:09:28.588282 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-24 04:09:28.616881 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-24 04:09:28.616881 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-24 04:09:28.616881 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-24 04:09:28.819960 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.20 seconds
2022-01-24 04:09:28.819960 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-24 04:09:28.835580 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-24 04:09:28.835580 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-24 04:09:28.835580 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-24 04:09:28.835580 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-24 04:09:28.913687 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.08 seconds
2022-01-24 04:09:28.913687 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-24 04:09:28.913687 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_examples".
2022-01-24 04:09:28.929307 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_examples".
2022-01-24 04:09:28.929307 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: BEGIN
2022-01-24 04:09:28.929307 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-24 04:09:29.148014 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.22 seconds
2022-01-24 04:09:29.148014 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_examples".
2022-01-24 04:09:29.148014 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_examples"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'examples'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'examples'
  
2022-01-24 04:09:29.319842 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.17 seconds
2022-01-24 04:09:29.319842 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: ROLLBACK
2022-01-24 04:09:29.319842 (ThreadPoolExecutor-1_0): On list_sakila_wh_examples: Close
2022-01-24 04:09:29.319842 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-24 04:09:29.335461 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-24 04:09:29.335461 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-24 04:09:29.335461 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-24 04:09:29.397947 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.06 seconds
2022-01-24 04:09:29.397947 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-24 04:09:29.397947 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-24 04:09:29.413569 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.02 seconds
2022-01-24 04:09:29.413569 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-24 04:09:29.429195 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-24 04:09:29.444821 (MainThread): Using postgres connection "master".
2022-01-24 04:09:29.444821 (MainThread): On master: BEGIN
2022-01-24 04:09:29.444821 (MainThread): Opening a new connection, currently in state init
2022-01-24 04:09:29.616650 (MainThread): SQL status: BEGIN in 0.17 seconds
2022-01-24 04:09:29.616650 (MainThread): Using postgres connection "master".
2022-01-24 04:09:29.616650 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-24 04:09:31.085055 (MainThread): SQL status: SELECT 43 in 1.47 seconds
2022-01-24 04:09:31.085055 (MainThread): On master: ROLLBACK
2022-01-24 04:09:31.100676 (MainThread): Using postgres connection "master".
2022-01-24 04:09:31.100676 (MainThread): On master: BEGIN
2022-01-24 04:09:31.100676 (MainThread): SQL status: BEGIN in 0.00 seconds
2022-01-24 04:09:31.100676 (MainThread): On master: COMMIT
2022-01-24 04:09:31.100676 (MainThread): Using postgres connection "master".
2022-01-24 04:09:31.100676 (MainThread): On master: COMMIT
2022-01-24 04:09:31.100676 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-24 04:09:31.100676 (MainThread): On master: Close
2022-01-24 04:09:31.100676 (MainThread): 09:39:31 | Concurrency: 1 threads (target='dev')
2022-01-24 04:09:31.100676 (MainThread): 09:39:31 | 
2022-01-24 04:09:31.163162 (Thread-1): Began running node model.sakila_dbt_project.dim_customer
2022-01-24 04:09:31.163162 (Thread-1): 09:39:31 | 1 of 13 START incremental model dwh.dim_customer..................... [RUN]
2022-01-24 04:09:31.163162 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-24 04:09:31.163162 (Thread-1): Compiling model.sakila_dbt_project.dim_customer
2022-01-24 04:09:31.178779 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-24 04:09:31.194406 (Thread-1): finished collecting timing info
2022-01-24 04:09:31.361068 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-24 04:09:31.361068 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

    

  create temporary table "dim_customer__dbt_tmp093931298581"
  as (
    

with customer_base as (

select
 *,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.active::int as active_int,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
  '2022-01-24 04:09:26'::timestamp as dbt_time
from
	"sakila_wh"."stg"."customer" as customer),

  address as (
    select * from "sakila_wh"."stg"."address"
  ),

  city as (
    select * from "sakila_wh"."stg"."city"
  ),

  country as (
    select * from "sakila_wh"."stg"."country"
  )

  select
  customer_base.customer_id,
  customer_base.store_id,
  customer_base.first_name,
  customer_base.last_name,
  customer_base.full_name,
  customer_base.domain,
  customer_base.email,
  customer_base.active_int as active,
  customer_base.active_desc,

  address.address_id,
  address.address,
  city.city_id,
  city.city,
  country.country_id,
  country.country,

  customer_base.create_date,
  customer_base.last_update,
  customer_base.dbt_time

  from
  customer_base

	left join address on 1=1
	and customer_base.address_id =address.address_id

	left join city on 1=1
	and address.city_id = city.city_id

  left join country on 1=1
  and country.country_id = city.country_id

  where 1=1

  
  and customer_base.last_update::timestamp > (select max(last_update) from "sakila_wh"."dwh"."dim_customer")
  
  );
  
2022-01-24 04:09:31.361068 (Thread-1): Opening a new connection, currently in state init
2022-01-24 04:09:31.845331 (Thread-1): SQL status: SELECT 0 in 0.48 seconds
2022-01-24 04:09:31.860951 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-24 04:09:31.860951 (Thread-1): On model.sakila_dbt_project.dim_customer: BEGIN
2022-01-24 04:09:31.876593 (Thread-1): SQL status: BEGIN in 0.02 seconds
2022-01-24 04:09:31.876593 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-24 04:09:31.876593 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer__dbt_tmp093931298581'
        
      order by ordinal_position

  
2022-01-24 04:09:32.079646 (Thread-1): SQL status: SELECT 18 in 0.20 seconds
2022-01-24 04:09:32.095266 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-24 04:09:32.095266 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-24 04:09:32.110893 (Thread-1): SQL status: SELECT 18 in 0.02 seconds
2022-01-24 04:09:32.157751 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-24 04:09:32.157751 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-24 04:09:32.173374 (Thread-1): SQL status: SELECT 18 in 0.02 seconds
2022-01-24 04:09:32.188996 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-24 04:09:32.204618 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-24 04:09:32.204618 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      delete
    from "sakila_wh"."dwh"."dim_customer"
    where (customer_id) in (
        select (customer_id)
        from "dim_customer__dbt_tmp093931298581"
    );

    insert into "sakila_wh"."dwh"."dim_customer" ("customer_id", "store_id", "first_name", "last_name", "full_name", "domain", "email", "active", "active_desc", "address_id", "address", "city_id", "city", "country_id", "country", "create_date", "last_update", "dbt_time")
    (
       select "customer_id", "store_id", "first_name", "last_name", "full_name", "domain", "email", "active", "active_desc", "address_id", "address", "city_id", "city", "country_id", "country", "create_date", "last_update", "dbt_time"
       from "dim_customer__dbt_tmp093931298581"
    );
  
2022-01-24 04:09:32.262504 (Thread-1): SQL status: INSERT 0 0 in 0.06 seconds
2022-01-24 04:09:32.293753 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:32.293753 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-24 04:09:32.293753 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

        insert into "sakila_wh"."dwh"."dim_customer"(customer_id) VALUES (-1)
      
2022-01-24 04:09:32.309370 (Thread-1): SQL status: INSERT 0 1 in 0.02 seconds
2022-01-24 04:09:32.309370 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-24 04:09:32.309370 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-24 04:09:32.309370 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-24 04:09:32.324990 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-24 04:09:32.324990 (Thread-1): finished collecting timing info
2022-01-24 04:09:32.324990 (Thread-1): On model.sakila_dbt_project.dim_customer: Close
2022-01-24 04:09:32.324990 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C1103A0>]}
2022-01-24 04:09:32.324990 (Thread-1): 09:39:32 | 1 of 13 OK created incremental model dwh.dim_customer................ [INSERT 0 0 in 1.16s]
2022-01-24 04:09:32.324990 (Thread-1): Finished running node model.sakila_dbt_project.dim_customer
2022-01-24 04:09:32.324990 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-24 04:09:32.324990 (Thread-1): 09:39:32 | 2 of 13 START table model dwh.dim_date............................... [RUN]
2022-01-24 04:09:32.324990 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-24 04:09:32.324990 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-24 04:09:32.340614 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-24 04:09:32.356232 (Thread-1): finished collecting timing info
2022-01-24 04:09:32.403096 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-24 04:09:32.449960 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-24 04:09:32.449960 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-24 04:09:32.449960 (Thread-1): Opening a new connection, currently in state closed
2022-01-24 04:09:32.544377 (Thread-1): SQL status: BEGIN in 0.09 seconds
2022-01-24 04:09:32.544377 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-24 04:09:32.544377 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-24 04:09:33.028642 (Thread-1): SQL status: SELECT 8060 in 0.48 seconds
2022-01-24 04:09:33.044265 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-24 04:09:33.044265 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-24 04:09:33.075506 (Thread-1): SQL status: ALTER TABLE in 0.03 seconds
2022-01-24 04:09:33.075506 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-24 04:09:33.075506 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-24 04:09:33.075506 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:33.091125 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-24 04:09:33.091125 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-24 04:09:33.091125 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-24 04:09:33.106745 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-24 04:09:33.122368 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-24 04:09:33.122368 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-24 04:09:33.169235 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-24 04:09:33.169235 (Thread-1): finished collecting timing info
2022-01-24 04:09:33.169235 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-24 04:09:33.169235 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C22B3A0>]}
2022-01-24 04:09:33.184852 (Thread-1): 09:39:33 | 2 of 13 OK created table model dwh.dim_date.......................... [SELECT 8060 in 0.84s]
2022-01-24 04:09:33.184852 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-24 04:09:33.184852 (Thread-1): Began running node model.sakila_dbt_project.dim_film
2022-01-24 04:09:33.184852 (Thread-1): 09:39:33 | 3 of 13 START incremental model dwh.dim_film......................... [RUN]
2022-01-24 04:09:33.184852 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-24 04:09:33.184852 (Thread-1): Compiling model.sakila_dbt_project.dim_film
2022-01-24 04:09:33.200473 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_film"
2022-01-24 04:09:33.216129 (Thread-1): finished collecting timing info
2022-01-24 04:09:33.216129 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-24 04:09:33.216129 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

    

  create temporary table "dim_film__dbt_tmp093933216129"
  as (
    

with stg_film as (
	select
	*,
	(case
	when length<=75 then 'short'
	when (length>75 and length<=120) then 'medium'
	when length>120 then 'long'
	else 'na' end) as length_desc,
	COALESCE(original_language_id,0) as original_language_id_zero,
	case when POSITION('Trailers' in special_features::varchar)>0 then 1 else 0 end  as has_trailers,
	case when POSITION('Commentaries' in special_features::varchar)>0 then 1 else 0 end  as has_commentaries,
	case when POSITION('Deleted Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_deleted_scenes,
	case when POSITION('Behind the Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_behind_the_scenes,
	'2022-01-24 04:09:26'::timestamp as dbt_time
	from
	"sakila_wh"."stg"."film"
),

language as (
	select * from "sakila_wh"."stg"."language"
),

category as (
	select * from "sakila_wh"."stg"."category"
),

film_category as (
	select * from "sakila_wh"."stg"."film_category"
),

stg_film_1 as (
	select
	stg_film.*,
	language.name as lang_name
	from
	stg_film
	left join language on 1=1
	and stg_film.language_id = language.language_id
),

stg_film_2 as (
	select
		stg_film_1.*,
		category.category_id,
		category.name as category_desc
	from
	stg_film_1

	left join film_category on 1=1
	and stg_film_1.film_id = film_category.film_id

	left join category on 1=1
	and film_category.category_id  = category.category_id
)


select
  film_id,
  title,
  description,
  release_year,
  language_id,
  lang_name,
  original_language_id_zero as original_language_id,
  rental_duration,
  rental_rate,
  length,
  length_desc,
  replacement_cost,
  rating,
  category_id,
  category_desc,
  special_features,
  has_trailers,
  has_commentaries,
  has_behind_the_scenes,
  has_deleted_scenes,
  last_update,
	dbt_time
from
stg_film_2

where 1=1


and last_update::timestamp > (select max(last_update) from "sakila_wh"."dwh"."dim_film")

  );
  
2022-01-24 04:09:33.216129 (Thread-1): Opening a new connection, currently in state closed
2022-01-24 04:09:33.415462 (Thread-1): SQL status: SELECT 0 in 0.20 seconds
2022-01-24 04:09:33.431081 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-24 04:09:33.431081 (Thread-1): On model.sakila_dbt_project.dim_film: BEGIN
2022-01-24 04:09:33.431081 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-24 04:09:33.431081 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-24 04:09:33.431081 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dim_film__dbt_tmp093933216129'
        
      order by ordinal_position

  
2022-01-24 04:09:33.462324 (Thread-1): SQL status: SELECT 22 in 0.03 seconds
2022-01-24 04:09:33.477946 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-24 04:09:33.477946 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_film'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-24 04:09:33.477946 (Thread-1): SQL status: SELECT 22 in 0.00 seconds
2022-01-24 04:09:33.493565 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-24 04:09:33.493565 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_film'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-24 04:09:33.493565 (Thread-1): SQL status: SELECT 22 in 0.00 seconds
2022-01-24 04:09:33.509190 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_film"
2022-01-24 04:09:33.509190 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-24 04:09:33.509190 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      delete
    from "sakila_wh"."dwh"."dim_film"
    where (film_id) in (
        select (film_id)
        from "dim_film__dbt_tmp093933216129"
    );

    insert into "sakila_wh"."dwh"."dim_film" ("film_id", "title", "description", "release_year", "language_id", "lang_name", "original_language_id", "rental_duration", "rental_rate", "length", "length_desc", "replacement_cost", "rating", "category_id", "category_desc", "special_features", "has_trailers", "has_commentaries", "has_behind_the_scenes", "has_deleted_scenes", "last_update", "dbt_time")
    (
       select "film_id", "title", "description", "release_year", "language_id", "lang_name", "original_language_id", "rental_duration", "rental_rate", "length", "length_desc", "replacement_cost", "rating", "category_id", "category_desc", "special_features", "has_trailers", "has_commentaries", "has_behind_the_scenes", "has_deleted_scenes", "last_update", "dbt_time"
       from "dim_film__dbt_tmp093933216129"
    );
  
2022-01-24 04:09:33.509190 (Thread-1): SQL status: INSERT 0 0 in 0.00 seconds
2022-01-24 04:09:33.524807 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:33.524807 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-24 04:09:33.524807 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

        insert into "sakila_wh"."dwh"."dim_film"(film_id) VALUES (-1)
      
2022-01-24 04:09:33.540433 (Thread-1): SQL status: INSERT 0 1 in 0.02 seconds
2022-01-24 04:09:33.540433 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-24 04:09:33.540433 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-24 04:09:33.540433 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-24 04:09:33.540433 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-24 04:09:33.540433 (Thread-1): finished collecting timing info
2022-01-24 04:09:33.540433 (Thread-1): On model.sakila_dbt_project.dim_film: Close
2022-01-24 04:09:33.540433 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C26FF70>]}
2022-01-24 04:09:33.540433 (Thread-1): 09:39:33 | 3 of 13 OK created incremental model dwh.dim_film.................... [INSERT 0 0 in 0.36s]
2022-01-24 04:09:33.556052 (Thread-1): Finished running node model.sakila_dbt_project.dim_film
2022-01-24 04:09:33.556052 (Thread-1): Began running node model.sakila_dbt_project.dim_staff
2022-01-24 04:09:33.556052 (Thread-1): 09:39:33 | 4 of 13 START table model dwh.dim_staff.............................. [RUN]
2022-01-24 04:09:33.556052 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-24 04:09:33.556052 (Thread-1): Compiling model.sakila_dbt_project.dim_staff
2022-01-24 04:09:33.569905 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-24 04:09:33.569905 (Thread-1): finished collecting timing info
2022-01-24 04:09:33.569905 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-24 04:09:33.585529 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-24 04:09:33.585529 (Thread-1): On model.sakila_dbt_project.dim_staff: BEGIN
2022-01-24 04:09:33.585529 (Thread-1): Opening a new connection, currently in state closed
2022-01-24 04:09:33.702646 (Thread-1): SQL status: BEGIN in 0.12 seconds
2022-01-24 04:09:33.702646 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-24 04:09:33.702646 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */


  create  table "sakila_wh"."dwh"."dim_staff__dbt_tmp"
  as (
    

with staff_base as (
select
*,
(case when active::int = 1 then 1 else 0 end) as "active_int",
(case when active::int = 1 then 'yes' else 'no' end) as "active_desc",
'2022-01-24 04:09:26'::timestamp as dbt_time
from
"sakila_wh"."stg"."staff"
)

select
	staff_id,
	first_name,
	last_name,
	email,
  active_int as active,
  active_desc,
	last_update,
  dbt_time
from
	staff_base
  );
2022-01-24 04:09:33.780753 (Thread-1): SQL status: SELECT 2 in 0.08 seconds
2022-01-24 04:09:33.780753 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-24 04:09:33.780753 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
alter table "sakila_wh"."dwh"."dim_staff" rename to "dim_staff__dbt_backup"
2022-01-24 04:09:33.780753 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:33.796373 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-24 04:09:33.796373 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
alter table "sakila_wh"."dwh"."dim_staff__dbt_tmp" rename to "dim_staff"
2022-01-24 04:09:33.796373 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:33.796373 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:33.796373 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-24 04:09:33.796373 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */

        insert into "sakila_wh"."dwh"."dim_staff"(staff_id) VALUES (-1)
      
2022-01-24 04:09:33.796373 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-24 04:09:33.811997 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-24 04:09:33.811997 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-24 04:09:33.811997 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-24 04:09:33.811997 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-24 04:09:33.811997 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-24 04:09:33.811997 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
drop table if exists "sakila_wh"."dwh"."dim_staff__dbt_backup" cascade
2022-01-24 04:09:33.811997 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2022-01-24 04:09:33.827616 (Thread-1): finished collecting timing info
2022-01-24 04:09:33.827616 (Thread-1): On model.sakila_dbt_project.dim_staff: Close
2022-01-24 04:09:33.827616 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C2BE0A0>]}
2022-01-24 04:09:33.827616 (Thread-1): 09:39:33 | 4 of 13 OK created table model dwh.dim_staff......................... [SELECT 2 in 0.27s]
2022-01-24 04:09:33.827616 (Thread-1): Finished running node model.sakila_dbt_project.dim_staff
2022-01-24 04:09:33.827616 (Thread-1): Began running node model.sakila_dbt_project.fact_payment
2022-01-24 04:09:33.827616 (Thread-1): 09:39:33 | 5 of 13 START incremental model dwh.fact_payment..................... [RUN]
2022-01-24 04:09:33.827616 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-24 04:09:33.827616 (Thread-1): Compiling model.sakila_dbt_project.fact_payment
2022-01-24 04:09:33.827616 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.fact_payment"
2022-01-24 04:09:33.843239 (Thread-1): finished collecting timing info
2022-01-24 04:09:33.843239 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-24 04:09:33.843239 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

    

  create temporary table "fact_payment__dbt_tmp093933843239"
  as (
    

select
*,
'2022-01-24 04:09:26' as dbt_time
from
"sakila_wh"."stg"."payment"
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."dwh"."fact_payment")

  );
  
2022-01-24 04:09:33.858858 (Thread-1): Opening a new connection, currently in state closed
2022-01-24 04:09:34.110587 (Thread-1): SQL status: SELECT 0 in 0.25 seconds
2022-01-24 04:09:34.110587 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-24 04:09:34.110587 (Thread-1): On model.sakila_dbt_project.fact_payment: BEGIN
2022-01-24 04:09:34.126210 (Thread-1): SQL status: BEGIN in 0.02 seconds
2022-01-24 04:09:34.126210 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-24 04:09:34.126210 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_payment__dbt_tmp093933843239'
        
      order by ordinal_position

  
2022-01-24 04:09:34.157451 (Thread-1): SQL status: SELECT 7 in 0.03 seconds
2022-01-24 04:09:34.157451 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-24 04:09:34.157451 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'fact_payment'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-24 04:09:34.173075 (Thread-1): SQL status: SELECT 7 in 0.02 seconds
2022-01-24 04:09:34.173075 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-24 04:09:34.173075 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'fact_payment'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-24 04:09:34.188696 (Thread-1): SQL status: SELECT 7 in 0.02 seconds
2022-01-24 04:09:34.188696 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.fact_payment"
2022-01-24 04:09:34.188696 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-24 04:09:34.188696 (Thread-1): On model.sakila_dbt_project.fact_payment: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_payment"} */

      delete
    from "sakila_wh"."dwh"."fact_payment"
    where (payment_id) in (
        select (payment_id)
        from "fact_payment__dbt_tmp093933843239"
    );

    insert into "sakila_wh"."dwh"."fact_payment" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time"
       from "fact_payment__dbt_tmp093933843239"
    );
  
2022-01-24 04:09:34.188696 (Thread-1): SQL status: INSERT 0 0 in 0.00 seconds
2022-01-24 04:09:34.188696 (Thread-1): On model.sakila_dbt_project.fact_payment: COMMIT
2022-01-24 04:09:34.188696 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_payment".
2022-01-24 04:09:34.188696 (Thread-1): On model.sakila_dbt_project.fact_payment: COMMIT
2022-01-24 04:09:34.204316 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-24 04:09:34.204316 (Thread-1): finished collecting timing info
2022-01-24 04:09:34.204316 (Thread-1): On model.sakila_dbt_project.fact_payment: Close
2022-01-24 04:09:34.204316 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C2F0250>]}
2022-01-24 04:09:34.204316 (Thread-1): 09:39:34 | 5 of 13 OK created incremental model dwh.fact_payment................ [INSERT 0 0 in 0.38s]
2022-01-24 04:09:34.204316 (Thread-1): Finished running node model.sakila_dbt_project.fact_payment
2022-01-24 04:09:34.204316 (Thread-1): Began running node model.sakila_dbt_project.film_test
2022-01-24 04:09:34.204316 (Thread-1): 09:39:34 | 6 of 13 START table model examples.film_test......................... [RUN]
2022-01-24 04:09:34.204316 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-24 04:09:34.204316 (Thread-1): Compiling model.sakila_dbt_project.film_test
2022-01-24 04:09:34.219936 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.film_test"
2022-01-24 04:09:34.261860 (Thread-1): finished collecting timing info
2022-01-24 04:09:34.261860 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.film_test"
2022-01-24 04:09:36.290631 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-24 04:09:36.290631 (Thread-1): On model.sakila_dbt_project.film_test: BEGIN
2022-01-24 04:09:36.290631 (Thread-1): Opening a new connection, currently in state closed
2022-01-24 04:09:36.418676 (Thread-1): SQL status: BEGIN in 0.13 seconds
2022-01-24 04:09:36.418676 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-24 04:09:36.418676 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */


  create  table "sakila_wh"."examples"."film_test__dbt_tmp"
  as (
    select
*
from
-- sakila_wh.stg.film
"sakila_wh"."stg"."film"
  );
2022-01-24 04:09:36.512403 (Thread-1): SQL status: SELECT 1000 in 0.09 seconds
2022-01-24 04:09:36.528025 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-24 04:09:36.528025 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."examples"."film_test" rename to "film_test__dbt_backup"
2022-01-24 04:09:36.528025 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:36.528025 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-24 04:09:36.528025 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."examples"."film_test__dbt_tmp" rename to "film_test"
2022-01-24 04:09:36.528025 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:36.528025 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-24 04:09:36.528025 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-24 04:09:36.543647 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-24 04:09:36.543647 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-24 04:09:36.543647 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-24 04:09:36.543647 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
drop table if exists "sakila_wh"."examples"."film_test__dbt_backup" cascade
2022-01-24 04:09:36.574887 (Thread-1): SQL status: DROP TABLE in 0.03 seconds
2022-01-24 04:09:36.574887 (Thread-1): finished collecting timing info
2022-01-24 04:09:36.574887 (Thread-1): On model.sakila_dbt_project.film_test: Close
2022-01-24 04:09:36.574887 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C226DC0>]}
2022-01-24 04:09:36.574887 (Thread-1): 09:39:36 | 6 of 13 OK created table model examples.film_test.................... [SELECT 1000 in 2.37s]
2022-01-24 04:09:36.574887 (Thread-1): Finished running node model.sakila_dbt_project.film_test
2022-01-24 04:09:36.574887 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-24 04:09:36.574887 (Thread-1): 09:39:36 | 7 of 13 START table model examples.hello_world....................... [RUN]
2022-01-24 04:09:36.574887 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-24 04:09:36.574887 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-24 04:09:36.574887 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-24 04:09:36.590513 (Thread-1): finished collecting timing info
2022-01-24 04:09:36.606133 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-24 04:09:36.637372 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-24 04:09:36.637372 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-24 04:09:36.637372 (Thread-1): Opening a new connection, currently in state closed
2022-01-24 04:09:36.740275 (Thread-1): SQL status: BEGIN in 0.10 seconds
2022-01-24 04:09:36.740275 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-24 04:09:36.740275 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."examples"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-24 04:09:36.871963 (Thread-1): SQL status: SELECT 599 in 0.13 seconds
2022-01-24 04:09:36.887585 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-24 04:09:36.887585 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."examples"."hello_world" rename to "hello_world__dbt_backup"
2022-01-24 04:09:36.887585 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:36.887585 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-24 04:09:36.887585 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."examples"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-24 04:09:36.887585 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:36.903205 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-24 04:09:36.903205 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-24 04:09:36.903205 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-24 04:09:36.903205 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-24 04:09:36.903205 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-24 04:09:36.903205 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."examples"."hello_world__dbt_backup" cascade
2022-01-24 04:09:36.918826 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-01-24 04:09:36.918826 (Thread-1): finished collecting timing info
2022-01-24 04:09:36.918826 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-24 04:09:36.918826 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C253550>]}
2022-01-24 04:09:36.918826 (Thread-1): 09:39:36 | 7 of 13 OK created table model examples.hello_world.................. [SELECT 599 in 0.34s]
2022-01-24 04:09:36.918826 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-24 04:09:36.918826 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-24 04:09:36.918826 (Thread-1): 09:39:36 | 8 of 13 START table model examples.my_first_dbt_model................ [RUN]
2022-01-24 04:09:36.918826 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-24 04:09:36.934448 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-24 04:09:36.934448 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-24 04:09:36.950072 (Thread-1): finished collecting timing info
2022-01-24 04:09:36.950072 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-24 04:09:36.950072 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-24 04:09:36.950072 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-24 04:09:36.950072 (Thread-1): Opening a new connection, currently in state closed
2022-01-24 04:09:37.056874 (Thread-1): SQL status: BEGIN in 0.11 seconds
2022-01-24 04:09:37.056874 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-24 04:09:37.056874 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."examples"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-24 04:09:37.072495 (Thread-1): SQL status: SELECT 2 in 0.02 seconds
2022-01-24 04:09:37.088118 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-24 04:09:37.088118 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."examples"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-24 04:09:37.088118 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:37.103738 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-24 04:09:37.103738 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."examples"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-24 04:09:37.103738 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:37.103738 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-24 04:09:37.103738 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-24 04:09:37.103738 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-24 04:09:37.103738 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-24 04:09:37.119360 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-24 04:09:37.119360 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."examples"."my_first_dbt_model__dbt_backup" cascade
2022-01-24 04:09:37.134982 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-01-24 04:09:37.134982 (Thread-1): finished collecting timing info
2022-01-24 04:09:37.134982 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-24 04:09:37.134982 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C2D3C40>]}
2022-01-24 04:09:37.134982 (Thread-1): 09:39:37 | 8 of 13 OK created table model examples.my_first_dbt_model........... [SELECT 2 in 0.22s]
2022-01-24 04:09:37.134982 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-24 04:09:37.150602 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-24 04:09:37.150602 (Thread-1): 09:39:37 | 9 of 13 START incremental model examples.payment_inc................. [RUN]
2022-01-24 04:09:37.150602 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-24 04:09:37.150602 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-24 04:09:37.150602 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-24 04:09:37.181846 (Thread-1): finished collecting timing info
2022-01-24 04:09:37.197469 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-24 04:09:37.197469 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

    

  create temporary table "payment_inc__dbt_tmp093937181846"
  as (
    

select
*,
'2022-01-24 04:09:26' as dbt_time
from
stg.payment
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."examples"."payment_inc")



-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-24 04:09:37.197469 (Thread-1): Opening a new connection, currently in state closed
2022-01-24 04:09:37.367441 (Thread-1): SQL status: SELECT 0 in 0.17 seconds
2022-01-24 04:09:37.367441 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-24 04:09:37.367441 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-24 04:09:37.367441 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-24 04:09:37.367441 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-24 04:09:37.367441 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc__dbt_tmp093937181846'
        
      order by ordinal_position

  
2022-01-24 04:09:37.414304 (Thread-1): SQL status: SELECT 7 in 0.03 seconds
2022-01-24 04:09:37.414304 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-24 04:09:37.429924 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'examples'
        
      order by ordinal_position

  
2022-01-24 04:09:37.429924 (Thread-1): SQL status: SELECT 7 in 0.00 seconds
2022-01-24 04:09:37.429924 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-24 04:09:37.429924 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'examples'
        
      order by ordinal_position

  
2022-01-24 04:09:37.445546 (Thread-1): SQL status: SELECT 7 in 0.00 seconds
2022-01-24 04:09:37.445546 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-24 04:09:37.461168 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-24 04:09:37.461168 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      delete
    from "sakila_wh"."examples"."payment_inc"
    where (payment_id) in (
        select (payment_id)
        from "payment_inc__dbt_tmp093937181846"
    );

    insert into "sakila_wh"."examples"."payment_inc" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_time"
       from "payment_inc__dbt_tmp093937181846"
    );
  
2022-01-24 04:09:37.461168 (Thread-1): SQL status: INSERT 0 0 in 0.00 seconds
2022-01-24 04:09:37.461168 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-24 04:09:37.461168 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-24 04:09:37.461168 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-24 04:09:37.461168 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-24 04:09:37.461168 (Thread-1): finished collecting timing info
2022-01-24 04:09:37.476789 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-24 04:09:37.476789 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C306BE0>]}
2022-01-24 04:09:37.476789 (Thread-1): 09:39:37 | 9 of 13 OK created incremental model examples.payment_inc............ [INSERT 0 0 in 0.33s]
2022-01-24 04:09:37.476789 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-24 04:09:37.476789 (Thread-1): Began running node model.sakila_dbt_project.dim_date_inc
2022-01-24 04:09:37.476789 (Thread-1): 09:39:37 | 10 of 13 START incremental model examples.dim_date_inc............... [RUN]
2022-01-24 04:09:37.476789 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-24 04:09:37.476789 (Thread-1): Compiling model.sakila_dbt_project.dim_date_inc
2022-01-24 04:09:37.476789 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date_inc"
2022-01-24 04:09:37.500753 (Thread-1): finished collecting timing info
2022-01-24 04:09:37.516374 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-24 04:09:37.516374 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

    

  create temporary table "dim_date_inc__dbt_tmp093937500753"
  as (
    


SELECT
*
from "sakila_wh"."dwh"."dim_date"
where 1=1



and date_key::timestamp > (select max(date_key) - INTERVAL '3 DAY' from "sakila_wh"."examples"."dim_date_inc")

  );
  
2022-01-24 04:09:37.516374 (Thread-1): Opening a new connection, currently in state closed
2022-01-24 04:09:37.679081 (Thread-1): SQL status: SELECT 4 in 0.16 seconds
2022-01-24 04:09:37.679081 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-24 04:09:37.679081 (Thread-1): On model.sakila_dbt_project.dim_date_inc: BEGIN
2022-01-24 04:09:37.679081 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-24 04:09:37.679081 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-24 04:09:37.679081 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dim_date_inc__dbt_tmp093937500753'
        
      order by ordinal_position

  
2022-01-24 04:09:37.725945 (Thread-1): SQL status: SELECT 26 in 0.05 seconds
2022-01-24 04:09:37.741565 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-24 04:09:37.741565 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_date_inc'
        
        and table_schema = 'examples'
        
      order by ordinal_position

  
2022-01-24 04:09:37.757188 (Thread-1): SQL status: SELECT 26 in 0.02 seconds
2022-01-24 04:09:37.757188 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-24 04:09:37.757188 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_date_inc'
        
        and table_schema = 'examples'
        
      order by ordinal_position

  
2022-01-24 04:09:37.772808 (Thread-1): SQL status: SELECT 26 in 0.02 seconds
2022-01-24 04:09:37.788430 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date_inc"
2022-01-24 04:09:37.788430 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-24 04:09:37.788430 (Thread-1): On model.sakila_dbt_project.dim_date_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date_inc"} */

      delete
    from "sakila_wh"."examples"."dim_date_inc"
    where (date_dim_id) in (
        select (date_dim_id)
        from "dim_date_inc__dbt_tmp093937500753"
    );

    insert into "sakila_wh"."examples"."dim_date_inc" ("date_dim_id", "date_key", "epoch", "day_name", "day_of_week", "day_of_month", "day_of_quarter", "day_of_year", "week_of_month", "week_of_year", "month_actual", "month_name", "month_name_abbreviated", "quarter_actual", "quarter_name", "year_actual", "first_day_of_week", "last_day_of_week", "first_day_of_month", "last_day_of_month", "first_day_of_quarter", "last_day_of_quarter", "first_day_of_year", "last_day_of_year", "yyyymm", "weekend_indr")
    (
       select "date_dim_id", "date_key", "epoch", "day_name", "day_of_week", "day_of_month", "day_of_quarter", "day_of_year", "week_of_month", "week_of_year", "month_actual", "month_name", "month_name_abbreviated", "quarter_actual", "quarter_name", "year_actual", "first_day_of_week", "last_day_of_week", "first_day_of_month", "last_day_of_month", "first_day_of_quarter", "last_day_of_quarter", "first_day_of_year", "last_day_of_year", "yyyymm", "weekend_indr"
       from "dim_date_inc__dbt_tmp093937500753"
    );
  
2022-01-24 04:09:37.804053 (Thread-1): SQL status: INSERT 0 4 in 0.02 seconds
2022-01-24 04:09:37.804053 (Thread-1): On model.sakila_dbt_project.dim_date_inc: COMMIT
2022-01-24 04:09:37.804053 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date_inc".
2022-01-24 04:09:37.804053 (Thread-1): On model.sakila_dbt_project.dim_date_inc: COMMIT
2022-01-24 04:09:37.804053 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-24 04:09:37.819674 (Thread-1): finished collecting timing info
2022-01-24 04:09:37.819674 (Thread-1): On model.sakila_dbt_project.dim_date_inc: Close
2022-01-24 04:09:37.819674 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C2F4670>]}
2022-01-24 04:09:37.819674 (Thread-1): 09:39:37 | 10 of 13 OK created incremental model examples.dim_date_inc.......... [INSERT 0 4 in 0.34s]
2022-01-24 04:09:37.819674 (Thread-1): Finished running node model.sakila_dbt_project.dim_date_inc
2022-01-24 04:09:37.819674 (Thread-1): Began running node model.sakila_dbt_project.dim_store
2022-01-24 04:09:37.819674 (Thread-1): 09:39:37 | 11 of 13 START table model dwh.dim_store............................. [RUN]
2022-01-24 04:09:37.819674 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-24 04:09:37.819674 (Thread-1): Compiling model.sakila_dbt_project.dim_store
2022-01-24 04:09:37.819674 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_store"
2022-01-24 04:09:37.847857 (Thread-1): finished collecting timing info
2022-01-24 04:09:37.847857 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_store"
2022-01-24 04:09:37.863481 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-24 04:09:37.863481 (Thread-1): On model.sakila_dbt_project.dim_store: BEGIN
2022-01-24 04:09:37.863481 (Thread-1): Opening a new connection, currently in state closed
2022-01-24 04:09:37.974173 (Thread-1): SQL status: BEGIN in 0.11 seconds
2022-01-24 04:09:37.974173 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-24 04:09:37.974173 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */


  create  table "sakila_wh"."dwh"."dim_store__dbt_tmp"
  as (
    

with stg_store as (
		select
    *,
    '2022-01-24 04:09:26'::timestamp as dbt_time
     from "sakila_wh"."stg"."store"
),

staff as (
 select * from "sakila_wh"."dwh"."dim_staff"
),

address as (
  select * from "sakila_wh"."stg"."address"
),

city as (
  select * from "sakila_wh"."stg"."city"
),

country as (
  select * from "sakila_wh"."stg"."country"
),
stg_store_1 as (-- add staff
		select
		stg_store.*,
		staff.first_name as staff_first_name,
		staff.last_name as staff_last_name
		from
		stg_store
		left join staff  on 1=1
		and stg_store.manager_staff_id = staff.staff_id
),
stg_store_2 as (-- add adress
		select
		stg_store_1.*,
		address.address,
		city.city_id,
		city.city,
		country.country_id,
		country.country
		from
		stg_store_1

		left join address on 1=1
		and stg_store_1.address_id =address.address_id

		left join city on 1=1
		and address.city_id = city.city_id

		left join country on  1=1
		and city.country_id = country.country_id
)

select
  store_id,
  manager_staff_id,
  staff_first_name,
  staff_last_name,
  address_id,
  address,
  city_id,
  city,
  country_id,
  country,
  last_update,
  dbt_time
from stg_store_2
  );
2022-01-24 04:09:38.005416 (Thread-1): SQL status: SELECT 2 in 0.03 seconds
2022-01-24 04:09:38.005416 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-24 04:09:38.005416 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
alter table "sakila_wh"."dwh"."dim_store" rename to "dim_store__dbt_backup"
2022-01-24 04:09:38.005416 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:38.021039 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-24 04:09:38.021039 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
alter table "sakila_wh"."dwh"."dim_store__dbt_tmp" rename to "dim_store"
2022-01-24 04:09:38.021039 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:38.021039 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-24 04:09:38.021039 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-24 04:09:38.021039 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */

        insert into "sakila_wh"."dwh"."dim_store"(store_id) VALUES (-1)
      
2022-01-24 04:09:38.021039 (Thread-1): SQL status: INSERT 0 1 in 0.00 seconds
2022-01-24 04:09:38.036658 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-24 04:09:38.036658 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-24 04:09:38.036658 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-24 04:09:38.036658 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-24 04:09:38.036658 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-24 04:09:38.036658 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
drop table if exists "sakila_wh"."dwh"."dim_store__dbt_backup" cascade
2022-01-24 04:09:38.052280 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-01-24 04:09:38.052280 (Thread-1): finished collecting timing info
2022-01-24 04:09:38.052280 (Thread-1): On model.sakila_dbt_project.dim_store: Close
2022-01-24 04:09:38.052280 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C3261C0>]}
2022-01-24 04:09:38.052280 (Thread-1): 09:39:38 | 11 of 13 OK created table model dwh.dim_store........................ [SELECT 2 in 0.23s]
2022-01-24 04:09:38.052280 (Thread-1): Finished running node model.sakila_dbt_project.dim_store
2022-01-24 04:09:38.052280 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-24 04:09:38.052280 (Thread-1): 09:39:38 | 12 of 13 START table model examples.my_second_dbt_model.............. [RUN]
2022-01-24 04:09:38.052280 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-24 04:09:38.052280 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-24 04:09:38.067903 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-24 04:09:38.099144 (Thread-1): finished collecting timing info
2022-01-24 04:09:38.099144 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-24 04:09:38.099144 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-24 04:09:38.099144 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-24 04:09:38.099144 (Thread-1): Opening a new connection, currently in state closed
2022-01-24 04:09:38.218374 (Thread-1): SQL status: BEGIN in 0.12 seconds
2022-01-24 04:09:38.218374 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-24 04:09:38.218374 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."examples"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."examples"."my_first_dbt_model"
where id = 1
  );
2022-01-24 04:09:38.233996 (Thread-1): SQL status: SELECT 1 in 0.02 seconds
2022-01-24 04:09:38.233996 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-24 04:09:38.233996 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."examples"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-24 04:09:38.233996 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:38.249618 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-24 04:09:38.249618 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."examples"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-24 04:09:38.249618 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2022-01-24 04:09:38.249618 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-24 04:09:38.249618 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-24 04:09:38.249618 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-24 04:09:38.265240 (Thread-1): SQL status: COMMIT in 0.02 seconds
2022-01-24 04:09:38.265240 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-24 04:09:38.265240 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."examples"."my_second_dbt_model__dbt_backup" cascade
2022-01-24 04:09:38.280858 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2022-01-24 04:09:38.296480 (Thread-1): finished collecting timing info
2022-01-24 04:09:38.296480 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-24 04:09:38.296480 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C321610>]}
2022-01-24 04:09:38.296480 (Thread-1): 09:39:38 | 12 of 13 OK created table model examples.my_second_dbt_model......... [SELECT 1 in 0.24s]
2022-01-24 04:09:38.296480 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-24 04:09:38.296480 (Thread-1): Began running node model.sakila_dbt_project.fact_rental
2022-01-24 04:09:38.296480 (Thread-1): 09:39:38 | 13 of 13 START incremental model dwh.fact_rental..................... [RUN]
2022-01-24 04:09:38.296480 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-24 04:09:38.296480 (Thread-1): Compiling model.sakila_dbt_project.fact_rental
2022-01-24 04:09:38.312104 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.fact_rental"
2022-01-24 04:09:38.312104 (Thread-1): finished collecting timing info
2022-01-24 04:09:38.327723 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-24 04:09:38.327723 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

    

  create temporary table "fact_rental__dbt_tmp093938327723"
  as (
    

with rental_base as (--base
select
	*,
	EXTRACT(EPOCH from rental_date::timestamp) as rental_epoch,
	EXTRACT(EPOCH from return_date::timestamp) as return_epoch,
	EXTRACT(EPOCH from return_date::timestamp)-EXTRACT(EPOCH from rental_date::timestamp) as diff,
	(case when return_date is not null then 1 else 0 end) as is_return,
	to_char(rental_date::timestamp, 'YYYYMMDD')::integer as date_key,
  '2022-01-24 04:09:26'::timestamp as dbt_time

	from
	"sakila_wh"."stg"."rental"
),

inventory as (
	select * from "sakila_wh"."stg"."inventory"
),

dim_film as (
	select * from "sakila_wh"."dwh"."dim_film"
),

dim_store as (
	select * from "sakila_wh"."dwh"."dim_store"
),

dim_staff as (
	select * from "sakila_wh"."dwh"."dim_staff"
),

dim_customer as (
	select * from "sakila_wh"."dwh"."dim_customer"
),

rental_base_1 as (-- join base with inventory
	select
	rental_base.*,
	inventory.store_id,
  inventory.film_id
	from
	rental_base

	inner join inventory on 1=1
	and inventory.inventory_id = rental_base.inventory_id
),


rental_base_2 as (--check direct integrity
	select
	rental_base_1.*,
	(case when dim_staff.staff_id is not null then dim_staff.staff_id else -1 end) as staff_id_rental_check,
	(case when dim_customer.customer_id is not null then dim_customer.customer_id else -1 end) as customer_id_check,
  (case when dim_film.film_id is not null then dim_film.film_id else -1 end) as film_id_check,
	(case when dim_store.store_id is not null then dim_store.store_id else -1 end) as store_id_check
	from
	rental_base_1

	left join
  dim_staff
  on 1=1
	and rental_base_1.staff_id = dim_staff.staff_id

	left join
  dim_customer
  on 1=1
	and rental_base_1.customer_id = dim_customer.customer_id

  left join
  dim_film
  on 1=1
  and  rental_base_1.film_id = dim_film.film_id

  left join
  dim_store
  on 1=1
  and  rental_base_1.store_id = dim_store.store_id
)

select
  rental_id,
  rental_date,
  date_key,
  inventory_id,
  customer_id_check as customer_id,
  film_id_check as film_id,
  store_id_check as store_id,
  staff_id_rental_check as staff_id_rental,
  return_date,
  case when return_date is not null then diff/3600 else null end rental_hours,
  is_return,
  last_update,
  dbt_time
from
 rental_base_2
 where 1=1

 
 and last_update::timestamp > (select max(last_update) from "sakila_wh"."dwh"."fact_rental")
 

 --  - INTERVAL '10 minutes'
  );
  
2022-01-24 04:09:38.327723 (Thread-1): Opening a new connection, currently in state closed
2022-01-24 04:09:38.605002 (Thread-1): SQL status: SELECT 0 in 0.28 seconds
2022-01-24 04:09:38.605002 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-24 04:09:38.605002 (Thread-1): On model.sakila_dbt_project.fact_rental: BEGIN
2022-01-24 04:09:38.605002 (Thread-1): SQL status: BEGIN in 0.00 seconds
2022-01-24 04:09:38.605002 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-24 04:09:38.605002 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_rental__dbt_tmp093938327723'
        
      order by ordinal_position

  
2022-01-24 04:09:38.636246 (Thread-1): SQL status: SELECT 13 in 0.03 seconds
2022-01-24 04:09:38.651868 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-24 04:09:38.651868 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'fact_rental'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-24 04:09:38.651868 (Thread-1): SQL status: SELECT 13 in 0.00 seconds
2022-01-24 04:09:38.667489 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-24 04:09:38.667489 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'fact_rental'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-24 04:09:38.667489 (Thread-1): SQL status: SELECT 13 in 0.00 seconds
2022-01-24 04:09:38.683110 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.fact_rental"
2022-01-24 04:09:38.683110 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-24 04:09:38.683110 (Thread-1): On model.sakila_dbt_project.fact_rental: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.fact_rental"} */

      delete
    from "sakila_wh"."dwh"."fact_rental"
    where (rental_id) in (
        select (rental_id)
        from "fact_rental__dbt_tmp093938327723"
    );

    insert into "sakila_wh"."dwh"."fact_rental" ("rental_id", "rental_date", "date_key", "inventory_id", "customer_id", "film_id", "store_id", "staff_id_rental", "return_date", "rental_hours", "is_return", "last_update", "dbt_time")
    (
       select "rental_id", "rental_date", "date_key", "inventory_id", "customer_id", "film_id", "store_id", "staff_id_rental", "return_date", "rental_hours", "is_return", "last_update", "dbt_time"
       from "fact_rental__dbt_tmp093938327723"
    );
  
2022-01-24 04:09:38.683110 (Thread-1): SQL status: INSERT 0 0 in 0.00 seconds
2022-01-24 04:09:38.683110 (Thread-1): On model.sakila_dbt_project.fact_rental: COMMIT
2022-01-24 04:09:38.683110 (Thread-1): Using postgres connection "model.sakila_dbt_project.fact_rental".
2022-01-24 04:09:38.683110 (Thread-1): On model.sakila_dbt_project.fact_rental: COMMIT
2022-01-24 04:09:38.683110 (Thread-1): SQL status: COMMIT in 0.00 seconds
2022-01-24 04:09:38.683110 (Thread-1): finished collecting timing info
2022-01-24 04:09:38.683110 (Thread-1): On model.sakila_dbt_project.fact_rental: Close
2022-01-24 04:09:38.683110 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a01b5978-a53b-4257-b35c-f9170651ea93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C2BE1F0>]}
2022-01-24 04:09:38.683110 (Thread-1): 09:39:38 | 13 of 13 OK created incremental model dwh.fact_rental................ [INSERT 0 0 in 0.39s]
2022-01-24 04:09:38.683110 (Thread-1): Finished running node model.sakila_dbt_project.fact_rental
2022-01-24 04:09:38.740120 (MainThread): Acquiring new postgres connection "master".
2022-01-24 04:09:38.740120 (MainThread): Using postgres connection "master".
2022-01-24 04:09:38.740120 (MainThread): On master: BEGIN
2022-01-24 04:09:38.740120 (MainThread): Opening a new connection, currently in state closed
2022-01-24 04:09:38.833851 (MainThread): SQL status: BEGIN in 0.09 seconds
2022-01-24 04:09:38.833851 (MainThread): On master: COMMIT
2022-01-24 04:09:38.833851 (MainThread): Using postgres connection "master".
2022-01-24 04:09:38.833851 (MainThread): On master: COMMIT
2022-01-24 04:09:38.833851 (MainThread): SQL status: COMMIT in 0.00 seconds
2022-01-24 04:09:38.833851 (MainThread): On master: Close
2022-01-24 04:09:38.849471 (MainThread): 09:39:38 | 
2022-01-24 04:09:38.849471 (MainThread): 09:39:38 | Finished running 6 incremental models, 7 table models in 10.26s.
2022-01-24 04:09:38.849471 (MainThread): Connection 'master' was properly closed.
2022-01-24 04:09:38.849471 (MainThread): Connection 'list_sakila_wh' was properly closed.
2022-01-24 04:09:38.849471 (MainThread): Connection 'list_sakila_wh_dwh' was properly closed.
2022-01-24 04:09:38.849471 (MainThread): Connection 'model.sakila_dbt_project.fact_rental' was properly closed.
2022-01-24 04:09:38.896333 (MainThread): 
2022-01-24 04:09:38.896333 (MainThread): Completed successfully
2022-01-24 04:09:38.896333 (MainThread): 
Done. PASS=13 WARN=0 ERROR=0 SKIP=0 TOTAL=13
2022-01-24 04:09:38.896333 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C0CAB20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8C0CA940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8BF086A0>]}
2022-01-24 04:09:38.896333 (MainThread): Flushing usage events
